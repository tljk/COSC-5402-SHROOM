{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing dependencies. You might need to tweak the CMAKE_ARGS for the `llama-cpp-python` pip package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CKL68Itp9Bm-",
    "outputId": "dd33c010-aa3e-4f6a-c763-e30047591c5e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'CMAKE_ARGS' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.17.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface_hub) (3.7.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface_hub) (2023.9.2)\n",
      "Requirement already satisfied: requests in c:\\users\\tangl\\appdata\\roaming\\python\\python39\\site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface_hub) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface_hub) (4.11.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface_hub) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging>=20.9->huggingface_hub) (3.0.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\tangl\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->huggingface_hub) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->huggingface_hub) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->huggingface_hub) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->huggingface_hub) (2023.7.22)\n",
      "Requirement already satisfied: datasets in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.14.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (14.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (1.4.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\tangl\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.9.2)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.17.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (2.0.12)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging->datasets) (3.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\tangl\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.62.1->datasets) (0.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tangl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# GPU llama-cpp-python; Starting from version llama-cpp-python==0.1.79, it supports GGUF\n",
    "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on \" pip install 'llama-cpp-python>=0.1.79' --force-reinstall --upgrade --no-cache-dir\n",
    "# For download the models\n",
    "!pip install huggingface_hub\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by downloading an instruction-finetuned Mistral model, which we will ask to classify model outputs for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106,
     "referenced_widgets": [
      "2ae89d1a8a074a249b750d138587e44d",
      "eb30e73c1e824fa8942f0c58104d696f",
      "df0a135d8a5b43d5ab94bef15b2db5aa",
      "a5e99c0d3739407799fde2f29a301d05",
      "fa5555299e2e47ae9d2cc7a7e58415f4",
      "c96a1b051a7b4fbfbd873be07cf44cf0",
      "fa37a3f2205749468f31309b6061ffef",
      "a0ceffacff7f492d87084da291061006",
      "af87959da48a436e842f58ac691717df",
      "e35a5293e19748679095d1222f1a31e5",
      "2abefc6082af406ab1c955a880a2b419"
     ]
    },
    "id": "uDMqQmBfAhYO",
    "outputId": "eacd2078-6e5a-4451-84b4-69c6789cb4d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 25 key-value pairs and 435 tensors from C:\\Users\\tangl\\.cache\\huggingface\\hub\\models--TheBloke--Solar-10.7B-SLERP-GGUF\\snapshots\\e0d472af9430370775d9baa724f0f5eb2c0022ae\\solar-10.7b-slerp.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 48\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                      tokenizer.ggml.merges arr[str,58980]   = [\"▁ t\", \"i n\", \"e r\", \"▁ a\", \"h e...\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 2\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  22:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  23:                    tokenizer.chat_template str              = {% for message in messages %}{% if me...\n",
      "llama_model_loader: - kv  24:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   97 tensors\n",
      "llama_model_loader: - type q4_K:  289 tensors\n",
      "llama_model_loader: - type q6_K:   49 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 48\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 34B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 10.73 B\n",
      "llm_load_print_meta: model size       = 6.02 GiB (4.82 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 2 '</s>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.33 MiB\n",
      "llm_load_tensors: offloading 48 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 49/49 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =    70.31 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  6091.30 MiB\n",
      "....................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 8192\n",
      "llama_new_context_with_model: n_batch    = 8000\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =  1536.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 1536.00 MiB, K (f16):  768.00 MiB, V (f16):  768.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   560.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    24.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1542\n",
      "llama_new_context_with_model: graph splits = 2\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'general.name': 'LLaMA v2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.block_count': '48', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '2', 'general.file_type': '15', 'llama.attention.head_count_kv': '8', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '10000.000000', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.padding_token_id': '2', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.chat_template': \"{% for message in messages %}{% if message['role'] == 'system' %}{% if message['content']%}{{'### System:\\n' + message['content']+'\\n\\n'}}{% endif %}{% elif message['role'] == 'user' %}{{'### User:\\n' + message['content']+'\\n\\n'}}{% elif message['role'] == 'assistant' %}{{'### Assistant:\\n'  + message['content']}}{% endif %}{% if loop.last and add_generation_prompt %}{{ '### Assistant:\\n' }}{% endif %}{% endfor %}\"}\n",
      "Using gguf chat template: {% for message in messages %}{% if message['role'] == 'system' %}{% if message['content']%}{{'### System:\n",
      "' + message['content']+'\n",
      "\n",
      "'}}{% endif %}{% elif message['role'] == 'user' %}{{'### User:\n",
      "' + message['content']+'\n",
      "\n",
      "'}}{% elif message['role'] == 'assistant' %}{{'### Assistant:\n",
      "'  + message['content']}}{% endif %}{% if loop.last and add_generation_prompt %}{{ '### Assistant:\n",
      "' }}{% endif %}{% endfor %}\n",
      "Using chat eos_token: </s>\n",
      "Using chat bos_token: <s>\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "model_name_or_path = \"TheBloke/Solar-10.7B-SLERP-GGUF\"\n",
    "model_basename = \"solar-10.7b-slerp.Q4_K_M.gguf\"\n",
    "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)\n",
    "\n",
    "# This config has been tested on an RTX 3080 (VRAM of 16GB).\n",
    "# you might need to tweak with respect to your hardware.\n",
    "from llama_cpp import Llama\n",
    "lcpp_llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_threads=12, # CPU cores\n",
    "    n_batch=8000, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "    n_gpu_layers=64, # Change this value based on your model and your GPU VRAM pool.\n",
    "    n_ctx=8192, # Context window\n",
    "    logits_all=True\n",
    ")\n",
    "\n",
    "run_on_test = False # whether this baseline system is ran on the test splits or the val splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running on the model-aware track data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UKo1-X5OvT4b",
    "outputId": "4eba054f-48c4-4aea-a1de-4c14c9c45fa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724e61cf9d94495cb811d6452ef13612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     4 runs   (    0.21 ms per token,  4773.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1528.91 ms /    51 tokens (   29.98 ms per token,    33.36 tokens per second)\n",
      "llama_print_timings:        eval time =     353.81 ms /     3 runs   (  117.94 ms per token,     8.48 tokens per second)\n",
      "llama_print_timings:       total time =    2026.49 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.73 ms /     3 runs   (    0.24 ms per token,  4126.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1090.13 ms /    42 tokens (   25.96 ms per token,    38.53 tokens per second)\n",
      "llama_print_timings:        eval time =     272.57 ms /     2 runs   (  136.28 ms per token,     7.34 tokens per second)\n",
      "llama_print_timings:       total time =    1475.80 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     4 runs   (    0.23 ms per token,  4444.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1150.66 ms /    47 tokens (   24.48 ms per token,    40.85 tokens per second)\n",
      "llama_print_timings:        eval time =     357.58 ms /     3 runs   (  119.19 ms per token,     8.39 tokens per second)\n",
      "llama_print_timings:       total time =    1638.80 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     4 runs   (    0.22 ms per token,  4509.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1213.00 ms /    50 tokens (   24.26 ms per token,    41.22 tokens per second)\n",
      "llama_print_timings:        eval time =     343.18 ms /     3 runs   (  114.39 ms per token,     8.74 tokens per second)\n",
      "llama_print_timings:       total time =    1696.87 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4580.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.08 ms /    53 tokens (   23.94 ms per token,    41.76 tokens per second)\n",
      "llama_print_timings:        eval time =     245.75 ms /     2 runs   (  122.87 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =    1688.02 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4702.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1365.46 ms /    57 tokens (   23.96 ms per token,    41.74 tokens per second)\n",
      "llama_print_timings:        eval time =     243.89 ms /     2 runs   (  121.95 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =    1769.98 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     4 runs   (    0.20 ms per token,  4920.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     926.68 ms /    36 tokens (   25.74 ms per token,    38.85 tokens per second)\n",
      "llama_print_timings:        eval time =     352.06 ms /     3 runs   (  117.35 ms per token,     8.52 tokens per second)\n",
      "llama_print_timings:       total time =    1370.27 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     3 runs   (    0.27 ms per token,  3750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1191.95 ms /    46 tokens (   25.91 ms per token,    38.59 tokens per second)\n",
      "llama_print_timings:        eval time =     232.08 ms /     2 runs   (  116.04 ms per token,     8.62 tokens per second)\n",
      "llama_print_timings:       total time =    1542.28 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4373.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1304.91 ms /    51 tokens (   25.59 ms per token,    39.08 tokens per second)\n",
      "llama_print_timings:        eval time =     249.81 ms /     2 runs   (  124.90 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =    1685.26 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4769.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1073.25 ms /    43 tokens (   24.96 ms per token,    40.07 tokens per second)\n",
      "llama_print_timings:        eval time =     231.43 ms /     2 runs   (  115.71 ms per token,     8.64 tokens per second)\n",
      "llama_print_timings:       total time =    1405.06 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     3 runs   (    0.24 ms per token,  4249.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1223.91 ms /    48 tokens (   25.50 ms per token,    39.22 tokens per second)\n",
      "llama_print_timings:        eval time =     258.55 ms /     2 runs   (  129.28 ms per token,     7.74 tokens per second)\n",
      "llama_print_timings:       total time =    1603.35 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     3 runs   (    0.24 ms per token,  4201.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1336.68 ms /    55 tokens (   24.30 ms per token,    41.15 tokens per second)\n",
      "llama_print_timings:        eval time =     229.22 ms /     2 runs   (  114.61 ms per token,     8.73 tokens per second)\n",
      "llama_print_timings:       total time =    1717.39 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4491.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1264.94 ms /    53 tokens (   23.87 ms per token,    41.90 tokens per second)\n",
      "llama_print_timings:        eval time =     249.09 ms /     2 runs   (  124.54 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =    1640.51 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.73 ms /     3 runs   (    0.24 ms per token,  4126.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1475.11 ms /    61 tokens (   24.18 ms per token,    41.35 tokens per second)\n",
      "llama_print_timings:        eval time =     236.66 ms /     2 runs   (  118.33 ms per token,     8.45 tokens per second)\n",
      "llama_print_timings:       total time =    1879.84 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4366.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1231.65 ms /    52 tokens (   23.69 ms per token,    42.22 tokens per second)\n",
      "llama_print_timings:        eval time =     250.21 ms /     2 runs   (  125.11 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =    1608.72 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     3 runs   (    0.24 ms per token,  4219.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1110.73 ms /    45 tokens (   24.68 ms per token,    40.51 tokens per second)\n",
      "llama_print_timings:        eval time =     234.50 ms /     2 runs   (  117.25 ms per token,     8.53 tokens per second)\n",
      "llama_print_timings:       total time =    1449.70 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     4 runs   (    0.21 ms per token,  4672.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1282.81 ms /    52 tokens (   24.67 ms per token,    40.54 tokens per second)\n",
      "llama_print_timings:        eval time =     347.08 ms /     3 runs   (  115.69 ms per token,     8.64 tokens per second)\n",
      "llama_print_timings:       total time =    1760.65 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4784.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2435.25 ms /   100 tokens (   24.35 ms per token,    41.06 tokens per second)\n",
      "llama_print_timings:        eval time =     241.90 ms /     2 runs   (  120.95 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =    2893.05 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     3 runs   (    0.28 ms per token,  3537.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1163.75 ms /    48 tokens (   24.24 ms per token,    41.25 tokens per second)\n",
      "llama_print_timings:        eval time =     235.61 ms /     2 runs   (  117.81 ms per token,     8.49 tokens per second)\n",
      "llama_print_timings:       total time =    1527.86 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.74 ms /     3 runs   (    0.25 ms per token,  4054.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1147.42 ms /    47 tokens (   24.41 ms per token,    40.96 tokens per second)\n",
      "llama_print_timings:        eval time =     232.44 ms /     2 runs   (  116.22 ms per token,     8.60 tokens per second)\n",
      "llama_print_timings:       total time =    1490.51 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     3 runs   (    0.26 ms per token,  3787.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.39 ms /    52 tokens (   24.01 ms per token,    41.65 tokens per second)\n",
      "llama_print_timings:        eval time =     244.70 ms /     2 runs   (  122.35 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =    1638.37 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     3 runs   (    0.28 ms per token,  3579.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1427.12 ms /    59 tokens (   24.19 ms per token,    41.34 tokens per second)\n",
      "llama_print_timings:        eval time =     236.99 ms /     2 runs   (  118.49 ms per token,     8.44 tokens per second)\n",
      "llama_print_timings:       total time =    1814.08 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     4 runs   (    0.22 ms per token,  4561.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1454.42 ms /    59 tokens (   24.65 ms per token,    40.57 tokens per second)\n",
      "llama_print_timings:        eval time =     349.10 ms /     3 runs   (  116.37 ms per token,     8.59 tokens per second)\n",
      "llama_print_timings:       total time =    1984.23 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     4 runs   (    0.22 ms per token,  4566.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1406.23 ms /    54 tokens (   26.04 ms per token,    38.40 tokens per second)\n",
      "llama_print_timings:        eval time =     323.12 ms /     3 runs   (  107.71 ms per token,     9.28 tokens per second)\n",
      "llama_print_timings:       total time =    1853.12 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /    16 runs   (    0.22 ms per token,  4581.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1416.07 ms /    54 tokens (   26.22 ms per token,    38.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1701.75 ms /    15 runs   (  113.45 ms per token,     8.81 tokens per second)\n",
      "llama_print_timings:       total time =    3328.67 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4950.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.68 ms /    47 tokens (   24.67 ms per token,    40.53 tokens per second)\n",
      "llama_print_timings:        eval time =     228.88 ms /     2 runs   (  114.44 ms per token,     8.74 tokens per second)\n",
      "llama_print_timings:       total time =    1495.75 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4784.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1058.27 ms /    40 tokens (   26.46 ms per token,    37.80 tokens per second)\n",
      "llama_print_timings:        eval time =     235.63 ms /     2 runs   (  117.82 ms per token,     8.49 tokens per second)\n",
      "llama_print_timings:       total time =    1389.56 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4687.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1745.85 ms /    49 tokens (   35.63 ms per token,    28.07 tokens per second)\n",
      "llama_print_timings:        eval time =     250.66 ms /     2 runs   (  125.33 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =    2139.96 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     3 runs   (    0.30 ms per token,  3322.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1988.41 ms /    59 tokens (   33.70 ms per token,    29.67 tokens per second)\n",
      "llama_print_timings:        eval time =     278.04 ms /     2 runs   (  139.02 ms per token,     7.19 tokens per second)\n",
      "llama_print_timings:       total time =    2414.23 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     4 runs   (    0.23 ms per token,  4444.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1608.31 ms /    53 tokens (   30.35 ms per token,    32.95 tokens per second)\n",
      "llama_print_timings:        eval time =     338.27 ms /     3 runs   (  112.76 ms per token,     8.87 tokens per second)\n",
      "llama_print_timings:       total time =    2084.34 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4643.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1450.57 ms /    61 tokens (   23.78 ms per token,    42.05 tokens per second)\n",
      "llama_print_timings:        eval time =     239.94 ms /     2 runs   (  119.97 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =    1858.93 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     4 runs   (    0.20 ms per token,  4932.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1054.22 ms /    42 tokens (   25.10 ms per token,    39.84 tokens per second)\n",
      "llama_print_timings:        eval time =     342.32 ms /     3 runs   (  114.11 ms per token,     8.76 tokens per second)\n",
      "llama_print_timings:       total time =    1496.22 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4792.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1057.36 ms /    42 tokens (   25.18 ms per token,    39.72 tokens per second)\n",
      "llama_print_timings:        eval time =     223.62 ms /     2 runs   (  111.81 ms per token,     8.94 tokens per second)\n",
      "llama_print_timings:       total time =    1379.39 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4322.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1226.64 ms /    48 tokens (   25.55 ms per token,    39.13 tokens per second)\n",
      "llama_print_timings:        eval time =     239.21 ms /     2 runs   (  119.61 ms per token,     8.36 tokens per second)\n",
      "llama_print_timings:       total time =    1583.40 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.57 ms /     3 runs   (    0.19 ms per token,  5244.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     889.89 ms /    34 tokens (   26.17 ms per token,    38.21 tokens per second)\n",
      "llama_print_timings:        eval time =     201.38 ms /     2 runs   (  100.69 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:       total time =    1172.13 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4477.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1476.23 ms /    56 tokens (   26.36 ms per token,    37.93 tokens per second)\n",
      "llama_print_timings:        eval time =     239.05 ms /     2 runs   (  119.52 ms per token,     8.37 tokens per second)\n",
      "llama_print_timings:       total time =    1863.20 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4792.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1092.07 ms /    44 tokens (   24.82 ms per token,    40.29 tokens per second)\n",
      "llama_print_timings:        eval time =     220.51 ms /     2 runs   (  110.25 ms per token,     9.07 tokens per second)\n",
      "llama_print_timings:       total time =    1411.86 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4291.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1068.93 ms /    41 tokens (   26.07 ms per token,    38.36 tokens per second)\n",
      "llama_print_timings:        eval time =     219.72 ms /     2 runs   (  109.86 ms per token,     9.10 tokens per second)\n",
      "llama_print_timings:       total time =    1384.46 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.73 ms /     3 runs   (    0.24 ms per token,  4126.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1132.54 ms /    42 tokens (   26.97 ms per token,    37.08 tokens per second)\n",
      "llama_print_timings:        eval time =     246.81 ms /     2 runs   (  123.41 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =    1497.46 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /     3 runs   (    0.24 ms per token,  4166.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1461.95 ms /    56 tokens (   26.11 ms per token,    38.31 tokens per second)\n",
      "llama_print_timings:        eval time =     224.42 ms /     2 runs   (  112.21 ms per token,     8.91 tokens per second)\n",
      "llama_print_timings:       total time =    1889.97 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       3.55 ms /    16 runs   (    0.22 ms per token,  4512.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1309.31 ms /    52 tokens (   25.18 ms per token,    39.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1701.65 ms /    15 runs   (  113.44 ms per token,     8.81 tokens per second)\n",
      "llama_print_timings:       total time =    3243.47 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     4 runs   (    0.21 ms per token,  4689.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1104.84 ms /    44 tokens (   25.11 ms per token,    39.82 tokens per second)\n",
      "llama_print_timings:        eval time =     346.69 ms /     3 runs   (  115.56 ms per token,     8.65 tokens per second)\n",
      "llama_print_timings:       total time =    1563.30 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       3.31 ms /    16 runs   (    0.21 ms per token,  4830.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1220.27 ms /    48 tokens (   25.42 ms per token,    39.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1664.65 ms /    15 runs   (  110.98 ms per token,     9.01 tokens per second)\n",
      "llama_print_timings:       total time =    3042.12 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     4 runs   (    0.22 ms per token,  4449.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1102.03 ms /    44 tokens (   25.05 ms per token,    39.93 tokens per second)\n",
      "llama_print_timings:        eval time =     349.25 ms /     3 runs   (  116.42 ms per token,     8.59 tokens per second)\n",
      "llama_print_timings:       total time =    1556.35 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4792.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1573.75 ms /    62 tokens (   25.38 ms per token,    39.40 tokens per second)\n",
      "llama_print_timings:        eval time =     227.62 ms /     2 runs   (  113.81 ms per token,     8.79 tokens per second)\n",
      "llama_print_timings:       total time =    1952.85 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4601.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1335.38 ms /    54 tokens (   24.73 ms per token,    40.44 tokens per second)\n",
      "llama_print_timings:        eval time =     243.59 ms /     2 runs   (  121.79 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =    1722.54 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.99 ms /     4 runs   (    0.25 ms per token,  4040.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1225.21 ms /    51 tokens (   24.02 ms per token,    41.63 tokens per second)\n",
      "llama_print_timings:        eval time =     341.24 ms /     3 runs   (  113.75 ms per token,     8.79 tokens per second)\n",
      "llama_print_timings:       total time =    1712.57 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     4 runs   (    0.23 ms per token,  4268.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1093.95 ms /    45 tokens (   24.31 ms per token,    41.14 tokens per second)\n",
      "llama_print_timings:        eval time =     368.68 ms /     3 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =    1582.58 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     4 runs   (    0.21 ms per token,  4750.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.64 ms /    48 tokens (   24.12 ms per token,    41.46 tokens per second)\n",
      "llama_print_timings:        eval time =     349.03 ms /     3 runs   (  116.34 ms per token,     8.60 tokens per second)\n",
      "llama_print_timings:       total time =    1623.09 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /     3 runs   (    0.24 ms per token,  4178.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1555.78 ms /    63 tokens (   24.69 ms per token,    40.49 tokens per second)\n",
      "llama_print_timings:        eval time =     223.45 ms /     2 runs   (  111.73 ms per token,     8.95 tokens per second)\n",
      "llama_print_timings:       total time =    1943.47 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.59 ms /     3 runs   (    0.20 ms per token,  5059.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     961.92 ms /    38 tokens (   25.31 ms per token,    39.50 tokens per second)\n",
      "llama_print_timings:        eval time =     207.70 ms /     2 runs   (  103.85 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    1258.89 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     4 runs   (    0.20 ms per token,  5056.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     966.12 ms /    36 tokens (   26.84 ms per token,    37.26 tokens per second)\n",
      "llama_print_timings:        eval time =     317.14 ms /     3 runs   (  105.71 ms per token,     9.46 tokens per second)\n",
      "llama_print_timings:       total time =    1370.95 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4636.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1142.56 ms /    45 tokens (   25.39 ms per token,    39.39 tokens per second)\n",
      "llama_print_timings:        eval time =     224.74 ms /     2 runs   (  112.37 ms per token,     8.90 tokens per second)\n",
      "llama_print_timings:       total time =    1473.07 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4680.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1124.61 ms /    44 tokens (   25.56 ms per token,    39.12 tokens per second)\n",
      "llama_print_timings:        eval time =     232.08 ms /     2 runs   (  116.04 ms per token,     8.62 tokens per second)\n",
      "llama_print_timings:       total time =    1462.32 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.73 ms /     3 runs   (    0.24 ms per token,  4092.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1331.24 ms /    55 tokens (   24.20 ms per token,    41.31 tokens per second)\n",
      "llama_print_timings:        eval time =     234.44 ms /     2 runs   (  117.22 ms per token,     8.53 tokens per second)\n",
      "llama_print_timings:       total time =    1715.25 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4347.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1134.54 ms /    46 tokens (   24.66 ms per token,    40.54 tokens per second)\n",
      "llama_print_timings:        eval time =     229.62 ms /     2 runs   (  114.81 ms per token,     8.71 tokens per second)\n",
      "llama_print_timings:       total time =    1473.85 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4615.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1073.91 ms /    42 tokens (   25.57 ms per token,    39.11 tokens per second)\n",
      "llama_print_timings:        eval time =     232.22 ms /     2 runs   (  116.11 ms per token,     8.61 tokens per second)\n",
      "llama_print_timings:       total time =    1407.43 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     4 runs   (    0.22 ms per token,  4576.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1183.94 ms /    48 tokens (   24.67 ms per token,    40.54 tokens per second)\n",
      "llama_print_timings:        eval time =     352.10 ms /     3 runs   (  117.37 ms per token,     8.52 tokens per second)\n",
      "llama_print_timings:       total time =    1661.76 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     3 runs   (    0.24 ms per token,  4243.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1842.30 ms /    72 tokens (   25.59 ms per token,    39.08 tokens per second)\n",
      "llama_print_timings:        eval time =     219.12 ms /     2 runs   (  109.56 ms per token,     9.13 tokens per second)\n",
      "llama_print_timings:       total time =    2222.16 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     3 runs   (    0.24 ms per token,  4213.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1015.10 ms /    41 tokens (   24.76 ms per token,    40.39 tokens per second)\n",
      "llama_print_timings:        eval time =     226.41 ms /     2 runs   (  113.20 ms per token,     8.83 tokens per second)\n",
      "llama_print_timings:       total time =    1334.69 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4918.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1067.93 ms /    41 tokens (   26.05 ms per token,    38.39 tokens per second)\n",
      "llama_print_timings:        eval time =     230.39 ms /     2 runs   (  115.20 ms per token,     8.68 tokens per second)\n",
      "llama_print_timings:       total time =    1392.27 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4497.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1214.21 ms /    49 tokens (   24.78 ms per token,    40.36 tokens per second)\n",
      "llama_print_timings:        eval time =     244.31 ms /     2 runs   (  122.15 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =    1575.56 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4846.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1115.91 ms /    44 tokens (   25.36 ms per token,    39.43 tokens per second)\n",
      "llama_print_timings:        eval time =     217.84 ms /     2 runs   (  108.92 ms per token,     9.18 tokens per second)\n",
      "llama_print_timings:       total time =    1437.84 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4754.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1460.47 ms /    60 tokens (   24.34 ms per token,    41.08 tokens per second)\n",
      "llama_print_timings:        eval time =     220.65 ms /     2 runs   (  110.33 ms per token,     9.06 tokens per second)\n",
      "llama_print_timings:       total time =    1835.34 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4807.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     986.37 ms /    39 tokens (   25.29 ms per token,    39.54 tokens per second)\n",
      "llama_print_timings:        eval time =     206.96 ms /     2 runs   (  103.48 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    1284.89 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1958.93 ms /    69 tokens (   28.39 ms per token,    35.22 tokens per second)\n",
      "llama_print_timings:        eval time =     232.82 ms /     2 runs   (  116.41 ms per token,     8.59 tokens per second)\n",
      "llama_print_timings:       total time =    2361.35 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.58 ms /     3 runs   (    0.19 ms per token,  5145.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     894.48 ms /    35 tokens (   25.56 ms per token,    39.13 tokens per second)\n",
      "llama_print_timings:        eval time =     203.24 ms /     2 runs   (  101.62 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    1178.39 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /     3 runs   (    0.25 ms per token,  3952.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1248.04 ms /    49 tokens (   25.47 ms per token,    39.26 tokens per second)\n",
      "llama_print_timings:        eval time =     248.82 ms /     2 runs   (  124.41 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =    1626.72 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.97 ms /     3 runs   (    0.32 ms per token,  3095.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1215.63 ms /    49 tokens (   24.81 ms per token,    40.31 tokens per second)\n",
      "llama_print_timings:        eval time =     228.43 ms /     2 runs   (  114.22 ms per token,     8.76 tokens per second)\n",
      "llama_print_timings:       total time =    1564.52 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4885.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1048.96 ms /    43 tokens (   24.39 ms per token,    40.99 tokens per second)\n",
      "llama_print_timings:        eval time =     224.58 ms /     2 runs   (  112.29 ms per token,     8.91 tokens per second)\n",
      "llama_print_timings:       total time =    1373.84 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4909.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1025.87 ms /    40 tokens (   25.65 ms per token,    38.99 tokens per second)\n",
      "llama_print_timings:        eval time =     214.93 ms /     2 runs   (  107.46 ms per token,     9.31 tokens per second)\n",
      "llama_print_timings:       total time =    1334.16 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       3.56 ms /    16 runs   (    0.22 ms per token,  4498.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1979.04 ms /    77 tokens (   25.70 ms per token,    38.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1714.64 ms /    15 runs   (  114.31 ms per token,     8.75 tokens per second)\n",
      "llama_print_timings:       total time =    3909.15 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     4 runs   (    0.21 ms per token,  4694.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     961.85 ms /    38 tokens (   25.31 ms per token,    39.51 tokens per second)\n",
      "llama_print_timings:        eval time =     316.20 ms /     3 runs   (  105.40 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =    1371.85 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.74 ms /     3 runs   (    0.25 ms per token,  4070.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1336.10 ms /    54 tokens (   24.74 ms per token,    40.42 tokens per second)\n",
      "llama_print_timings:        eval time =     248.41 ms /     2 runs   (  124.20 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =    1723.83 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4545.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1070.90 ms /    44 tokens (   24.34 ms per token,    41.09 tokens per second)\n",
      "llama_print_timings:        eval time =     231.85 ms /     2 runs   (  115.92 ms per token,     8.63 tokens per second)\n",
      "llama_print_timings:       total time =    1402.69 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     4 runs   (    0.22 ms per token,  4459.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1125.68 ms /    44 tokens (   25.58 ms per token,    39.09 tokens per second)\n",
      "llama_print_timings:        eval time =     348.15 ms /     3 runs   (  116.05 ms per token,     8.62 tokens per second)\n",
      "llama_print_timings:       total time =    1584.44 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4830.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1043.63 ms /    42 tokens (   24.85 ms per token,    40.24 tokens per second)\n",
      "llama_print_timings:        eval time =     232.86 ms /     2 runs   (  116.43 ms per token,     8.59 tokens per second)\n",
      "llama_print_timings:       total time =    1375.73 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  4975.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     990.08 ms /    37 tokens (   26.76 ms per token,    37.37 tokens per second)\n",
      "llama_print_timings:        eval time =     221.40 ms /     2 runs   (  110.70 ms per token,     9.03 tokens per second)\n",
      "llama_print_timings:       total time =    1296.24 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     4 runs   (    0.22 ms per token,  4540.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1028.27 ms /    39 tokens (   26.37 ms per token,    37.93 tokens per second)\n",
      "llama_print_timings:        eval time =     329.36 ms /     3 runs   (  109.79 ms per token,     9.11 tokens per second)\n",
      "llama_print_timings:       total time =    1451.88 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4846.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1125.08 ms /    44 tokens (   25.57 ms per token,    39.11 tokens per second)\n",
      "llama_print_timings:        eval time =     221.61 ms /     2 runs   (  110.81 ms per token,     9.02 tokens per second)\n",
      "llama_print_timings:       total time =    1449.86 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4504.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1277.63 ms /    52 tokens (   24.57 ms per token,    40.70 tokens per second)\n",
      "llama_print_timings:        eval time =     244.87 ms /     2 runs   (  122.44 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =    1651.01 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /    16 runs   (    0.21 ms per token,  4712.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1075.81 ms /    43 tokens (   25.02 ms per token,    39.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1596.58 ms /    15 runs   (  106.44 ms per token,     9.40 tokens per second)\n",
      "llama_print_timings:       total time =    2812.62 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     4 runs   (    0.20 ms per token,  4938.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     950.22 ms /    38 tokens (   25.01 ms per token,    39.99 tokens per second)\n",
      "llama_print_timings:        eval time =     325.02 ms /     3 runs   (  108.34 ms per token,     9.23 tokens per second)\n",
      "llama_print_timings:       total time =    1366.73 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4437.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1343.36 ms /    54 tokens (   24.88 ms per token,    40.20 tokens per second)\n",
      "llama_print_timings:        eval time =     246.50 ms /     2 runs   (  123.25 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =    1714.07 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.59 ms /     3 runs   (    0.20 ms per token,  5076.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     926.22 ms /    36 tokens (   25.73 ms per token,    38.87 tokens per second)\n",
      "llama_print_timings:        eval time =     203.85 ms /     2 runs   (  101.92 ms per token,     9.81 tokens per second)\n",
      "llama_print_timings:       total time =    1213.38 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4823.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1149.07 ms /    44 tokens (   26.12 ms per token,    38.29 tokens per second)\n",
      "llama_print_timings:        eval time =     244.43 ms /     2 runs   (  122.21 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =    1499.20 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     4 runs   (    0.23 ms per token,  4291.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1220.98 ms /    48 tokens (   25.44 ms per token,    39.31 tokens per second)\n",
      "llama_print_timings:        eval time =     359.76 ms /     3 runs   (  119.92 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =    1723.08 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4800.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1191.12 ms /    49 tokens (   24.31 ms per token,    41.14 tokens per second)\n",
      "llama_print_timings:        eval time =     231.05 ms /     2 runs   (  115.52 ms per token,     8.66 tokens per second)\n",
      "llama_print_timings:       total time =    1545.26 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /    16 runs   (    0.21 ms per token,  4697.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     955.49 ms /    37 tokens (   25.82 ms per token,    38.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1600.49 ms /    15 runs   (  106.70 ms per token,     9.37 tokens per second)\n",
      "llama_print_timings:       total time =    2685.06 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     4 runs   (    0.20 ms per token,  4987.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     933.24 ms /    36 tokens (   25.92 ms per token,    38.58 tokens per second)\n",
      "llama_print_timings:        eval time =     313.62 ms /     3 runs   (  104.54 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    1334.52 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     4 runs   (    0.22 ms per token,  4524.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1104.77 ms /    42 tokens (   26.30 ms per token,    38.02 tokens per second)\n",
      "llama_print_timings:        eval time =     338.35 ms /     3 runs   (  112.78 ms per token,     8.87 tokens per second)\n",
      "llama_print_timings:       total time =    1549.24 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       3.67 ms /    16 runs   (    0.23 ms per token,  4364.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1259.61 ms /    52 tokens (   24.22 ms per token,    41.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1663.74 ms /    15 runs   (  110.92 ms per token,     9.02 tokens per second)\n",
      "llama_print_timings:       total time =    3087.79 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4878.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1047.41 ms /    42 tokens (   24.94 ms per token,    40.10 tokens per second)\n",
      "llama_print_timings:        eval time =     212.27 ms /     2 runs   (  106.13 ms per token,     9.42 tokens per second)\n",
      "llama_print_timings:       total time =    1356.52 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.58 ms /     3 runs   (    0.19 ms per token,  5163.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     912.79 ms /    33 tokens (   27.66 ms per token,    36.15 tokens per second)\n",
      "llama_print_timings:        eval time =     205.83 ms /     2 runs   (  102.91 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    1197.25 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     4 runs   (    0.21 ms per token,  4662.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1305.04 ms /    54 tokens (   24.17 ms per token,    41.38 tokens per second)\n",
      "llama_print_timings:        eval time =     342.84 ms /     3 runs   (  114.28 ms per token,     8.75 tokens per second)\n",
      "llama_print_timings:       total time =    1775.86 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4608.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1452.70 ms /    60 tokens (   24.21 ms per token,    41.30 tokens per second)\n",
      "llama_print_timings:        eval time =     220.91 ms /     2 runs   (  110.45 ms per token,     9.05 tokens per second)\n",
      "llama_print_timings:       total time =    1832.94 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4304.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1972.50 ms /    78 tokens (   25.29 ms per token,    39.54 tokens per second)\n",
      "llama_print_timings:        eval time =     223.01 ms /     2 runs   (  111.50 ms per token,     8.97 tokens per second)\n",
      "llama_print_timings:       total time =    2376.63 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     4 runs   (    0.22 ms per token,  4629.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     982.27 ms /    38 tokens (   25.85 ms per token,    38.69 tokens per second)\n",
      "llama_print_timings:        eval time =     328.45 ms /     3 runs   (  109.48 ms per token,     9.13 tokens per second)\n",
      "llama_print_timings:       total time =    1402.49 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       3.62 ms /    16 runs   (    0.23 ms per token,  4423.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1067.24 ms /    42 tokens (   25.41 ms per token,    39.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1580.68 ms /    15 runs   (  105.38 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =    2797.00 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4392.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1123.14 ms /    46 tokens (   24.42 ms per token,    40.96 tokens per second)\n",
      "llama_print_timings:        eval time =     231.93 ms /     2 runs   (  115.97 ms per token,     8.62 tokens per second)\n",
      "llama_print_timings:       total time =    1462.21 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  5000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1018.16 ms /    39 tokens (   26.11 ms per token,    38.30 tokens per second)\n",
      "llama_print_timings:        eval time =     224.72 ms /     2 runs   (  112.36 ms per token,     8.90 tokens per second)\n",
      "llama_print_timings:       total time =    1333.42 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.74 ms /     3 runs   (    0.25 ms per token,  4043.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1266.31 ms /    50 tokens (   25.33 ms per token,    39.48 tokens per second)\n",
      "llama_print_timings:        eval time =     251.26 ms /     2 runs   (  125.63 ms per token,     7.96 tokens per second)\n",
      "llama_print_timings:       total time =    1641.43 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /    16 runs   (    0.22 ms per token,  4581.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.13 ms /    51 tokens (   24.67 ms per token,    40.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1669.62 ms /    15 runs   (  111.31 ms per token,     8.98 tokens per second)\n",
      "llama_print_timings:       total time =    3109.39 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4573.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2110.99 ms /    85 tokens (   24.84 ms per token,    40.27 tokens per second)\n",
      "llama_print_timings:        eval time =     220.52 ms /     2 runs   (  110.26 ms per token,     9.07 tokens per second)\n",
      "llama_print_timings:       total time =    2524.60 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4950.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     977.02 ms /    39 tokens (   25.05 ms per token,    39.92 tokens per second)\n",
      "llama_print_timings:        eval time =     212.48 ms /     2 runs   (  106.24 ms per token,     9.41 tokens per second)\n",
      "llama_print_timings:       total time =    1280.15 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     3 runs   (    0.27 ms per token,  3703.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1264.52 ms /    49 tokens (   25.81 ms per token,    38.75 tokens per second)\n",
      "llama_print_timings:        eval time =     244.84 ms /     2 runs   (  122.42 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =    1635.25 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4680.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1054.10 ms /    42 tokens (   25.10 ms per token,    39.84 tokens per second)\n",
      "llama_print_timings:        eval time =     232.39 ms /     2 runs   (  116.19 ms per token,     8.61 tokens per second)\n",
      "llama_print_timings:       total time =    1382.23 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4815.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1078.19 ms /    42 tokens (   25.67 ms per token,    38.95 tokens per second)\n",
      "llama_print_timings:        eval time =     221.32 ms /     2 runs   (  110.66 ms per token,     9.04 tokens per second)\n",
      "llama_print_timings:       total time =    1395.22 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  5008.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1040.13 ms /    39 tokens (   26.67 ms per token,    37.50 tokens per second)\n",
      "llama_print_timings:        eval time =     213.34 ms /     2 runs   (  106.67 ms per token,     9.37 tokens per second)\n",
      "llama_print_timings:       total time =    1344.79 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4754.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1153.53 ms /    45 tokens (   25.63 ms per token,    39.01 tokens per second)\n",
      "llama_print_timings:        eval time =     233.24 ms /     2 runs   (  116.62 ms per token,     8.57 tokens per second)\n",
      "llama_print_timings:       total time =    1490.81 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       3.58 ms /    16 runs   (    0.22 ms per token,  4463.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1308.58 ms /    53 tokens (   24.69 ms per token,    40.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1680.59 ms /    15 runs   (  112.04 ms per token,     8.93 tokens per second)\n",
      "llama_print_timings:       total time =    3160.28 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4261.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1237.81 ms /    52 tokens (   23.80 ms per token,    42.01 tokens per second)\n",
      "llama_print_timings:        eval time =     240.25 ms /     2 runs   (  120.13 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =    1602.83 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /     3 runs   (    0.24 ms per token,  4155.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1367.96 ms /    55 tokens (   24.87 ms per token,    40.21 tokens per second)\n",
      "llama_print_timings:        eval time =     213.53 ms /     2 runs   (  106.77 ms per token,     9.37 tokens per second)\n",
      "llama_print_timings:       total time =    1743.25 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4702.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1821.51 ms /    70 tokens (   26.02 ms per token,    38.43 tokens per second)\n",
      "llama_print_timings:        eval time =     223.42 ms /     2 runs   (  111.71 ms per token,     8.95 tokens per second)\n",
      "llama_print_timings:       total time =    2202.73 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     4 runs   (    0.21 ms per token,  4878.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     992.91 ms /    40 tokens (   24.82 ms per token,    40.29 tokens per second)\n",
      "llama_print_timings:        eval time =     339.69 ms /     3 runs   (  113.23 ms per token,     8.83 tokens per second)\n",
      "llama_print_timings:       total time =    1428.27 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /     3 runs   (    0.24 ms per token,  4184.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1315.22 ms /    54 tokens (   24.36 ms per token,    41.06 tokens per second)\n",
      "llama_print_timings:        eval time =     221.27 ms /     2 runs   (  110.63 ms per token,     9.04 tokens per second)\n",
      "llama_print_timings:       total time =    1697.30 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.98 ms /     4 runs   (    0.25 ms per token,  4077.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1075.95 ms /    44 tokens (   24.45 ms per token,    40.89 tokens per second)\n",
      "llama_print_timings:        eval time =     356.43 ms /     3 runs   (  118.81 ms per token,     8.42 tokens per second)\n",
      "llama_print_timings:       total time =    1540.09 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     4 runs   (    0.22 ms per token,  4634.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1000.89 ms /    39 tokens (   25.66 ms per token,    38.97 tokens per second)\n",
      "llama_print_timings:        eval time =     354.36 ms /     3 runs   (  118.12 ms per token,     8.47 tokens per second)\n",
      "llama_print_timings:       total time =    1453.14 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     4 runs   (    0.21 ms per token,  4842.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1188.70 ms /    49 tokens (   24.26 ms per token,    41.22 tokens per second)\n",
      "llama_print_timings:        eval time =     342.86 ms /     3 runs   (  114.29 ms per token,     8.75 tokens per second)\n",
      "llama_print_timings:       total time =    1664.21 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4573.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1351.64 ms /    55 tokens (   24.58 ms per token,    40.69 tokens per second)\n",
      "llama_print_timings:        eval time =     222.90 ms /     2 runs   (  111.45 ms per token,     8.97 tokens per second)\n",
      "llama_print_timings:       total time =    1722.04 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       3.76 ms /    16 runs   (    0.24 ms per token,  4253.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.11 ms /    52 tokens (   23.85 ms per token,    41.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1671.99 ms /    15 runs   (  111.47 ms per token,     8.97 tokens per second)\n",
      "llama_print_timings:       total time =    3074.45 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /     3 runs   (    0.25 ms per token,  3968.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.23 ms /    49 tokens (   23.84 ms per token,    41.94 tokens per second)\n",
      "llama_print_timings:        eval time =     234.08 ms /     2 runs   (  117.04 ms per token,     8.54 tokens per second)\n",
      "llama_print_timings:       total time =    1520.79 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     4 runs   (    0.23 ms per token,  4434.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1085.30 ms /    43 tokens (   25.24 ms per token,    39.62 tokens per second)\n",
      "llama_print_timings:        eval time =     351.75 ms /     3 runs   (  117.25 ms per token,     8.53 tokens per second)\n",
      "llama_print_timings:       total time =    1541.89 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4854.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1080.31 ms /    44 tokens (   24.55 ms per token,    40.73 tokens per second)\n",
      "llama_print_timings:        eval time =     240.06 ms /     2 runs   (  120.03 ms per token,     8.33 tokens per second)\n",
      "llama_print_timings:       total time =    1422.40 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /     3 runs   (    0.25 ms per token,  3926.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.90 ms /    48 tokens (   24.44 ms per token,    40.92 tokens per second)\n",
      "llama_print_timings:        eval time =     246.31 ms /     2 runs   (  123.16 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =    1543.06 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4601.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1210.14 ms /    49 tokens (   24.70 ms per token,    40.49 tokens per second)\n",
      "llama_print_timings:        eval time =     243.52 ms /     2 runs   (  121.76 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =    1574.67 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  4975.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1020.10 ms /    40 tokens (   25.50 ms per token,    39.21 tokens per second)\n",
      "llama_print_timings:        eval time =     213.72 ms /     2 runs   (  106.86 ms per token,     9.36 tokens per second)\n",
      "llama_print_timings:       total time =    1326.26 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.73 ms /     3 runs   (    0.24 ms per token,  4115.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1145.86 ms /    45 tokens (   25.46 ms per token,    39.27 tokens per second)\n",
      "llama_print_timings:        eval time =     245.93 ms /     2 runs   (  122.97 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =    1504.02 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  5016.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     986.47 ms /    38 tokens (   25.96 ms per token,    38.52 tokens per second)\n",
      "llama_print_timings:        eval time =     215.68 ms /     2 runs   (  107.84 ms per token,     9.27 tokens per second)\n",
      "llama_print_timings:       total time =    1290.09 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     4 runs   (    0.22 ms per token,  4524.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1037.80 ms /    39 tokens (   26.61 ms per token,    37.58 tokens per second)\n",
      "llama_print_timings:        eval time =     325.22 ms /     3 runs   (  108.41 ms per token,     9.22 tokens per second)\n",
      "llama_print_timings:       total time =    1457.22 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     3 runs   (    0.27 ms per token,  3694.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1384.08 ms /    57 tokens (   24.28 ms per token,    41.18 tokens per second)\n",
      "llama_print_timings:        eval time =     228.36 ms /     2 runs   (  114.18 ms per token,     8.76 tokens per second)\n",
      "llama_print_timings:       total time =    1780.40 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /     3 runs   (    0.24 ms per token,  4143.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1110.13 ms /    46 tokens (   24.13 ms per token,    41.44 tokens per second)\n",
      "llama_print_timings:        eval time =     225.95 ms /     2 runs   (  112.97 ms per token,     8.85 tokens per second)\n",
      "llama_print_timings:       total time =    1444.14 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     4 runs   (    0.22 ms per token,  4524.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.53 ms /    56 tokens (   24.60 ms per token,    40.65 tokens per second)\n",
      "llama_print_timings:        eval time =     337.18 ms /     3 runs   (  112.39 ms per token,     8.90 tokens per second)\n",
      "llama_print_timings:       total time =    1875.03 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4559.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.96 ms /    47 tokens (   24.51 ms per token,    40.80 tokens per second)\n",
      "llama_print_timings:        eval time =     238.41 ms /     2 runs   (  119.20 ms per token,     8.39 tokens per second)\n",
      "llama_print_timings:       total time =    1513.97 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     4 runs   (    0.20 ms per token,  5102.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     849.05 ms /    32 tokens (   26.53 ms per token,    37.69 tokens per second)\n",
      "llama_print_timings:        eval time =     320.80 ms /     3 runs   (  106.93 ms per token,     9.35 tokens per second)\n",
      "llama_print_timings:       total time =    1252.96 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4335.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1355.08 ms /    55 tokens (   24.64 ms per token,    40.59 tokens per second)\n",
      "llama_print_timings:        eval time =     250.01 ms /     2 runs   (  125.01 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =    1739.37 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4622.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     929.84 ms /    36 tokens (   25.83 ms per token,    38.72 tokens per second)\n",
      "llama_print_timings:        eval time =     204.78 ms /     2 runs   (  102.39 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =    1218.31 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     4 runs   (    0.23 ms per token,  4338.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1284.07 ms /    51 tokens (   25.18 ms per token,    39.72 tokens per second)\n",
      "llama_print_timings:        eval time =     369.09 ms /     3 runs   (  123.03 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =    1791.02 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     4 runs   (    0.20 ms per token,  4907.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     945.89 ms /    37 tokens (   25.56 ms per token,    39.12 tokens per second)\n",
      "llama_print_timings:        eval time =     335.13 ms /     3 runs   (  111.71 ms per token,     8.95 tokens per second)\n",
      "llama_print_timings:       total time =    1369.25 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4366.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1286.49 ms /    52 tokens (   24.74 ms per token,    40.42 tokens per second)\n",
      "llama_print_timings:        eval time =     227.19 ms /     2 runs   (  113.59 ms per token,     8.80 tokens per second)\n",
      "llama_print_timings:       total time =    1672.55 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     3 runs   (    0.27 ms per token,  3676.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1451.61 ms /    56 tokens (   25.92 ms per token,    38.58 tokens per second)\n",
      "llama_print_timings:        eval time =     239.29 ms /     2 runs   (  119.64 ms per token,     8.36 tokens per second)\n",
      "llama_print_timings:       total time =    1944.56 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       4.10 ms /    16 runs   (    0.26 ms per token,  3900.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1211.38 ms /    44 tokens (   27.53 ms per token,    36.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1770.66 ms /    15 runs   (  118.04 ms per token,     8.47 tokens per second)\n",
      "llama_print_timings:       total time =    3236.85 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4672.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     920.77 ms /    34 tokens (   27.08 ms per token,    36.93 tokens per second)\n",
      "llama_print_timings:        eval time =     207.71 ms /     2 runs   (  103.86 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    1210.93 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4373.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1307.25 ms /    52 tokens (   25.14 ms per token,    39.78 tokens per second)\n",
      "llama_print_timings:        eval time =     246.25 ms /     2 runs   (  123.13 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =    1682.29 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       3.61 ms /    16 runs   (    0.23 ms per token,  4428.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1729.68 ms /    65 tokens (   26.61 ms per token,    37.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1674.53 ms /    15 runs   (  111.64 ms per token,     8.96 tokens per second)\n",
      "llama_print_timings:       total time =    3590.35 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     3 runs   (    0.24 ms per token,  4195.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1218.00 ms /    51 tokens (   23.88 ms per token,    41.87 tokens per second)\n",
      "llama_print_timings:        eval time =     244.62 ms /     2 runs   (  122.31 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =    1602.24 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     4 runs   (    0.20 ms per token,  4884.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1048.34 ms /    42 tokens (   24.96 ms per token,    40.06 tokens per second)\n",
      "llama_print_timings:        eval time =     353.38 ms /     3 runs   (  117.79 ms per token,     8.49 tokens per second)\n",
      "llama_print_timings:       total time =    1503.86 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4491.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1506.02 ms /    61 tokens (   24.69 ms per token,    40.50 tokens per second)\n",
      "llama_print_timings:        eval time =     219.10 ms /     2 runs   (  109.55 ms per token,     9.13 tokens per second)\n",
      "llama_print_timings:       total time =    1870.62 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4360.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1138.37 ms /    47 tokens (   24.22 ms per token,    41.29 tokens per second)\n",
      "llama_print_timings:        eval time =     250.15 ms /     2 runs   (  125.07 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =    1500.03 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /     3 runs   (    0.25 ms per token,  3957.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1224.91 ms /    50 tokens (   24.50 ms per token,    40.82 tokens per second)\n",
      "llama_print_timings:        eval time =     230.41 ms /     2 runs   (  115.20 ms per token,     8.68 tokens per second)\n",
      "llama_print_timings:       total time =    1582.01 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4431.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     995.88 ms /    39 tokens (   25.54 ms per token,    39.16 tokens per second)\n",
      "llama_print_timings:        eval time =     231.66 ms /     2 runs   (  115.83 ms per token,     8.63 tokens per second)\n",
      "llama_print_timings:       total time =    1320.13 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     4 runs   (    0.21 ms per token,  4672.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1304.52 ms /    53 tokens (   24.61 ms per token,    40.63 tokens per second)\n",
      "llama_print_timings:        eval time =     349.98 ms /     3 runs   (  116.66 ms per token,     8.57 tokens per second)\n",
      "llama_print_timings:       total time =    1784.60 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4451.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.25 ms /    52 tokens (   24.10 ms per token,    41.49 tokens per second)\n",
      "llama_print_timings:        eval time =     249.80 ms /     2 runs   (  124.90 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =    1629.50 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4893.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1003.55 ms /    40 tokens (   25.09 ms per token,    39.86 tokens per second)\n",
      "llama_print_timings:        eval time =     230.07 ms /     2 runs   (  115.04 ms per token,     8.69 tokens per second)\n",
      "llama_print_timings:       total time =    1326.76 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4580.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1548.10 ms /    62 tokens (   24.97 ms per token,    40.05 tokens per second)\n",
      "llama_print_timings:        eval time =     226.83 ms /     2 runs   (  113.41 ms per token,     8.82 tokens per second)\n",
      "llama_print_timings:       total time =    1945.50 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /     3 runs   (    0.25 ms per token,  3947.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1350.35 ms /    56 tokens (   24.11 ms per token,    41.47 tokens per second)\n",
      "llama_print_timings:        eval time =     250.10 ms /     2 runs   (  125.05 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =    1747.14 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  4975.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     958.06 ms /    38 tokens (   25.21 ms per token,    39.66 tokens per second)\n",
      "llama_print_timings:        eval time =     209.82 ms /     2 runs   (  104.91 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    1257.17 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     4 runs   (    0.24 ms per token,  4223.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1388.29 ms /    55 tokens (   25.24 ms per token,    39.62 tokens per second)\n",
      "llama_print_timings:        eval time =     339.41 ms /     3 runs   (  113.14 ms per token,     8.84 tokens per second)\n",
      "llama_print_timings:       total time =    1869.66 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4815.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1061.64 ms /    43 tokens (   24.69 ms per token,    40.50 tokens per second)\n",
      "llama_print_timings:        eval time =     232.13 ms /     2 runs   (  116.06 ms per token,     8.62 tokens per second)\n",
      "llama_print_timings:       total time =    1394.93 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4658.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.20 ms /    47 tokens (   24.98 ms per token,    40.03 tokens per second)\n",
      "llama_print_timings:        eval time =     232.14 ms /     2 runs   (  116.07 ms per token,     8.62 tokens per second)\n",
      "llama_print_timings:       total time =    1532.65 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4854.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1030.73 ms /    41 tokens (   25.14 ms per token,    39.78 tokens per second)\n",
      "llama_print_timings:        eval time =     238.13 ms /     2 runs   (  119.06 ms per token,     8.40 tokens per second)\n",
      "llama_print_timings:       total time =    1364.22 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4800.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1193.29 ms /    47 tokens (   25.39 ms per token,    39.39 tokens per second)\n",
      "llama_print_timings:        eval time =     234.42 ms /     2 runs   (  117.21 ms per token,     8.53 tokens per second)\n",
      "llama_print_timings:       total time =    1555.78 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4545.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1750.83 ms /    66 tokens (   26.53 ms per token,    37.70 tokens per second)\n",
      "llama_print_timings:        eval time =     224.91 ms /     2 runs   (  112.45 ms per token,     8.89 tokens per second)\n",
      "llama_print_timings:       total time =    2120.48 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     4 runs   (    0.21 ms per token,  4678.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     940.44 ms /    37 tokens (   25.42 ms per token,    39.34 tokens per second)\n",
      "llama_print_timings:        eval time =     331.25 ms /     3 runs   (  110.42 ms per token,     9.06 tokens per second)\n",
      "llama_print_timings:       total time =    1361.21 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4622.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1560.15 ms /    62 tokens (   25.16 ms per token,    39.74 tokens per second)\n",
      "llama_print_timings:        eval time =     219.82 ms /     2 runs   (  109.91 ms per token,     9.10 tokens per second)\n",
      "llama_print_timings:       total time =    1937.36 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4731.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1068.30 ms /    43 tokens (   24.84 ms per token,    40.25 tokens per second)\n",
      "llama_print_timings:        eval time =     231.77 ms /     2 runs   (  115.89 ms per token,     8.63 tokens per second)\n",
      "llama_print_timings:       total time =    1399.41 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4545.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1399.76 ms /    56 tokens (   25.00 ms per token,    40.01 tokens per second)\n",
      "llama_print_timings:        eval time =     236.56 ms /     2 runs   (  118.28 ms per token,     8.45 tokens per second)\n",
      "llama_print_timings:       total time =    1791.00 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.74 ms /     3 runs   (    0.25 ms per token,  4065.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1337.52 ms /    56 tokens (   23.88 ms per token,    41.87 tokens per second)\n",
      "llama_print_timings:        eval time =     251.38 ms /     2 runs   (  125.69 ms per token,     7.96 tokens per second)\n",
      "llama_print_timings:       total time =    1730.67 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4665.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.16 ms /    48 tokens (   24.11 ms per token,    41.48 tokens per second)\n",
      "llama_print_timings:        eval time =     235.01 ms /     2 runs   (  117.50 ms per token,     8.51 tokens per second)\n",
      "llama_print_timings:       total time =    1509.58 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4566.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1207.12 ms /    49 tokens (   24.64 ms per token,    40.59 tokens per second)\n",
      "llama_print_timings:        eval time =     245.52 ms /     2 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =    1577.65 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     3 runs   (    0.26 ms per token,  3861.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1244.55 ms /    51 tokens (   24.40 ms per token,    40.98 tokens per second)\n",
      "llama_print_timings:        eval time =     234.35 ms /     2 runs   (  117.18 ms per token,     8.53 tokens per second)\n",
      "llama_print_timings:       total time =    1611.82 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /    16 runs   (    0.22 ms per token,  4588.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1180.88 ms /    49 tokens (   24.10 ms per token,    41.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1654.75 ms /    15 runs   (  110.32 ms per token,     9.06 tokens per second)\n",
      "llama_print_timings:       total time =    3016.30 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /    16 runs   (    0.21 ms per token,  4663.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1006.15 ms /    40 tokens (   25.15 ms per token,    39.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1593.83 ms /    15 runs   (  106.26 ms per token,     9.41 tokens per second)\n",
      "llama_print_timings:       total time =    2732.68 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4431.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     977.15 ms /    39 tokens (   25.06 ms per token,    39.91 tokens per second)\n",
      "llama_print_timings:        eval time =     214.94 ms /     2 runs   (  107.47 ms per token,     9.31 tokens per second)\n",
      "llama_print_timings:       total time =    1284.35 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4437.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1186.29 ms /    46 tokens (   25.79 ms per token,    38.78 tokens per second)\n",
      "llama_print_timings:        eval time =     234.00 ms /     2 runs   (  117.00 ms per token,     8.55 tokens per second)\n",
      "llama_print_timings:       total time =    1534.35 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.97 ms /     4 runs   (    0.24 ms per token,  4115.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1004.25 ms /    39 tokens (   25.75 ms per token,    38.83 tokens per second)\n",
      "llama_print_timings:        eval time =     327.60 ms /     3 runs   (  109.20 ms per token,     9.16 tokens per second)\n",
      "llama_print_timings:       total time =    1429.85 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.75 ms /     3 runs   (    0.25 ms per token,  4016.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1265.33 ms /    52 tokens (   24.33 ms per token,    41.10 tokens per second)\n",
      "llama_print_timings:        eval time =     233.05 ms /     2 runs   (  116.52 ms per token,     8.58 tokens per second)\n",
      "llama_print_timings:       total time =    1642.63 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4347.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1197.39 ms /    50 tokens (   23.95 ms per token,    41.76 tokens per second)\n",
      "llama_print_timings:        eval time =     241.83 ms /     2 runs   (  120.92 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =    1564.61 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4405.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1405.59 ms /    57 tokens (   24.66 ms per token,    40.55 tokens per second)\n",
      "llama_print_timings:        eval time =     237.06 ms /     2 runs   (  118.53 ms per token,     8.44 tokens per second)\n",
      "llama_print_timings:       total time =    1804.42 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       3.75 ms /    16 runs   (    0.23 ms per token,  4262.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.11 ms /    52 tokens (   24.18 ms per token,    41.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1676.27 ms /    15 runs   (  111.75 ms per token,     8.95 tokens per second)\n",
      "llama_print_timings:       total time =    3102.18 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4418.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1111.33 ms /    46 tokens (   24.16 ms per token,    41.39 tokens per second)\n",
      "llama_print_timings:        eval time =     233.28 ms /     2 runs   (  116.64 ms per token,     8.57 tokens per second)\n",
      "llama_print_timings:       total time =    1448.51 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     4 runs   (    0.21 ms per token,  4750.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1838.19 ms /    68 tokens (   27.03 ms per token,    36.99 tokens per second)\n",
      "llama_print_timings:        eval time =     330.52 ms /     3 runs   (  110.17 ms per token,     9.08 tokens per second)\n",
      "llama_print_timings:       total time =    2322.45 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4731.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1521.34 ms /    62 tokens (   24.54 ms per token,    40.75 tokens per second)\n",
      "llama_print_timings:        eval time =     220.58 ms /     2 runs   (  110.29 ms per token,     9.07 tokens per second)\n",
      "llama_print_timings:       total time =    1905.64 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4518.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1105.17 ms /    45 tokens (   24.56 ms per token,    40.72 tokens per second)\n",
      "llama_print_timings:        eval time =     238.48 ms /     2 runs   (  119.24 ms per token,     8.39 tokens per second)\n",
      "llama_print_timings:       total time =    1449.68 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4497.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1392.53 ms /    57 tokens (   24.43 ms per token,    40.93 tokens per second)\n",
      "llama_print_timings:        eval time =     233.62 ms /     2 runs   (  116.81 ms per token,     8.56 tokens per second)\n",
      "llama_print_timings:       total time =    1782.03 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       1.04 ms /     4 runs   (    0.26 ms per token,  3835.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1020.03 ms /    41 tokens (   24.88 ms per token,    40.19 tokens per second)\n",
      "llama_print_timings:        eval time =     347.17 ms /     3 runs   (  115.72 ms per token,     8.64 tokens per second)\n",
      "llama_print_timings:       total time =    1475.65 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4329.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1289.15 ms /    53 tokens (   24.32 ms per token,    41.11 tokens per second)\n",
      "llama_print_timings:        eval time =     222.80 ms /     2 runs   (  111.40 ms per token,     8.98 tokens per second)\n",
      "llama_print_timings:       total time =    1657.07 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     4 runs   (    0.20 ms per token,  4950.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     890.33 ms /    34 tokens (   26.19 ms per token,    38.19 tokens per second)\n",
      "llama_print_timings:        eval time =     321.97 ms /     3 runs   (  107.32 ms per token,     9.32 tokens per second)\n",
      "llama_print_timings:       total time =    1296.14 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       1.08 ms /     3 runs   (    0.36 ms per token,  2772.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1213.32 ms /    48 tokens (   25.28 ms per token,    39.56 tokens per second)\n",
      "llama_print_timings:        eval time =     240.46 ms /     2 runs   (  120.23 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =    1567.59 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4629.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1936.38 ms /    76 tokens (   25.48 ms per token,    39.25 tokens per second)\n",
      "llama_print_timings:        eval time =     219.90 ms /     2 runs   (  109.95 ms per token,     9.10 tokens per second)\n",
      "llama_print_timings:       total time =    2328.39 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4341.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1832.43 ms /    71 tokens (   25.81 ms per token,    38.75 tokens per second)\n",
      "llama_print_timings:        eval time =     224.97 ms /     2 runs   (  112.49 ms per token,     8.89 tokens per second)\n",
      "llama_print_timings:       total time =    2224.78 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     3 runs   (    0.26 ms per token,  3880.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1111.24 ms /    46 tokens (   24.16 ms per token,    41.40 tokens per second)\n",
      "llama_print_timings:        eval time =     231.62 ms /     2 runs   (  115.81 ms per token,     8.64 tokens per second)\n",
      "llama_print_timings:       total time =    1456.48 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4511.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1191.41 ms /    48 tokens (   24.82 ms per token,    40.29 tokens per second)\n",
      "llama_print_timings:        eval time =     236.74 ms /     2 runs   (  118.37 ms per token,     8.45 tokens per second)\n",
      "llama_print_timings:       total time =    1540.11 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4291.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.89 ms /    48 tokens (   24.23 ms per token,    41.28 tokens per second)\n",
      "llama_print_timings:        eval time =     244.13 ms /     2 runs   (  122.07 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =    1549.74 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4545.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1385.78 ms /    56 tokens (   24.75 ms per token,    40.41 tokens per second)\n",
      "llama_print_timings:        eval time =     226.12 ms /     2 runs   (  113.06 ms per token,     8.84 tokens per second)\n",
      "llama_print_timings:       total time =    1774.63 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     3 runs   (    0.24 ms per token,  4225.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1232.50 ms /    52 tokens (   23.70 ms per token,    42.19 tokens per second)\n",
      "llama_print_timings:        eval time =     238.46 ms /     2 runs   (  119.23 ms per token,     8.39 tokens per second)\n",
      "llama_print_timings:       total time =    1605.78 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4608.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1569.16 ms /    64 tokens (   24.52 ms per token,    40.79 tokens per second)\n",
      "llama_print_timings:        eval time =     221.57 ms /     2 runs   (  110.78 ms per token,     9.03 tokens per second)\n",
      "llama_print_timings:       total time =    1950.30 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4531.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1047.79 ms /    42 tokens (   24.95 ms per token,    40.08 tokens per second)\n",
      "llama_print_timings:        eval time =     233.50 ms /     2 runs   (  116.75 ms per token,     8.57 tokens per second)\n",
      "llama_print_timings:       total time =    1384.78 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4862.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1071.74 ms /    41 tokens (   26.14 ms per token,    38.26 tokens per second)\n",
      "llama_print_timings:        eval time =     225.24 ms /     2 runs   (  112.62 ms per token,     8.88 tokens per second)\n",
      "llama_print_timings:       total time =    1394.21 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4310.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1528.64 ms /    62 tokens (   24.66 ms per token,    40.56 tokens per second)\n",
      "llama_print_timings:        eval time =     223.82 ms /     2 runs   (  111.91 ms per token,     8.94 tokens per second)\n",
      "llama_print_timings:       total time =    1925.64 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /     3 runs   (    0.25 ms per token,  3968.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1148.08 ms /    46 tokens (   24.96 ms per token,    40.07 tokens per second)\n",
      "llama_print_timings:        eval time =     231.87 ms /     2 runs   (  115.93 ms per token,     8.63 tokens per second)\n",
      "llama_print_timings:       total time =    1509.42 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4580.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1620.99 ms /    61 tokens (   26.57 ms per token,    37.63 tokens per second)\n",
      "llama_print_timings:        eval time =     227.48 ms /     2 runs   (  113.74 ms per token,     8.79 tokens per second)\n",
      "llama_print_timings:       total time =    2001.75 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4279.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1384.82 ms /    57 tokens (   24.30 ms per token,    41.16 tokens per second)\n",
      "llama_print_timings:        eval time =     236.45 ms /     2 runs   (  118.22 ms per token,     8.46 tokens per second)\n",
      "llama_print_timings:       total time =    1767.72 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /     3 runs   (    0.24 ms per token,  4160.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1316.48 ms /    55 tokens (   23.94 ms per token,    41.78 tokens per second)\n",
      "llama_print_timings:        eval time =     249.40 ms /     2 runs   (  124.70 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =    1699.68 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     3 runs   (    0.24 ms per token,  4213.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1137.90 ms /    47 tokens (   24.21 ms per token,    41.30 tokens per second)\n",
      "llama_print_timings:        eval time =     238.27 ms /     2 runs   (  119.14 ms per token,     8.39 tokens per second)\n",
      "llama_print_timings:       total time =    1499.46 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4424.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1799.52 ms /    68 tokens (   26.46 ms per token,    37.79 tokens per second)\n",
      "llama_print_timings:        eval time =     225.21 ms /     2 runs   (  112.61 ms per token,     8.88 tokens per second)\n",
      "llama_print_timings:       total time =    2183.70 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     4 runs   (    0.23 ms per token,  4264.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1184.44 ms /    49 tokens (   24.17 ms per token,    41.37 tokens per second)\n",
      "llama_print_timings:        eval time =     351.45 ms /     3 runs   (  117.15 ms per token,     8.54 tokens per second)\n",
      "llama_print_timings:       total time =    1673.85 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4885.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1409.01 ms /    58 tokens (   24.29 ms per token,    41.16 tokens per second)\n",
      "llama_print_timings:        eval time =     236.03 ms /     2 runs   (  118.01 ms per token,     8.47 tokens per second)\n",
      "llama_print_timings:       total time =    1804.22 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4316.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1739.91 ms /    66 tokens (   26.36 ms per token,    37.93 tokens per second)\n",
      "llama_print_timings:        eval time =     223.87 ms /     2 runs   (  111.93 ms per token,     8.93 tokens per second)\n",
      "llama_print_timings:       total time =    2115.39 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       3.51 ms /    16 runs   (    0.22 ms per token,  4563.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.55 ms /    51 tokens (   24.32 ms per token,    41.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1673.58 ms /    15 runs   (  111.57 ms per token,     8.96 tokens per second)\n",
      "llama_print_timings:       total time =    3078.27 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4424.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1128.80 ms /    47 tokens (   24.02 ms per token,    41.64 tokens per second)\n",
      "llama_print_timings:        eval time =     236.54 ms /     2 runs   (  118.27 ms per token,     8.46 tokens per second)\n",
      "llama_print_timings:       total time =    1473.60 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4484.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1747.35 ms /    65 tokens (   26.88 ms per token,    37.20 tokens per second)\n",
      "llama_print_timings:        eval time =     227.58 ms /     2 runs   (  113.79 ms per token,     8.79 tokens per second)\n",
      "llama_print_timings:       total time =    2128.99 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4901.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1164.36 ms /    48 tokens (   24.26 ms per token,    41.22 tokens per second)\n",
      "llama_print_timings:        eval time =     230.24 ms /     2 runs   (  115.12 ms per token,     8.69 tokens per second)\n",
      "llama_print_timings:       total time =    1520.26 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.74 ms /     3 runs   (    0.25 ms per token,  4054.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1135.87 ms /    45 tokens (   25.24 ms per token,    39.62 tokens per second)\n",
      "llama_print_timings:        eval time =     238.90 ms /     2 runs   (  119.45 ms per token,     8.37 tokens per second)\n",
      "llama_print_timings:       total time =    1489.80 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     3 runs   (    0.24 ms per token,  4249.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1359.46 ms /    56 tokens (   24.28 ms per token,    41.19 tokens per second)\n",
      "llama_print_timings:        eval time =     244.72 ms /     2 runs   (  122.36 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =    1752.93 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       3.71 ms /    16 runs   (    0.23 ms per token,  4306.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1212.54 ms /    51 tokens (   23.78 ms per token,    42.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1672.94 ms /    15 runs   (  111.53 ms per token,     8.97 tokens per second)\n",
      "llama_print_timings:       total time =    3069.75 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4643.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1740.96 ms /    66 tokens (   26.38 ms per token,    37.91 tokens per second)\n",
      "llama_print_timings:        eval time =     222.02 ms /     2 runs   (  111.01 ms per token,     9.01 tokens per second)\n",
      "llama_print_timings:       total time =    2115.78 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4477.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1563.03 ms /    64 tokens (   24.42 ms per token,    40.95 tokens per second)\n",
      "llama_print_timings:        eval time =     235.21 ms /     2 runs   (  117.60 ms per token,     8.50 tokens per second)\n",
      "llama_print_timings:       total time =    1964.85 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4273.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.90 ms /    52 tokens (   24.04 ms per token,    41.60 tokens per second)\n",
      "llama_print_timings:        eval time =     236.53 ms /     2 runs   (  118.27 ms per token,     8.46 tokens per second)\n",
      "llama_print_timings:       total time =    1612.50 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4545.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1858.75 ms /    72 tokens (   25.82 ms per token,    38.74 tokens per second)\n",
      "llama_print_timings:        eval time =     223.19 ms /     2 runs   (  111.59 ms per token,     8.96 tokens per second)\n",
      "llama_print_timings:       total time =    2246.11 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4451.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1418.38 ms /    59 tokens (   24.04 ms per token,    41.60 tokens per second)\n",
      "llama_print_timings:        eval time =     236.67 ms /     2 runs   (  118.34 ms per token,     8.45 tokens per second)\n",
      "llama_print_timings:       total time =    1822.62 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4601.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1878.00 ms /    73 tokens (   25.73 ms per token,    38.87 tokens per second)\n",
      "llama_print_timings:        eval time =     224.82 ms /     2 runs   (  112.41 ms per token,     8.90 tokens per second)\n",
      "llama_print_timings:       total time =    2278.21 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4354.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1309.17 ms /    55 tokens (   23.80 ms per token,    42.01 tokens per second)\n",
      "llama_print_timings:        eval time =     238.42 ms /     2 runs   (  119.21 ms per token,     8.39 tokens per second)\n",
      "llama_print_timings:       total time =    1676.09 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4594.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.35 ms /    49 tokens (   24.05 ms per token,    41.58 tokens per second)\n",
      "llama_print_timings:        eval time =     240.55 ms /     2 runs   (  120.28 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =    1550.92 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4341.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1498.64 ms /    61 tokens (   24.57 ms per token,    40.70 tokens per second)\n",
      "llama_print_timings:        eval time =     238.15 ms /     2 runs   (  119.08 ms per token,     8.40 tokens per second)\n",
      "llama_print_timings:       total time =    1892.09 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.75 ms /     3 runs   (    0.25 ms per token,  3994.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1414.07 ms /    53 tokens (   26.68 ms per token,    37.48 tokens per second)\n",
      "llama_print_timings:        eval time =     249.03 ms /     2 runs   (  124.52 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =    1840.65 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4524.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1501.22 ms /    58 tokens (   25.88 ms per token,    38.64 tokens per second)\n",
      "llama_print_timings:        eval time =     228.74 ms /     2 runs   (  114.37 ms per token,     8.74 tokens per second)\n",
      "llama_print_timings:       total time =    1892.24 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4573.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1830.97 ms /    70 tokens (   26.16 ms per token,    38.23 tokens per second)\n",
      "llama_print_timings:        eval time =     225.23 ms /     2 runs   (  112.62 ms per token,     8.88 tokens per second)\n",
      "llama_print_timings:       total time =    2217.58 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /     3 runs   (    0.24 ms per token,  4172.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.38 ms /    48 tokens (   24.49 ms per token,    40.84 tokens per second)\n",
      "llama_print_timings:        eval time =     235.62 ms /     2 runs   (  117.81 ms per token,     8.49 tokens per second)\n",
      "llama_print_timings:       total time =    1541.52 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     3 runs   (    0.27 ms per token,  3754.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1148.43 ms /    47 tokens (   24.43 ms per token,    40.93 tokens per second)\n",
      "llama_print_timings:        eval time =     250.16 ms /     2 runs   (  125.08 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =    1525.74 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4531.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1125.82 ms /    45 tokens (   25.02 ms per token,    39.97 tokens per second)\n",
      "llama_print_timings:        eval time =     235.35 ms /     2 runs   (  117.67 ms per token,     8.50 tokens per second)\n",
      "llama_print_timings:       total time =    1479.77 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       3.92 ms /    16 runs   (    0.24 ms per token,  4081.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1210.22 ms /    48 tokens (   25.21 ms per token,    39.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1674.64 ms /    15 runs   (  111.64 ms per token,     8.96 tokens per second)\n",
      "llama_print_timings:       total time =    3062.44 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4615.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1909.09 ms /    71 tokens (   26.89 ms per token,    37.19 tokens per second)\n",
      "llama_print_timings:        eval time =     235.74 ms /     2 runs   (  117.87 ms per token,     8.48 tokens per second)\n",
      "llama_print_timings:       total time =    2315.33 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4451.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1359.17 ms /    54 tokens (   25.17 ms per token,    39.73 tokens per second)\n",
      "llama_print_timings:        eval time =     233.75 ms /     2 runs   (  116.88 ms per token,     8.56 tokens per second)\n",
      "llama_print_timings:       total time =    1750.44 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /     3 runs   (    0.25 ms per token,  3931.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1143.35 ms /    45 tokens (   25.41 ms per token,    39.36 tokens per second)\n",
      "llama_print_timings:        eval time =     230.51 ms /     2 runs   (  115.25 ms per token,     8.68 tokens per second)\n",
      "llama_print_timings:       total time =    1495.75 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4470.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1878.77 ms /    69 tokens (   27.23 ms per token,    36.73 tokens per second)\n",
      "llama_print_timings:        eval time =     228.42 ms /     2 runs   (  114.21 ms per token,     8.76 tokens per second)\n",
      "llama_print_timings:       total time =    2272.62 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.74 ms /     3 runs   (    0.25 ms per token,  4026.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1592.76 ms /    64 tokens (   24.89 ms per token,    40.18 tokens per second)\n",
      "llama_print_timings:        eval time =     235.04 ms /     2 runs   (  117.52 ms per token,     8.51 tokens per second)\n",
      "llama_print_timings:       total time =    1993.22 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4360.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1389.56 ms /    57 tokens (   24.38 ms per token,    41.02 tokens per second)\n",
      "llama_print_timings:        eval time =     249.50 ms /     2 runs   (  124.75 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =    1816.97 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.74 ms /     3 runs   (    0.25 ms per token,  4059.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1438.25 ms /    59 tokens (   24.38 ms per token,    41.02 tokens per second)\n",
      "llama_print_timings:        eval time =     243.88 ms /     2 runs   (  121.94 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =    1852.23 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     3 runs   (    0.24 ms per token,  4237.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1823.54 ms /    69 tokens (   26.43 ms per token,    37.84 tokens per second)\n",
      "llama_print_timings:        eval time =     236.89 ms /     2 runs   (  118.45 ms per token,     8.44 tokens per second)\n",
      "llama_print_timings:       total time =    2237.12 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4392.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1540.70 ms /    63 tokens (   24.46 ms per token,    40.89 tokens per second)\n",
      "llama_print_timings:        eval time =     228.69 ms /     2 runs   (  114.34 ms per token,     8.75 tokens per second)\n",
      "llama_print_timings:       total time =    1935.98 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /     3 runs   (    0.25 ms per token,  3968.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1113.87 ms /    45 tokens (   24.75 ms per token,    40.40 tokens per second)\n",
      "llama_print_timings:        eval time =     240.77 ms /     2 runs   (  120.39 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =    1473.96 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /     3 runs   (    0.24 ms per token,  4137.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1919.79 ms /    73 tokens (   26.30 ms per token,    38.02 tokens per second)\n",
      "llama_print_timings:        eval time =     231.77 ms /     2 runs   (  115.88 ms per token,     8.63 tokens per second)\n",
      "llama_print_timings:       total time =    2323.80 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4316.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1438.74 ms /    58 tokens (   24.81 ms per token,    40.31 tokens per second)\n",
      "llama_print_timings:        eval time =     246.03 ms /     2 runs   (  123.01 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =    1854.22 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4587.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2030.95 ms /    80 tokens (   25.39 ms per token,    39.39 tokens per second)\n",
      "llama_print_timings:        eval time =     224.63 ms /     2 runs   (  112.31 ms per token,     8.90 tokens per second)\n",
      "llama_print_timings:       total time =    2433.70 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4636.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1362.80 ms /    56 tokens (   24.34 ms per token,    41.09 tokens per second)\n",
      "llama_print_timings:        eval time =     253.82 ms /     2 runs   (  126.91 ms per token,     7.88 tokens per second)\n",
      "llama_print_timings:       total time =    1767.49 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4484.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1284.38 ms /    52 tokens (   24.70 ms per token,    40.49 tokens per second)\n",
      "llama_print_timings:        eval time =     245.84 ms /     2 runs   (  122.92 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =    1659.73 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4316.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1218.91 ms /    50 tokens (   24.38 ms per token,    41.02 tokens per second)\n",
      "llama_print_timings:        eval time =     249.27 ms /     2 runs   (  124.64 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =    1596.38 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     3 runs   (    0.26 ms per token,  3807.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1372.78 ms /    56 tokens (   24.51 ms per token,    40.79 tokens per second)\n",
      "llama_print_timings:        eval time =     228.48 ms /     2 runs   (  114.24 ms per token,     8.75 tokens per second)\n",
      "llama_print_timings:       total time =    1763.29 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4573.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1519.42 ms /    61 tokens (   24.91 ms per token,    40.15 tokens per second)\n",
      "llama_print_timings:        eval time =     223.93 ms /     2 runs   (  111.96 ms per token,     8.93 tokens per second)\n",
      "llama_print_timings:       total time =    1928.58 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /     3 runs   (    0.24 ms per token,  4184.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1139.21 ms /    46 tokens (   24.77 ms per token,    40.38 tokens per second)\n",
      "llama_print_timings:        eval time =     237.37 ms /     2 runs   (  118.68 ms per token,     8.43 tokens per second)\n",
      "llama_print_timings:       total time =    1488.16 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4552.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1568.83 ms /    63 tokens (   24.90 ms per token,    40.16 tokens per second)\n",
      "llama_print_timings:        eval time =     229.07 ms /     2 runs   (  114.53 ms per token,     8.73 tokens per second)\n",
      "llama_print_timings:       total time =    1966.45 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     3 runs   (    0.24 ms per token,  4237.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1277.82 ms /    53 tokens (   24.11 ms per token,    41.48 tokens per second)\n",
      "llama_print_timings:        eval time =     246.31 ms /     2 runs   (  123.16 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =    1652.05 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4373.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1748.85 ms /    65 tokens (   26.91 ms per token,    37.17 tokens per second)\n",
      "llama_print_timings:        eval time =     231.76 ms /     2 runs   (  115.88 ms per token,     8.63 tokens per second)\n",
      "llama_print_timings:       total time =    2134.86 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4694.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1089.63 ms /    44 tokens (   24.76 ms per token,    40.38 tokens per second)\n",
      "llama_print_timings:        eval time =     235.42 ms /     2 runs   (  117.71 ms per token,     8.50 tokens per second)\n",
      "llama_print_timings:       total time =    1430.33 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.75 ms /     3 runs   (    0.25 ms per token,  4016.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1212.27 ms /    48 tokens (   25.26 ms per token,    39.60 tokens per second)\n",
      "llama_print_timings:        eval time =     259.39 ms /     2 runs   (  129.70 ms per token,     7.71 tokens per second)\n",
      "llama_print_timings:       total time =    1594.52 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     3 runs   (    0.26 ms per token,  3875.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1345.30 ms /    55 tokens (   24.46 ms per token,    40.88 tokens per second)\n",
      "llama_print_timings:        eval time =     237.69 ms /     2 runs   (  118.85 ms per token,     8.41 tokens per second)\n",
      "llama_print_timings:       total time =    1732.74 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4405.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1776.36 ms /    66 tokens (   26.91 ms per token,    37.15 tokens per second)\n",
      "llama_print_timings:        eval time =     228.37 ms /     2 runs   (  114.18 ms per token,     8.76 tokens per second)\n",
      "llama_print_timings:       total time =    2160.76 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4484.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1220.76 ms /    51 tokens (   23.94 ms per token,    41.78 tokens per second)\n",
      "llama_print_timings:        eval time =     238.33 ms /     2 runs   (  119.16 ms per token,     8.39 tokens per second)\n",
      "llama_print_timings:       total time =    1596.51 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4746.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1025.39 ms /    40 tokens (   25.63 ms per token,    39.01 tokens per second)\n",
      "llama_print_timings:        eval time =     233.93 ms /     2 runs   (  116.96 ms per token,     8.55 tokens per second)\n",
      "llama_print_timings:       total time =    1361.23 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4437.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1859.10 ms /    67 tokens (   27.75 ms per token,    36.04 tokens per second)\n",
      "llama_print_timings:        eval time =     221.84 ms /     2 runs   (  110.92 ms per token,     9.02 tokens per second)\n",
      "llama_print_timings:       total time =    2239.65 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4267.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1479.82 ms /    60 tokens (   24.66 ms per token,    40.55 tokens per second)\n",
      "llama_print_timings:        eval time =     227.32 ms /     2 runs   (  113.66 ms per token,     8.80 tokens per second)\n",
      "llama_print_timings:       total time =    1874.52 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4477.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1304.83 ms /    53 tokens (   24.62 ms per token,    40.62 tokens per second)\n",
      "llama_print_timings:        eval time =     245.56 ms /     2 runs   (  122.78 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =    1686.83 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /     3 runs   (    0.25 ms per token,  3926.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1407.10 ms /    58 tokens (   24.26 ms per token,    41.22 tokens per second)\n",
      "llama_print_timings:        eval time =     243.63 ms /     2 runs   (  121.81 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =    1828.59 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       1.45 ms /     3 runs   (    0.48 ms per token,  2070.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1228.18 ms /    51 tokens (   24.08 ms per token,    41.52 tokens per second)\n",
      "llama_print_timings:        eval time =     243.71 ms /     2 runs   (  121.86 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =    1607.42 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     3 runs   (    0.28 ms per token,  3529.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1117.33 ms /    44 tokens (   25.39 ms per token,    39.38 tokens per second)\n",
      "llama_print_timings:        eval time =     241.73 ms /     2 runs   (  120.87 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =    1487.14 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4524.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1484.81 ms /    58 tokens (   25.60 ms per token,    39.06 tokens per second)\n",
      "llama_print_timings:        eval time =     227.97 ms /     2 runs   (  113.99 ms per token,     8.77 tokens per second)\n",
      "llama_print_timings:       total time =    1878.31 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.73 ms /     3 runs   (    0.24 ms per token,  4132.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1275.84 ms /    52 tokens (   24.54 ms per token,    40.76 tokens per second)\n",
      "llama_print_timings:        eval time =     261.46 ms /     2 runs   (  130.73 ms per token,     7.65 tokens per second)\n",
      "llama_print_timings:       total time =    1669.27 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     3 runs   (    0.27 ms per token,  3764.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1493.09 ms /    61 tokens (   24.48 ms per token,    40.85 tokens per second)\n",
      "llama_print_timings:        eval time =     234.26 ms /     2 runs   (  117.13 ms per token,     8.54 tokens per second)\n",
      "llama_print_timings:       total time =    1904.71 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /     3 runs   (    0.25 ms per token,  3942.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1245.67 ms /    50 tokens (   24.91 ms per token,    40.14 tokens per second)\n",
      "llama_print_timings:        eval time =     247.16 ms /     2 runs   (  123.58 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =    1636.99 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4518.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1569.38 ms /    64 tokens (   24.52 ms per token,    40.78 tokens per second)\n",
      "llama_print_timings:        eval time =     227.17 ms /     2 runs   (  113.59 ms per token,     8.80 tokens per second)\n",
      "llama_print_timings:       total time =    1951.78 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     3 runs   (    0.24 ms per token,  4195.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1314.49 ms /    54 tokens (   24.34 ms per token,    41.08 tokens per second)\n",
      "llama_print_timings:        eval time =     254.08 ms /     2 runs   (  127.04 ms per token,     7.87 tokens per second)\n",
      "llama_print_timings:       total time =    1715.15 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4329.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1081.27 ms /    43 tokens (   25.15 ms per token,    39.77 tokens per second)\n",
      "llama_print_timings:        eval time =     242.68 ms /     2 runs   (  121.34 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =    1428.04 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4497.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1496.87 ms /    60 tokens (   24.95 ms per token,    40.08 tokens per second)\n",
      "llama_print_timings:        eval time =     234.72 ms /     2 runs   (  117.36 ms per token,     8.52 tokens per second)\n",
      "llama_print_timings:       total time =    1900.10 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4424.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1451.57 ms /    60 tokens (   24.19 ms per token,    41.33 tokens per second)\n",
      "llama_print_timings:        eval time =     237.84 ms /     2 runs   (  118.92 ms per token,     8.41 tokens per second)\n",
      "llama_print_timings:       total time =    1859.79 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4373.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1080.05 ms /    43 tokens (   25.12 ms per token,    39.81 tokens per second)\n",
      "llama_print_timings:        eval time =     238.18 ms /     2 runs   (  119.09 ms per token,     8.40 tokens per second)\n",
      "llama_print_timings:       total time =    1418.96 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.74 ms /     3 runs   (    0.25 ms per token,  4032.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1285.78 ms /    50 tokens (   25.72 ms per token,    38.89 tokens per second)\n",
      "llama_print_timings:        eval time =     245.18 ms /     2 runs   (  122.59 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =    1675.21 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4255.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1356.32 ms /    56 tokens (   24.22 ms per token,    41.29 tokens per second)\n",
      "llama_print_timings:        eval time =     246.75 ms /     2 runs   (  123.37 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =    1750.77 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4310.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1755.06 ms /    66 tokens (   26.59 ms per token,    37.61 tokens per second)\n",
      "llama_print_timings:        eval time =     230.67 ms /     2 runs   (  115.33 ms per token,     8.67 tokens per second)\n",
      "llama_print_timings:       total time =    2147.54 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4304.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.56 ms /    52 tokens (   24.18 ms per token,    41.35 tokens per second)\n",
      "llama_print_timings:        eval time =     257.52 ms /     2 runs   (  128.76 ms per token,     7.77 tokens per second)\n",
      "llama_print_timings:       total time =    1654.40 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4580.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1517.32 ms /    62 tokens (   24.47 ms per token,    40.86 tokens per second)\n",
      "llama_print_timings:        eval time =     230.03 ms /     2 runs   (  115.02 ms per token,     8.69 tokens per second)\n",
      "llama_print_timings:       total time =    1914.55 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4694.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1493.73 ms /    60 tokens (   24.90 ms per token,    40.17 tokens per second)\n",
      "llama_print_timings:        eval time =     226.60 ms /     2 runs   (  113.30 ms per token,     8.83 tokens per second)\n",
      "llama_print_timings:       total time =    1896.12 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4531.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1754.78 ms /    66 tokens (   26.59 ms per token,    37.61 tokens per second)\n",
      "llama_print_timings:        eval time =     224.53 ms /     2 runs   (  112.26 ms per token,     8.91 tokens per second)\n",
      "llama_print_timings:       total time =    2134.97 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     3 runs   (    0.24 ms per token,  4231.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1196.21 ms /    49 tokens (   24.41 ms per token,    40.96 tokens per second)\n",
      "llama_print_timings:        eval time =     244.12 ms /     2 runs   (  122.06 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =    1588.29 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4702.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1499.85 ms /    61 tokens (   24.59 ms per token,    40.67 tokens per second)\n",
      "llama_print_timings:        eval time =     225.00 ms /     2 runs   (  112.50 ms per token,     8.89 tokens per second)\n",
      "llama_print_timings:       total time =    1890.42 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4379.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1423.53 ms /    59 tokens (   24.13 ms per token,    41.45 tokens per second)\n",
      "llama_print_timings:        eval time =     242.30 ms /     2 runs   (  121.15 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =    1845.57 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.74 ms /     3 runs   (    0.25 ms per token,  4026.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1766.40 ms /    66 tokens (   26.76 ms per token,    37.36 tokens per second)\n",
      "llama_print_timings:        eval time =     230.76 ms /     2 runs   (  115.38 ms per token,     8.67 tokens per second)\n",
      "llama_print_timings:       total time =    2154.73 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.21 ms per token,  4651.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.98 ms /    47 tokens (   24.62 ms per token,    40.62 tokens per second)\n",
      "llama_print_timings:        eval time =     239.76 ms /     2 runs   (  119.88 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =    1525.09 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4746.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1102.85 ms /    43 tokens (   25.65 ms per token,    38.99 tokens per second)\n",
      "llama_print_timings:        eval time =     228.26 ms /     2 runs   (  114.13 ms per token,     8.76 tokens per second)\n",
      "llama_print_timings:       total time =    1431.20 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4329.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1458.81 ms /    58 tokens (   25.15 ms per token,    39.76 tokens per second)\n",
      "llama_print_timings:        eval time =     228.75 ms /     2 runs   (  114.38 ms per token,     8.74 tokens per second)\n",
      "llama_print_timings:       total time =    1866.07 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /     3 runs   (    0.25 ms per token,  3931.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1284.01 ms /    53 tokens (   24.23 ms per token,    41.28 tokens per second)\n",
      "llama_print_timings:        eval time =     246.65 ms /     2 runs   (  123.32 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =    1671.45 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     3 runs   (    0.24 ms per token,  4225.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1304.70 ms /    53 tokens (   24.62 ms per token,    40.62 tokens per second)\n",
      "llama_print_timings:        eval time =     251.85 ms /     2 runs   (  125.92 ms per token,     7.94 tokens per second)\n",
      "llama_print_timings:       total time =    1695.42 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /     3 runs   (    0.24 ms per token,  4155.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1372.93 ms /    56 tokens (   24.52 ms per token,    40.79 tokens per second)\n",
      "llama_print_timings:        eval time =     242.04 ms /     2 runs   (  121.02 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =    1768.93 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     3 runs   (    0.27 ms per token,  3694.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1137.32 ms /    45 tokens (   25.27 ms per token,    39.57 tokens per second)\n",
      "llama_print_timings:        eval time =     238.62 ms /     2 runs   (  119.31 ms per token,     8.38 tokens per second)\n",
      "llama_print_timings:       total time =    1485.64 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.75 ms /     3 runs   (    0.25 ms per token,  4010.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1334.14 ms /    53 tokens (   25.17 ms per token,    39.73 tokens per second)\n",
      "llama_print_timings:        eval time =     239.67 ms /     2 runs   (  119.84 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =    1723.35 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4385.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1488.91 ms /    60 tokens (   24.82 ms per token,    40.30 tokens per second)\n",
      "llama_print_timings:        eval time =     233.13 ms /     2 runs   (  116.57 ms per token,     8.58 tokens per second)\n",
      "llama_print_timings:       total time =    1897.50 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4587.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1778.24 ms /    66 tokens (   26.94 ms per token,    37.12 tokens per second)\n",
      "llama_print_timings:        eval time =     228.98 ms /     2 runs   (  114.49 ms per token,     8.73 tokens per second)\n",
      "llama_print_timings:       total time =    2163.54 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     3 runs   (    0.24 ms per token,  4207.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1225.40 ms /    48 tokens (   25.53 ms per token,    39.17 tokens per second)\n",
      "llama_print_timings:        eval time =     250.63 ms /     2 runs   (  125.31 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =    1615.85 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4261.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1484.10 ms /    59 tokens (   25.15 ms per token,    39.75 tokens per second)\n",
      "llama_print_timings:        eval time =     224.92 ms /     2 runs   (  112.46 ms per token,     8.89 tokens per second)\n",
      "llama_print_timings:       total time =    1891.69 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.75 ms /     3 runs   (    0.25 ms per token,  4000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1190.36 ms /    47 tokens (   25.33 ms per token,    39.48 tokens per second)\n",
      "llama_print_timings:        eval time =     250.90 ms /     2 runs   (  125.45 ms per token,     7.97 tokens per second)\n",
      "llama_print_timings:       total time =    1567.51 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4335.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1052.26 ms /    41 tokens (   25.66 ms per token,    38.96 tokens per second)\n",
      "llama_print_timings:        eval time =     243.26 ms /     2 runs   (  121.63 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =    1394.19 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4255.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1354.40 ms /    54 tokens (   25.08 ms per token,    39.87 tokens per second)\n",
      "llama_print_timings:        eval time =     242.85 ms /     2 runs   (  121.42 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =    1747.63 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4511.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1564.24 ms /    63 tokens (   24.83 ms per token,    40.28 tokens per second)\n",
      "llama_print_timings:        eval time =     222.51 ms /     2 runs   (  111.26 ms per token,     8.99 tokens per second)\n",
      "llama_print_timings:       total time =    1956.83 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4267.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1164.78 ms /    47 tokens (   24.78 ms per token,    40.35 tokens per second)\n",
      "llama_print_timings:        eval time =     244.00 ms /     2 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =    1548.46 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4379.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1799.68 ms /    67 tokens (   26.86 ms per token,    37.23 tokens per second)\n",
      "llama_print_timings:        eval time =     227.14 ms /     2 runs   (  113.57 ms per token,     8.81 tokens per second)\n",
      "llama_print_timings:       total time =    2187.26 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4491.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1559.58 ms /    63 tokens (   24.76 ms per token,    40.40 tokens per second)\n",
      "llama_print_timings:        eval time =     227.71 ms /     2 runs   (  113.85 ms per token,     8.78 tokens per second)\n",
      "llama_print_timings:       total time =    1963.77 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4552.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1823.96 ms /    69 tokens (   26.43 ms per token,    37.83 tokens per second)\n",
      "llama_print_timings:        eval time =     227.23 ms /     2 runs   (  113.61 ms per token,     8.80 tokens per second)\n",
      "llama_print_timings:       total time =    2224.93 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /     3 runs   (    0.24 ms per token,  4160.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1270.93 ms /    52 tokens (   24.44 ms per token,    40.91 tokens per second)\n",
      "llama_print_timings:        eval time =     253.89 ms /     2 runs   (  126.94 ms per token,     7.88 tokens per second)\n",
      "llama_print_timings:       total time =    1674.55 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.75 ms /     3 runs   (    0.25 ms per token,  4016.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.53 ms /    51 tokens (   24.38 ms per token,    41.01 tokens per second)\n",
      "llama_print_timings:        eval time =     243.50 ms /     2 runs   (  121.75 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =    1616.36 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4424.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1425.32 ms /    58 tokens (   24.57 ms per token,    40.69 tokens per second)\n",
      "llama_print_timings:        eval time =     238.98 ms /     2 runs   (  119.49 ms per token,     8.37 tokens per second)\n",
      "llama_print_timings:       total time =    1833.50 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4424.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1345.26 ms /    55 tokens (   24.46 ms per token,    40.88 tokens per second)\n",
      "llama_print_timings:        eval time =     237.04 ms /     2 runs   (  118.52 ms per token,     8.44 tokens per second)\n",
      "llama_print_timings:       total time =    1718.10 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4373.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1409.23 ms /    58 tokens (   24.30 ms per token,    41.16 tokens per second)\n",
      "llama_print_timings:        eval time =     244.91 ms /     2 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =    1827.49 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4545.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1508.53 ms /    62 tokens (   24.33 ms per token,    41.10 tokens per second)\n",
      "llama_print_timings:        eval time =     226.83 ms /     2 runs   (  113.42 ms per token,     8.82 tokens per second)\n",
      "llama_print_timings:       total time =    1902.06 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /     3 runs   (    0.24 ms per token,  4137.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2022.51 ms /    78 tokens (   25.93 ms per token,    38.57 tokens per second)\n",
      "llama_print_timings:        eval time =     226.72 ms /     2 runs   (  113.36 ms per token,     8.82 tokens per second)\n",
      "llama_print_timings:       total time =    2446.82 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4518.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2254.40 ms /    91 tokens (   24.77 ms per token,    40.37 tokens per second)\n",
      "llama_print_timings:        eval time =     245.88 ms /     2 runs   (  122.94 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =    2710.91 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4601.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1818.21 ms /    69 tokens (   26.35 ms per token,    37.95 tokens per second)\n",
      "llama_print_timings:        eval time =     227.83 ms /     2 runs   (  113.92 ms per token,     8.78 tokens per second)\n",
      "llama_print_timings:       total time =    2200.82 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4451.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1525.52 ms /    63 tokens (   24.21 ms per token,    41.30 tokens per second)\n",
      "llama_print_timings:        eval time =     223.42 ms /     2 runs   (  111.71 ms per token,     8.95 tokens per second)\n",
      "llama_print_timings:       total time =    1918.11 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4566.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2469.23 ms /   101 tokens (   24.45 ms per token,    40.90 tokens per second)\n",
      "llama_print_timings:        eval time =     245.25 ms /     2 runs   (  122.63 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =    2944.30 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       3.58 ms /    16 runs   (    0.22 ms per token,  4474.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2546.11 ms /   106 tokens (   24.02 ms per token,    41.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1839.96 ms /    15 runs   (  122.66 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =    4659.34 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4477.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1817.89 ms /    68 tokens (   26.73 ms per token,    37.41 tokens per second)\n",
      "llama_print_timings:        eval time =     223.20 ms /     2 runs   (  111.60 ms per token,     8.96 tokens per second)\n",
      "llama_print_timings:       total time =    2201.23 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4347.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2114.49 ms /    84 tokens (   25.17 ms per token,    39.73 tokens per second)\n",
      "llama_print_timings:        eval time =     228.62 ms /     2 runs   (  114.31 ms per token,     8.75 tokens per second)\n",
      "llama_print_timings:       total time =    2540.72 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4335.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1904.38 ms /    74 tokens (   25.73 ms per token,    38.86 tokens per second)\n",
      "llama_print_timings:        eval time =     233.60 ms /     2 runs   (  116.80 ms per token,     8.56 tokens per second)\n",
      "llama_print_timings:       total time =    2302.09 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4341.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2231.23 ms /    90 tokens (   24.79 ms per token,    40.34 tokens per second)\n",
      "llama_print_timings:        eval time =     245.34 ms /     2 runs   (  122.67 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =    2677.89 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4379.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1436.54 ms /    59 tokens (   24.35 ms per token,    41.07 tokens per second)\n",
      "llama_print_timings:        eval time =     242.52 ms /     2 runs   (  121.26 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =    1865.76 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4398.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1945.49 ms /    77 tokens (   25.27 ms per token,    39.58 tokens per second)\n",
      "llama_print_timings:        eval time =     223.63 ms /     2 runs   (  111.81 ms per token,     8.94 tokens per second)\n",
      "llama_print_timings:       total time =    2349.26 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4431.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2705.94 ms /   113 tokens (   23.95 ms per token,    41.76 tokens per second)\n",
      "llama_print_timings:        eval time =     244.26 ms /     2 runs   (  122.13 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =    3197.58 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4322.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1535.47 ms /    63 tokens (   24.37 ms per token,    41.03 tokens per second)\n",
      "llama_print_timings:        eval time =     222.80 ms /     2 runs   (  111.40 ms per token,     8.98 tokens per second)\n",
      "llama_print_timings:       total time =    1923.90 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4261.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2346.37 ms /    95 tokens (   24.70 ms per token,    40.49 tokens per second)\n",
      "llama_print_timings:        eval time =     243.28 ms /     2 runs   (  121.64 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =    2797.67 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4511.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2125.02 ms /    85 tokens (   25.00 ms per token,    40.00 tokens per second)\n",
      "llama_print_timings:        eval time =     230.70 ms /     2 runs   (  115.35 ms per token,     8.67 tokens per second)\n",
      "llama_print_timings:       total time =    2546.88 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4636.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1806.80 ms /    69 tokens (   26.19 ms per token,    38.19 tokens per second)\n",
      "llama_print_timings:        eval time =     233.22 ms /     2 runs   (  116.61 ms per token,     8.58 tokens per second)\n",
      "llama_print_timings:       total time =    2202.52 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /     3 runs   (    0.24 ms per token,  4155.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1787.63 ms /    68 tokens (   26.29 ms per token,    38.04 tokens per second)\n",
      "llama_print_timings:        eval time =     231.13 ms /     2 runs   (  115.56 ms per token,     8.65 tokens per second)\n",
      "llama_print_timings:       total time =    2179.08 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     3 runs   (    0.27 ms per token,  3667.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1999.09 ms /    79 tokens (   25.30 ms per token,    39.52 tokens per second)\n",
      "llama_print_timings:        eval time =     223.23 ms /     2 runs   (  111.61 ms per token,     8.96 tokens per second)\n",
      "llama_print_timings:       total time =    2401.19 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4457.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2099.07 ms /    84 tokens (   24.99 ms per token,    40.02 tokens per second)\n",
      "llama_print_timings:        eval time =     224.69 ms /     2 runs   (  112.35 ms per token,     8.90 tokens per second)\n",
      "llama_print_timings:       total time =    2519.70 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4573.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3215.89 ms /   132 tokens (   24.36 ms per token,    41.05 tokens per second)\n",
      "llama_print_timings:        eval time =     266.13 ms /     2 runs   (  133.06 ms per token,     7.52 tokens per second)\n",
      "llama_print_timings:       total time =    3767.87 ms /   134 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4731.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2327.85 ms /    95 tokens (   24.50 ms per token,    40.81 tokens per second)\n",
      "llama_print_timings:        eval time =     242.02 ms /     2 runs   (  121.01 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =    2776.11 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /     3 runs   (    0.24 ms per token,  4155.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1428.69 ms /    59 tokens (   24.22 ms per token,    41.30 tokens per second)\n",
      "llama_print_timings:        eval time =     232.39 ms /     2 runs   (  116.20 ms per token,     8.61 tokens per second)\n",
      "llama_print_timings:       total time =    1835.93 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4830.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2176.07 ms /    89 tokens (   24.45 ms per token,    40.90 tokens per second)\n",
      "llama_print_timings:        eval time =     244.92 ms /     2 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =    2625.35 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4594.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2432.12 ms /   100 tokens (   24.32 ms per token,    41.12 tokens per second)\n",
      "llama_print_timings:        eval time =     245.56 ms /     2 runs   (  122.78 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =    2897.76 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4594.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1870.84 ms /    72 tokens (   25.98 ms per token,    38.49 tokens per second)\n",
      "llama_print_timings:        eval time =     221.69 ms /     2 runs   (  110.84 ms per token,     9.02 tokens per second)\n",
      "llama_print_timings:       total time =    2258.19 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4373.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1965.61 ms /    77 tokens (   25.53 ms per token,    39.17 tokens per second)\n",
      "llama_print_timings:        eval time =     221.64 ms /     2 runs   (  110.82 ms per token,     9.02 tokens per second)\n",
      "llama_print_timings:       total time =    2363.78 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4511.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2213.47 ms /    90 tokens (   24.59 ms per token,    40.66 tokens per second)\n",
      "llama_print_timings:        eval time =     243.13 ms /     2 runs   (  121.56 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =    2652.15 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     3 runs   (    0.26 ms per token,  3906.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2574.48 ms /   108 tokens (   23.84 ms per token,    41.95 tokens per second)\n",
      "llama_print_timings:        eval time =     257.35 ms /     2 runs   (  128.68 ms per token,     7.77 tokens per second)\n",
      "llama_print_timings:       total time =    3063.07 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4643.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1513.21 ms /    63 tokens (   24.02 ms per token,    41.63 tokens per second)\n",
      "llama_print_timings:        eval time =     225.59 ms /     2 runs   (  112.79 ms per token,     8.87 tokens per second)\n",
      "llama_print_timings:       total time =    1908.79 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4444.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2550.64 ms /   105 tokens (   24.29 ms per token,    41.17 tokens per second)\n",
      "llama_print_timings:        eval time =     241.13 ms /     2 runs   (  120.57 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =    3019.95 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4587.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1723.00 ms /    65 tokens (   26.51 ms per token,    37.73 tokens per second)\n",
      "llama_print_timings:        eval time =     228.30 ms /     2 runs   (  114.15 ms per token,     8.76 tokens per second)\n",
      "llama_print_timings:       total time =    2102.33 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4587.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2791.49 ms /   119 tokens (   23.46 ms per token,    42.63 tokens per second)\n",
      "llama_print_timings:        eval time =     250.07 ms /     2 runs   (  125.03 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =    3296.91 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     3 runs   (    0.28 ms per token,  3550.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1770.45 ms /    68 tokens (   26.04 ms per token,    38.41 tokens per second)\n",
      "llama_print_timings:        eval time =     228.30 ms /     2 runs   (  114.15 ms per token,     8.76 tokens per second)\n",
      "llama_print_timings:       total time =    2158.86 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4431.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2132.99 ms /    86 tokens (   24.80 ms per token,    40.32 tokens per second)\n",
      "llama_print_timings:        eval time =     220.98 ms /     2 runs   (  110.49 ms per token,     9.05 tokens per second)\n",
      "llama_print_timings:       total time =    2548.54 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /     3 runs   (    0.24 ms per token,  4178.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2132.89 ms /    86 tokens (   24.80 ms per token,    40.32 tokens per second)\n",
      "llama_print_timings:        eval time =     221.61 ms /     2 runs   (  110.81 ms per token,     9.02 tokens per second)\n",
      "llama_print_timings:       total time =    2550.50 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4680.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2196.21 ms /    89 tokens (   24.68 ms per token,    40.52 tokens per second)\n",
      "llama_print_timings:        eval time =     243.33 ms /     2 runs   (  121.67 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =    2633.16 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4366.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2348.34 ms /    97 tokens (   24.21 ms per token,    41.31 tokens per second)\n",
      "llama_print_timings:        eval time =     254.09 ms /     2 runs   (  127.05 ms per token,     7.87 tokens per second)\n",
      "llama_print_timings:       total time =    2813.82 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4354.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2734.24 ms /   114 tokens (   23.98 ms per token,    41.69 tokens per second)\n",
      "llama_print_timings:        eval time =     244.62 ms /     2 runs   (  122.31 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =    3222.31 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4629.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1556.03 ms /    64 tokens (   24.31 ms per token,    41.13 tokens per second)\n",
      "llama_print_timings:        eval time =     230.80 ms /     2 runs   (  115.40 ms per token,     8.67 tokens per second)\n",
      "llama_print_timings:       total time =    1948.79 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4373.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2548.26 ms /   105 tokens (   24.27 ms per token,    41.20 tokens per second)\n",
      "llama_print_timings:        eval time =     242.53 ms /     2 runs   (  121.26 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =    3016.14 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4504.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1912.70 ms /    75 tokens (   25.50 ms per token,    39.21 tokens per second)\n",
      "llama_print_timings:        eval time =     222.47 ms /     2 runs   (  111.24 ms per token,     8.99 tokens per second)\n",
      "llama_print_timings:       total time =    2302.37 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4694.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1751.13 ms /    66 tokens (   26.53 ms per token,    37.69 tokens per second)\n",
      "llama_print_timings:        eval time =     222.05 ms /     2 runs   (  111.03 ms per token,     9.01 tokens per second)\n",
      "llama_print_timings:       total time =    2119.70 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4601.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2247.44 ms /    91 tokens (   24.70 ms per token,    40.49 tokens per second)\n",
      "llama_print_timings:        eval time =     248.57 ms /     2 runs   (  124.28 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =    2703.04 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4580.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1478.79 ms /    61 tokens (   24.24 ms per token,    41.25 tokens per second)\n",
      "llama_print_timings:        eval time =     227.95 ms /     2 runs   (  113.98 ms per token,     8.77 tokens per second)\n",
      "llama_print_timings:       total time =    1879.72 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4464.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2251.44 ms /    91 tokens (   24.74 ms per token,    40.42 tokens per second)\n",
      "llama_print_timings:        eval time =     250.56 ms /     2 runs   (  125.28 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =    2706.73 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     3 runs   (    0.24 ms per token,  4207.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1556.85 ms /    64 tokens (   24.33 ms per token,    41.11 tokens per second)\n",
      "llama_print_timings:        eval time =     233.60 ms /     2 runs   (  116.80 ms per token,     8.56 tokens per second)\n",
      "llama_print_timings:       total time =    1960.42 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4470.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1470.91 ms /    61 tokens (   24.11 ms per token,    41.47 tokens per second)\n",
      "llama_print_timings:        eval time =     224.28 ms /     2 runs   (  112.14 ms per token,     8.92 tokens per second)\n",
      "llama_print_timings:       total time =    1860.10 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4470.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2188.47 ms /    89 tokens (   24.59 ms per token,    40.67 tokens per second)\n",
      "llama_print_timings:        eval time =     252.33 ms /     2 runs   (  126.16 ms per token,     7.93 tokens per second)\n",
      "llama_print_timings:       total time =    2633.52 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4573.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2049.62 ms /    83 tokens (   24.69 ms per token,    40.50 tokens per second)\n",
      "llama_print_timings:        eval time =     227.45 ms /     2 runs   (  113.73 ms per token,     8.79 tokens per second)\n",
      "llama_print_timings:       total time =    2466.82 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     3 runs   (    0.28 ms per token,  3546.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2823.26 ms /   120 tokens (   23.53 ms per token,    42.50 tokens per second)\n",
      "llama_print_timings:        eval time =     251.42 ms /     2 runs   (  125.71 ms per token,     7.95 tokens per second)\n",
      "llama_print_timings:       total time =    3332.00 ms /   122 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.75 ms /     3 runs   (    0.25 ms per token,  4005.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2829.72 ms /   120 tokens (   23.58 ms per token,    42.41 tokens per second)\n",
      "llama_print_timings:        eval time =     249.03 ms /     2 runs   (  124.52 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =    3336.28 ms /   122 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4297.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1884.74 ms /    73 tokens (   25.82 ms per token,    38.73 tokens per second)\n",
      "llama_print_timings:        eval time =     223.25 ms /     2 runs   (  111.63 ms per token,     8.96 tokens per second)\n",
      "llama_print_timings:       total time =    2274.91 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4694.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1752.16 ms /    66 tokens (   26.55 ms per token,    37.67 tokens per second)\n",
      "llama_print_timings:        eval time =     221.60 ms /     2 runs   (  110.80 ms per token,     9.03 tokens per second)\n",
      "llama_print_timings:       total time =    2124.40 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     3 runs   (    0.24 ms per token,  4231.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2220.20 ms /    90 tokens (   24.67 ms per token,    40.54 tokens per second)\n",
      "llama_print_timings:        eval time =     244.67 ms /     2 runs   (  122.34 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =    2671.69 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4566.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2175.64 ms /    88 tokens (   24.72 ms per token,    40.45 tokens per second)\n",
      "llama_print_timings:        eval time =     233.47 ms /     2 runs   (  116.73 ms per token,     8.57 tokens per second)\n",
      "llama_print_timings:       total time =    2603.08 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4862.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1753.46 ms /    66 tokens (   26.57 ms per token,    37.64 tokens per second)\n",
      "llama_print_timings:        eval time =     225.92 ms /     2 runs   (  112.96 ms per token,     8.85 tokens per second)\n",
      "llama_print_timings:       total time =    2131.78 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4366.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2094.57 ms /    84 tokens (   24.94 ms per token,    40.10 tokens per second)\n",
      "llama_print_timings:        eval time =     224.00 ms /     2 runs   (  112.00 ms per token,     8.93 tokens per second)\n",
      "llama_print_timings:       total time =    2502.29 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4629.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2503.99 ms /   104 tokens (   24.08 ms per token,    41.53 tokens per second)\n",
      "llama_print_timings:        eval time =     246.24 ms /     2 runs   (  123.12 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =    2980.67 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4470.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1933.46 ms /    76 tokens (   25.44 ms per token,    39.31 tokens per second)\n",
      "llama_print_timings:        eval time =     225.15 ms /     2 runs   (  112.58 ms per token,     8.88 tokens per second)\n",
      "llama_print_timings:       total time =    2333.69 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4665.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2453.68 ms /   102 tokens (   24.06 ms per token,    41.57 tokens per second)\n",
      "llama_print_timings:        eval time =     246.13 ms /     2 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =    2917.55 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4552.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1882.53 ms /    74 tokens (   25.44 ms per token,    39.31 tokens per second)\n",
      "llama_print_timings:        eval time =     224.61 ms /     2 runs   (  112.31 ms per token,     8.90 tokens per second)\n",
      "llama_print_timings:       total time =    2268.48 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4629.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2040.65 ms /    81 tokens (   25.19 ms per token,    39.69 tokens per second)\n",
      "llama_print_timings:        eval time =     226.19 ms /     2 runs   (  113.10 ms per token,     8.84 tokens per second)\n",
      "llama_print_timings:       total time =    2454.96 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.73 ms /     3 runs   (    0.24 ms per token,  4087.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1455.51 ms /    60 tokens (   24.26 ms per token,    41.22 tokens per second)\n",
      "llama_print_timings:        eval time =     229.27 ms /     2 runs   (  114.64 ms per token,     8.72 tokens per second)\n",
      "llama_print_timings:       total time =    1851.43 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4573.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1880.46 ms /    73 tokens (   25.76 ms per token,    38.82 tokens per second)\n",
      "llama_print_timings:        eval time =     226.60 ms /     2 runs   (  113.30 ms per token,     8.83 tokens per second)\n",
      "llama_print_timings:       total time =    2277.31 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4601.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2103.57 ms /    85 tokens (   24.75 ms per token,    40.41 tokens per second)\n",
      "llama_print_timings:        eval time =     222.69 ms /     2 runs   (  111.34 ms per token,     8.98 tokens per second)\n",
      "llama_print_timings:       total time =    2510.91 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4716.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1868.93 ms /    72 tokens (   25.96 ms per token,    38.52 tokens per second)\n",
      "llama_print_timings:        eval time =     229.38 ms /     2 runs   (  114.69 ms per token,     8.72 tokens per second)\n",
      "llama_print_timings:       total time =    2263.68 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4470.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2524.40 ms /   105 tokens (   24.04 ms per token,    41.59 tokens per second)\n",
      "llama_print_timings:        eval time =     244.28 ms /     2 runs   (  122.14 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =    2998.08 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4354.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1924.16 ms /    75 tokens (   25.66 ms per token,    38.98 tokens per second)\n",
      "llama_print_timings:        eval time =     224.09 ms /     2 runs   (  112.05 ms per token,     8.92 tokens per second)\n",
      "llama_print_timings:       total time =    2313.92 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4398.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2187.37 ms /    89 tokens (   24.58 ms per token,    40.69 tokens per second)\n",
      "llama_print_timings:        eval time =     242.44 ms /     2 runs   (  121.22 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =    2623.79 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4629.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1942.27 ms /    76 tokens (   25.56 ms per token,    39.13 tokens per second)\n",
      "llama_print_timings:        eval time =     222.34 ms /     2 runs   (  111.17 ms per token,     9.00 tokens per second)\n",
      "llama_print_timings:       total time =    2330.06 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4658.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2017.67 ms /    81 tokens (   24.91 ms per token,    40.15 tokens per second)\n",
      "llama_print_timings:        eval time =     227.70 ms /     2 runs   (  113.85 ms per token,     8.78 tokens per second)\n",
      "llama_print_timings:       total time =    2430.23 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.75 ms /     3 runs   (    0.25 ms per token,  3984.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1816.81 ms /    70 tokens (   25.95 ms per token,    38.53 tokens per second)\n",
      "llama_print_timings:        eval time =     220.21 ms /     2 runs   (  110.10 ms per token,     9.08 tokens per second)\n",
      "llama_print_timings:       total time =    2191.44 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /     3 runs   (    0.24 ms per token,  4172.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2219.63 ms /    90 tokens (   24.66 ms per token,    40.55 tokens per second)\n",
      "llama_print_timings:        eval time =     247.54 ms /     2 runs   (  123.77 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =    2665.77 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4615.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1431.10 ms /    59 tokens (   24.26 ms per token,    41.23 tokens per second)\n",
      "llama_print_timings:        eval time =     228.30 ms /     2 runs   (  114.15 ms per token,     8.76 tokens per second)\n",
      "llama_print_timings:       total time =    1829.96 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4629.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1829.45 ms /    71 tokens (   25.77 ms per token,    38.81 tokens per second)\n",
      "llama_print_timings:        eval time =     223.74 ms /     2 runs   (  111.87 ms per token,     8.94 tokens per second)\n",
      "llama_print_timings:       total time =    2215.82 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4615.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1364.16 ms /    57 tokens (   23.93 ms per token,    41.78 tokens per second)\n",
      "llama_print_timings:        eval time =     248.72 ms /     2 runs   (  124.36 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =    1765.24 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4504.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1976.13 ms /    78 tokens (   25.33 ms per token,    39.47 tokens per second)\n",
      "llama_print_timings:        eval time =     231.74 ms /     2 runs   (  115.87 ms per token,     8.63 tokens per second)\n",
      "llama_print_timings:       total time =    2377.51 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4629.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1730.17 ms /    65 tokens (   26.62 ms per token,    37.57 tokens per second)\n",
      "llama_print_timings:        eval time =     220.73 ms /     2 runs   (  110.37 ms per token,     9.06 tokens per second)\n",
      "llama_print_timings:       total time =    2097.89 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     3 runs   (    0.24 ms per token,  4231.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2276.86 ms /    93 tokens (   24.48 ms per token,    40.85 tokens per second)\n",
      "llama_print_timings:        eval time =     251.79 ms /     2 runs   (  125.89 ms per token,     7.94 tokens per second)\n",
      "llama_print_timings:       total time =    2733.42 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     3 runs   (    0.26 ms per token,  3921.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1714.17 ms /    65 tokens (   26.37 ms per token,    37.92 tokens per second)\n",
      "llama_print_timings:        eval time =     233.25 ms /     2 runs   (  116.62 ms per token,     8.57 tokens per second)\n",
      "llama_print_timings:       total time =    2097.41 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4629.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1749.30 ms /    67 tokens (   26.11 ms per token,    38.30 tokens per second)\n",
      "llama_print_timings:        eval time =     232.08 ms /     2 runs   (  116.04 ms per token,     8.62 tokens per second)\n",
      "llama_print_timings:       total time =    2135.10 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4524.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2142.92 ms /    86 tokens (   24.92 ms per token,    40.13 tokens per second)\n",
      "llama_print_timings:        eval time =     224.78 ms /     2 runs   (  112.39 ms per token,     8.90 tokens per second)\n",
      "llama_print_timings:       total time =    2557.08 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4464.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1560.89 ms /    64 tokens (   24.39 ms per token,    41.00 tokens per second)\n",
      "llama_print_timings:        eval time =     225.17 ms /     2 runs   (  112.58 ms per token,     8.88 tokens per second)\n",
      "llama_print_timings:       total time =    1946.14 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4437.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1994.27 ms /    79 tokens (   25.24 ms per token,    39.61 tokens per second)\n",
      "llama_print_timings:        eval time =     223.47 ms /     2 runs   (  111.74 ms per token,     8.95 tokens per second)\n",
      "llama_print_timings:       total time =    2398.40 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4702.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1978.02 ms /    78 tokens (   25.36 ms per token,    39.43 tokens per second)\n",
      "llama_print_timings:        eval time =     219.40 ms /     2 runs   (  109.70 ms per token,     9.12 tokens per second)\n",
      "llama_print_timings:       total time =    2367.94 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4451.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2118.08 ms /    85 tokens (   24.92 ms per token,    40.13 tokens per second)\n",
      "llama_print_timings:        eval time =     225.92 ms /     2 runs   (  112.96 ms per token,     8.85 tokens per second)\n",
      "llama_print_timings:       total time =    2532.52 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4680.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1778.14 ms /    68 tokens (   26.15 ms per token,    38.24 tokens per second)\n",
      "llama_print_timings:        eval time =     222.83 ms /     2 runs   (  111.42 ms per token,     8.98 tokens per second)\n",
      "llama_print_timings:       total time =    2159.17 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.75 ms /     3 runs   (    0.25 ms per token,  4010.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2049.83 ms /    82 tokens (   25.00 ms per token,    40.00 tokens per second)\n",
      "llama_print_timings:        eval time =     223.09 ms /     2 runs   (  111.54 ms per token,     8.97 tokens per second)\n",
      "llama_print_timings:       total time =    2450.50 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4658.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1851.20 ms /    72 tokens (   25.71 ms per token,    38.89 tokens per second)\n",
      "llama_print_timings:        eval time =     221.29 ms /     2 runs   (  110.64 ms per token,     9.04 tokens per second)\n",
      "llama_print_timings:       total time =    2239.89 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4398.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2254.51 ms /    91 tokens (   24.77 ms per token,    40.36 tokens per second)\n",
      "llama_print_timings:        eval time =     242.06 ms /     2 runs   (  121.03 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =    2693.15 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4573.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2443.06 ms /   101 tokens (   24.19 ms per token,    41.34 tokens per second)\n",
      "llama_print_timings:        eval time =     242.23 ms /     2 runs   (  121.12 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =    2900.37 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4470.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2841.69 ms /   120 tokens (   23.68 ms per token,    42.23 tokens per second)\n",
      "llama_print_timings:        eval time =     249.88 ms /     2 runs   (  124.94 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =    3355.38 ms /   122 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4680.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1718.74 ms /    65 tokens (   26.44 ms per token,    37.82 tokens per second)\n",
      "llama_print_timings:        eval time =     221.50 ms /     2 runs   (  110.75 ms per token,     9.03 tokens per second)\n",
      "llama_print_timings:       total time =    2083.74 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4392.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1952.47 ms /    77 tokens (   25.36 ms per token,    39.44 tokens per second)\n",
      "llama_print_timings:        eval time =     222.02 ms /     2 runs   (  111.01 ms per token,     9.01 tokens per second)\n",
      "llama_print_timings:       total time =    2345.02 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4658.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2098.68 ms /    84 tokens (   24.98 ms per token,    40.03 tokens per second)\n",
      "llama_print_timings:        eval time =     221.82 ms /     2 runs   (  110.91 ms per token,     9.02 tokens per second)\n",
      "llama_print_timings:       total time =    2504.40 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4511.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1790.14 ms /    68 tokens (   26.33 ms per token,    37.99 tokens per second)\n",
      "llama_print_timings:        eval time =     223.01 ms /     2 runs   (  111.50 ms per token,     8.97 tokens per second)\n",
      "llama_print_timings:       total time =    2161.29 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4444.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1830.64 ms /    71 tokens (   25.78 ms per token,    38.78 tokens per second)\n",
      "llama_print_timings:        eval time =     221.21 ms /     2 runs   (  110.61 ms per token,     9.04 tokens per second)\n",
      "llama_print_timings:       total time =    2213.22 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4580.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2268.20 ms /    92 tokens (   24.65 ms per token,    40.56 tokens per second)\n",
      "llama_print_timings:        eval time =     238.75 ms /     2 runs   (  119.38 ms per token,     8.38 tokens per second)\n",
      "llama_print_timings:       total time =    2706.25 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4360.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2127.44 ms /    87 tokens (   24.45 ms per token,    40.89 tokens per second)\n",
      "llama_print_timings:        eval time =     223.89 ms /     2 runs   (  111.94 ms per token,     8.93 tokens per second)\n",
      "llama_print_timings:       total time =    2547.91 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4545.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1983.97 ms /    78 tokens (   25.44 ms per token,    39.32 tokens per second)\n",
      "llama_print_timings:        eval time =     222.37 ms /     2 runs   (  111.18 ms per token,     8.99 tokens per second)\n",
      "llama_print_timings:       total time =    2376.01 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4405.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2225.14 ms /    91 tokens (   24.45 ms per token,    40.90 tokens per second)\n",
      "llama_print_timings:        eval time =     247.37 ms /     2 runs   (  123.69 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =    2671.05 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4304.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1496.09 ms /    61 tokens (   24.53 ms per token,    40.77 tokens per second)\n",
      "llama_print_timings:        eval time =     223.84 ms /     2 runs   (  111.92 ms per token,     8.93 tokens per second)\n",
      "llama_print_timings:       total time =    1881.90 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4580.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1972.74 ms /    77 tokens (   25.62 ms per token,    39.03 tokens per second)\n",
      "llama_print_timings:        eval time =     231.90 ms /     2 runs   (  115.95 ms per token,     8.62 tokens per second)\n",
      "llama_print_timings:       total time =    2379.14 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4354.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2294.88 ms /    93 tokens (   24.68 ms per token,    40.52 tokens per second)\n",
      "llama_print_timings:        eval time =     242.23 ms /     2 runs   (  121.12 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =    2738.26 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4511.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1907.61 ms /    75 tokens (   25.43 ms per token,    39.32 tokens per second)\n",
      "llama_print_timings:        eval time =     224.06 ms /     2 runs   (  112.03 ms per token,     8.93 tokens per second)\n",
      "llama_print_timings:       total time =    2303.37 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4531.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1913.56 ms /    74 tokens (   25.86 ms per token,    38.67 tokens per second)\n",
      "llama_print_timings:        eval time =     221.27 ms /     2 runs   (  110.64 ms per token,     9.04 tokens per second)\n",
      "llama_print_timings:       total time =    2300.59 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4437.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2668.11 ms /   114 tokens (   23.40 ms per token,    42.73 tokens per second)\n",
      "llama_print_timings:        eval time =     239.33 ms /     2 runs   (  119.67 ms per token,     8.36 tokens per second)\n",
      "llama_print_timings:       total time =    3153.33 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4608.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2112.18 ms /    85 tokens (   24.85 ms per token,    40.24 tokens per second)\n",
      "llama_print_timings:        eval time =     226.87 ms /     2 runs   (  113.44 ms per token,     8.82 tokens per second)\n",
      "llama_print_timings:       total time =    2535.44 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.75 ms /     3 runs   (    0.25 ms per token,  4000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1451.16 ms /    60 tokens (   24.19 ms per token,    41.35 tokens per second)\n",
      "llama_print_timings:        eval time =     226.68 ms /     2 runs   (  113.34 ms per token,     8.82 tokens per second)\n",
      "llama_print_timings:       total time =    1840.75 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4680.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1794.79 ms /    69 tokens (   26.01 ms per token,    38.44 tokens per second)\n",
      "llama_print_timings:        eval time =     226.30 ms /     2 runs   (  113.15 ms per token,     8.84 tokens per second)\n",
      "llama_print_timings:       total time =    2178.84 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.21 ms per token,  4651.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1742.49 ms /    66 tokens (   26.40 ms per token,    37.88 tokens per second)\n",
      "llama_print_timings:        eval time =     222.34 ms /     2 runs   (  111.17 ms per token,     9.00 tokens per second)\n",
      "llama_print_timings:       total time =    2110.47 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4497.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2126.70 ms /    85 tokens (   25.02 ms per token,    39.97 tokens per second)\n",
      "llama_print_timings:        eval time =     222.84 ms /     2 runs   (  111.42 ms per token,     8.98 tokens per second)\n",
      "llama_print_timings:       total time =    2542.72 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4511.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1852.59 ms /    73 tokens (   25.38 ms per token,    39.40 tokens per second)\n",
      "llama_print_timings:        eval time =     228.40 ms /     2 runs   (  114.20 ms per token,     8.76 tokens per second)\n",
      "llama_print_timings:       total time =    2242.31 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4316.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1961.29 ms /    77 tokens (   25.47 ms per token,    39.26 tokens per second)\n",
      "llama_print_timings:        eval time =     225.72 ms /     2 runs   (  112.86 ms per token,     8.86 tokens per second)\n",
      "llama_print_timings:       total time =    2368.82 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4709.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2500.49 ms /   104 tokens (   24.04 ms per token,    41.59 tokens per second)\n",
      "llama_print_timings:        eval time =     243.54 ms /     2 runs   (  121.77 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =    2967.53 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4545.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2356.60 ms /    96 tokens (   24.55 ms per token,    40.74 tokens per second)\n",
      "llama_print_timings:        eval time =     244.36 ms /     2 runs   (  122.18 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =    2807.60 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     3 runs   (    0.24 ms per token,  4207.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2448.30 ms /   101 tokens (   24.24 ms per token,    41.25 tokens per second)\n",
      "llama_print_timings:        eval time =     245.22 ms /     2 runs   (  122.61 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =    2919.23 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4594.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1330.06 ms /    55 tokens (   24.18 ms per token,    41.35 tokens per second)\n",
      "llama_print_timings:        eval time =     239.56 ms /     2 runs   (  119.78 ms per token,     8.35 tokens per second)\n",
      "llama_print_timings:       total time =    1710.91 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4643.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1543.96 ms /    63 tokens (   24.51 ms per token,    40.80 tokens per second)\n",
      "llama_print_timings:        eval time =     223.07 ms /     2 runs   (  111.54 ms per token,     8.97 tokens per second)\n",
      "llama_print_timings:       total time =    1925.28 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4457.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2103.02 ms /    84 tokens (   25.04 ms per token,    39.94 tokens per second)\n",
      "llama_print_timings:        eval time =     233.45 ms /     2 runs   (  116.73 ms per token,     8.57 tokens per second)\n",
      "llama_print_timings:       total time =    2528.42 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4464.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1817.24 ms /    71 tokens (   25.59 ms per token,    39.07 tokens per second)\n",
      "llama_print_timings:        eval time =     227.46 ms /     2 runs   (  113.73 ms per token,     8.79 tokens per second)\n",
      "llama_print_timings:       total time =    2202.92 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4552.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1483.68 ms /    62 tokens (   23.93 ms per token,    41.79 tokens per second)\n",
      "llama_print_timings:        eval time =     226.00 ms /     2 runs   (  113.00 ms per token,     8.85 tokens per second)\n",
      "llama_print_timings:       total time =    1880.21 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4761.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2163.45 ms /    88 tokens (   24.58 ms per token,    40.68 tokens per second)\n",
      "llama_print_timings:        eval time =     232.19 ms /     2 runs   (  116.09 ms per token,     8.61 tokens per second)\n",
      "llama_print_timings:       total time =    2602.42 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4777.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2772.67 ms /   118 tokens (   23.50 ms per token,    42.56 tokens per second)\n",
      "llama_print_timings:        eval time =     244.93 ms /     2 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =    3269.68 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /     3 runs   (    0.24 ms per token,  4143.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2017.13 ms /    80 tokens (   25.21 ms per token,    39.66 tokens per second)\n",
      "llama_print_timings:        eval time =     222.05 ms /     2 runs   (  111.03 ms per token,     9.01 tokens per second)\n",
      "llama_print_timings:       total time =    2417.92 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4594.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1458.34 ms /    60 tokens (   24.31 ms per token,    41.14 tokens per second)\n",
      "llama_print_timings:        eval time =     230.90 ms /     2 runs   (  115.45 ms per token,     8.66 tokens per second)\n",
      "llama_print_timings:       total time =    1866.94 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4411.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2458.44 ms /   102 tokens (   24.10 ms per token,    41.49 tokens per second)\n",
      "llama_print_timings:        eval time =     250.30 ms /     2 runs   (  125.15 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =    2927.32 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4702.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2523.53 ms /   106 tokens (   23.81 ms per token,    42.00 tokens per second)\n",
      "llama_print_timings:        eval time =     240.62 ms /     2 runs   (  120.31 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =    2992.77 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4354.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2177.67 ms /    88 tokens (   24.75 ms per token,    40.41 tokens per second)\n",
      "llama_print_timings:        eval time =     232.43 ms /     2 runs   (  116.22 ms per token,     8.60 tokens per second)\n",
      "llama_print_timings:       total time =    2601.07 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4524.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1876.94 ms /    73 tokens (   25.71 ms per token,    38.89 tokens per second)\n",
      "llama_print_timings:        eval time =     222.50 ms /     2 runs   (  111.25 ms per token,     8.99 tokens per second)\n",
      "llama_print_timings:       total time =    2271.53 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     3 runs   (    0.24 ms per token,  4195.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2108.38 ms /    84 tokens (   25.10 ms per token,    39.84 tokens per second)\n",
      "llama_print_timings:        eval time =     231.29 ms /     2 runs   (  115.64 ms per token,     8.65 tokens per second)\n",
      "llama_print_timings:       total time =    2527.24 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /     3 runs   (    0.24 ms per token,  4149.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1873.95 ms /    73 tokens (   25.67 ms per token,    38.96 tokens per second)\n",
      "llama_print_timings:        eval time =     226.17 ms /     2 runs   (  113.09 ms per token,     8.84 tokens per second)\n",
      "llama_print_timings:       total time =    2266.93 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4418.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2703.28 ms /   114 tokens (   23.71 ms per token,    42.17 tokens per second)\n",
      "llama_print_timings:        eval time =     243.50 ms /     2 runs   (  121.75 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =    3189.57 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4615.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1820.54 ms /    70 tokens (   26.01 ms per token,    38.45 tokens per second)\n",
      "llama_print_timings:        eval time =     228.19 ms /     2 runs   (  114.09 ms per token,     8.76 tokens per second)\n",
      "llama_print_timings:       total time =    2211.56 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /     3 runs   (    0.25 ms per token,  3952.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2599.38 ms /   109 tokens (   23.85 ms per token,    41.93 tokens per second)\n",
      "llama_print_timings:        eval time =     242.28 ms /     2 runs   (  121.14 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =    3083.01 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4524.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1348.81 ms /    56 tokens (   24.09 ms per token,    41.52 tokens per second)\n",
      "llama_print_timings:        eval time =     246.91 ms /     2 runs   (  123.45 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =    1731.81 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4497.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1541.00 ms /    64 tokens (   24.08 ms per token,    41.53 tokens per second)\n",
      "llama_print_timings:        eval time =     221.81 ms /     2 runs   (  110.90 ms per token,     9.02 tokens per second)\n",
      "llama_print_timings:       total time =    1927.49 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4573.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2153.07 ms /    87 tokens (   24.75 ms per token,    40.41 tokens per second)\n",
      "llama_print_timings:        eval time =     223.75 ms /     2 runs   (  111.88 ms per token,     8.94 tokens per second)\n",
      "llama_print_timings:       total time =    2565.53 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4601.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1790.25 ms /    66 tokens (   27.12 ms per token,    36.87 tokens per second)\n",
      "llama_print_timings:        eval time =     222.87 ms /     2 runs   (  111.44 ms per token,     8.97 tokens per second)\n",
      "llama_print_timings:       total time =    2171.86 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4329.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2395.46 ms /    99 tokens (   24.20 ms per token,    41.33 tokens per second)\n",
      "llama_print_timings:        eval time =     248.94 ms /     2 runs   (  124.47 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =    2862.97 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3006.99 ms /   127 tokens (   23.68 ms per token,    42.23 tokens per second)\n",
      "llama_print_timings:        eval time =     257.79 ms /     2 runs   (  128.90 ms per token,     7.76 tokens per second)\n",
      "llama_print_timings:       total time =    3541.45 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4643.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1791.58 ms /    69 tokens (   25.96 ms per token,    38.51 tokens per second)\n",
      "llama_print_timings:        eval time =     224.64 ms /     2 runs   (  112.32 ms per token,     8.90 tokens per second)\n",
      "llama_print_timings:       total time =    2167.84 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4531.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2288.04 ms /    92 tokens (   24.87 ms per token,    40.21 tokens per second)\n",
      "llama_print_timings:        eval time =     242.80 ms /     2 runs   (  121.40 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =    2731.60 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4559.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1305.29 ms /    54 tokens (   24.17 ms per token,    41.37 tokens per second)\n",
      "llama_print_timings:        eval time =     237.12 ms /     2 runs   (  118.56 ms per token,     8.43 tokens per second)\n",
      "llama_print_timings:       total time =    1669.71 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4360.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2194.01 ms /    88 tokens (   24.93 ms per token,    40.11 tokens per second)\n",
      "llama_print_timings:        eval time =     232.40 ms /     2 runs   (  116.20 ms per token,     8.61 tokens per second)\n",
      "llama_print_timings:       total time =    2618.37 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     3 runs   (    0.24 ms per token,  4237.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2234.29 ms /    91 tokens (   24.55 ms per token,    40.73 tokens per second)\n",
      "llama_print_timings:        eval time =     241.72 ms /     2 runs   (  120.86 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =    2673.46 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4531.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2148.24 ms /    87 tokens (   24.69 ms per token,    40.50 tokens per second)\n",
      "llama_print_timings:        eval time =     224.06 ms /     2 runs   (  112.03 ms per token,     8.93 tokens per second)\n",
      "llama_print_timings:       total time =    2563.69 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4746.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2045.34 ms /    81 tokens (   25.25 ms per token,    39.60 tokens per second)\n",
      "llama_print_timings:        eval time =     222.53 ms /     2 runs   (  111.27 ms per token,     8.99 tokens per second)\n",
      "llama_print_timings:       total time =    2444.06 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /     3 runs   (    0.24 ms per token,  4155.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1970.84 ms /    77 tokens (   25.60 ms per token,    39.07 tokens per second)\n",
      "llama_print_timings:        eval time =     230.25 ms /     2 runs   (  115.12 ms per token,     8.69 tokens per second)\n",
      "llama_print_timings:       total time =    2375.08 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4379.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1402.55 ms /    58 tokens (   24.18 ms per token,    41.35 tokens per second)\n",
      "llama_print_timings:        eval time =     234.30 ms /     2 runs   (  117.15 ms per token,     8.54 tokens per second)\n",
      "llama_print_timings:       total time =    1788.26 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4545.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2124.87 ms /    85 tokens (   25.00 ms per token,    40.00 tokens per second)\n",
      "llama_print_timings:        eval time =     230.97 ms /     2 runs   (  115.49 ms per token,     8.66 tokens per second)\n",
      "llama_print_timings:       total time =    2539.98 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4636.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2054.41 ms /    83 tokens (   24.75 ms per token,    40.40 tokens per second)\n",
      "llama_print_timings:        eval time =     223.70 ms /     2 runs   (  111.85 ms per token,     8.94 tokens per second)\n",
      "llama_print_timings:       total time =    2464.76 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4622.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1833.93 ms /    70 tokens (   26.20 ms per token,    38.17 tokens per second)\n",
      "llama_print_timings:        eval time =     220.76 ms /     2 runs   (  110.38 ms per token,     9.06 tokens per second)\n",
      "llama_print_timings:       total time =    2210.83 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /    16 runs   (    0.22 ms per token,  4620.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1814.75 ms /    70 tokens (   25.93 ms per token,    38.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1671.12 ms /    15 runs   (  111.41 ms per token,     8.98 tokens per second)\n",
      "llama_print_timings:       total time =    3678.62 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4373.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1763.69 ms /    67 tokens (   26.32 ms per token,    37.99 tokens per second)\n",
      "llama_print_timings:        eval time =     231.82 ms /     2 runs   (  115.91 ms per token,     8.63 tokens per second)\n",
      "llama_print_timings:       total time =    2151.48 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4643.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2062.91 ms /    83 tokens (   24.85 ms per token,    40.23 tokens per second)\n",
      "llama_print_timings:        eval time =     221.84 ms /     2 runs   (  110.92 ms per token,     9.02 tokens per second)\n",
      "llama_print_timings:       total time =    2466.20 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4431.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1392.94 ms /    58 tokens (   24.02 ms per token,    41.64 tokens per second)\n",
      "llama_print_timings:        eval time =     251.40 ms /     2 runs   (  125.70 ms per token,     7.96 tokens per second)\n",
      "llama_print_timings:       total time =    1804.93 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4524.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2945.31 ms /   125 tokens (   23.56 ms per token,    42.44 tokens per second)\n",
      "llama_print_timings:        eval time =     257.44 ms /     2 runs   (  128.72 ms per token,     7.77 tokens per second)\n",
      "llama_print_timings:       total time =    3476.16 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4497.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1994.92 ms /    79 tokens (   25.25 ms per token,    39.60 tokens per second)\n",
      "llama_print_timings:        eval time =     225.99 ms /     2 runs   (  112.99 ms per token,     8.85 tokens per second)\n",
      "llama_print_timings:       total time =    2403.11 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4823.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2017.47 ms /    80 tokens (   25.22 ms per token,    39.65 tokens per second)\n",
      "llama_print_timings:        eval time =     221.75 ms /     2 runs   (  110.88 ms per token,     9.02 tokens per second)\n",
      "llama_print_timings:       total time =    2412.08 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4477.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1862.88 ms /    72 tokens (   25.87 ms per token,    38.65 tokens per second)\n",
      "llama_print_timings:        eval time =     225.78 ms /     2 runs   (  112.89 ms per token,     8.86 tokens per second)\n",
      "llama_print_timings:       total time =    2256.46 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4538.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2251.76 ms /    92 tokens (   24.48 ms per token,    40.86 tokens per second)\n",
      "llama_print_timings:        eval time =     242.49 ms /     2 runs   (  121.25 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =    2693.08 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4601.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2933.70 ms /   123 tokens (   23.85 ms per token,    41.93 tokens per second)\n",
      "llama_print_timings:        eval time =     260.52 ms /     2 runs   (  130.26 ms per token,     7.68 tokens per second)\n",
      "llama_print_timings:       total time =    3455.92 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4398.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2602.46 ms /   108 tokens (   24.10 ms per token,    41.50 tokens per second)\n",
      "llama_print_timings:        eval time =     244.58 ms /     2 runs   (  122.29 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =    3079.90 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4511.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2459.13 ms /   101 tokens (   24.35 ms per token,    41.07 tokens per second)\n",
      "llama_print_timings:        eval time =     241.89 ms /     2 runs   (  120.95 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =    2917.82 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4451.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1848.91 ms /    71 tokens (   26.04 ms per token,    38.40 tokens per second)\n",
      "llama_print_timings:        eval time =     223.35 ms /     2 runs   (  111.68 ms per token,     8.95 tokens per second)\n",
      "llama_print_timings:       total time =    2227.97 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4594.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1798.43 ms /    68 tokens (   26.45 ms per token,    37.81 tokens per second)\n",
      "llama_print_timings:        eval time =     227.42 ms /     2 runs   (  113.71 ms per token,     8.79 tokens per second)\n",
      "llama_print_timings:       total time =    2181.56 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4823.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1995.00 ms /    79 tokens (   25.25 ms per token,    39.60 tokens per second)\n",
      "llama_print_timings:        eval time =     221.43 ms /     2 runs   (  110.71 ms per token,     9.03 tokens per second)\n",
      "llama_print_timings:       total time =    2389.99 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       3.44 ms /    16 runs   (    0.22 ms per token,  4645.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1439.96 ms /    59 tokens (   24.41 ms per token,    40.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1692.23 ms /    15 runs   (  112.82 ms per token,     8.86 tokens per second)\n",
      "llama_print_timings:       total time =    3331.73 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4665.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2596.36 ms /   109 tokens (   23.82 ms per token,    41.98 tokens per second)\n",
      "llama_print_timings:        eval time =     244.58 ms /     2 runs   (  122.29 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =    3084.10 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4444.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2201.00 ms /    89 tokens (   24.73 ms per token,    40.44 tokens per second)\n",
      "llama_print_timings:        eval time =     253.90 ms /     2 runs   (  126.95 ms per token,     7.88 tokens per second)\n",
      "llama_print_timings:       total time =    2649.97 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4622.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1423.06 ms /    59 tokens (   24.12 ms per token,    41.46 tokens per second)\n",
      "llama_print_timings:        eval time =     227.64 ms /     2 runs   (  113.82 ms per token,     8.79 tokens per second)\n",
      "llama_print_timings:       total time =    1807.43 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4379.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2435.69 ms /   100 tokens (   24.36 ms per token,    41.06 tokens per second)\n",
      "llama_print_timings:        eval time =     241.61 ms /     2 runs   (  120.80 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =    2899.35 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4658.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1894.89 ms /    74 tokens (   25.61 ms per token,    39.05 tokens per second)\n",
      "llama_print_timings:        eval time =     223.66 ms /     2 runs   (  111.83 ms per token,     8.94 tokens per second)\n",
      "llama_print_timings:       total time =    2298.07 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4601.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2106.38 ms /    85 tokens (   24.78 ms per token,    40.35 tokens per second)\n",
      "llama_print_timings:        eval time =     221.65 ms /     2 runs   (  110.83 ms per token,     9.02 tokens per second)\n",
      "llama_print_timings:       total time =    2521.08 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     3 runs   (    0.27 ms per token,  3717.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1764.56 ms /    67 tokens (   26.34 ms per token,    37.97 tokens per second)\n",
      "llama_print_timings:        eval time =     225.21 ms /     2 runs   (  112.60 ms per token,     8.88 tokens per second)\n",
      "llama_print_timings:       total time =    2146.29 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4566.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1736.95 ms /    65 tokens (   26.72 ms per token,    37.42 tokens per second)\n",
      "llama_print_timings:        eval time =     226.52 ms /     2 runs   (  113.26 ms per token,     8.83 tokens per second)\n",
      "llama_print_timings:       total time =    2114.77 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4464.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2207.71 ms /    90 tokens (   24.53 ms per token,    40.77 tokens per second)\n",
      "llama_print_timings:        eval time =     242.24 ms /     2 runs   (  121.12 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =    2660.78 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4444.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2624.05 ms /   110 tokens (   23.85 ms per token,    41.92 tokens per second)\n",
      "llama_print_timings:        eval time =     243.59 ms /     2 runs   (  121.79 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =    3104.50 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     3 runs   (    0.24 ms per token,  4201.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1236.48 ms /    51 tokens (   24.24 ms per token,    41.25 tokens per second)\n",
      "llama_print_timings:        eval time =     239.31 ms /     2 runs   (  119.66 ms per token,     8.36 tokens per second)\n",
      "llama_print_timings:       total time =    1596.21 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4470.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2260.96 ms /    92 tokens (   24.58 ms per token,    40.69 tokens per second)\n",
      "llama_print_timings:        eval time =     242.18 ms /     2 runs   (  121.09 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =    2702.75 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4424.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1733.07 ms /    66 tokens (   26.26 ms per token,    38.08 tokens per second)\n",
      "llama_print_timings:        eval time =     224.67 ms /     2 runs   (  112.33 ms per token,     8.90 tokens per second)\n",
      "llama_print_timings:       total time =    2109.10 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4291.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1891.44 ms /    74 tokens (   25.56 ms per token,    39.12 tokens per second)\n",
      "llama_print_timings:        eval time =     227.01 ms /     2 runs   (  113.51 ms per token,     8.81 tokens per second)\n",
      "llama_print_timings:       total time =    2288.75 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4497.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2165.96 ms /    88 tokens (   24.61 ms per token,    40.63 tokens per second)\n",
      "llama_print_timings:        eval time =     246.35 ms /     2 runs   (  123.17 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =    2606.77 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4464.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2510.67 ms /   103 tokens (   24.38 ms per token,    41.02 tokens per second)\n",
      "llama_print_timings:        eval time =     243.21 ms /     2 runs   (  121.60 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =    2976.81 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.73 ms /     3 runs   (    0.24 ms per token,  4103.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1909.51 ms /    75 tokens (   25.46 ms per token,    39.28 tokens per second)\n",
      "llama_print_timings:        eval time =     227.43 ms /     2 runs   (  113.72 ms per token,     8.79 tokens per second)\n",
      "llama_print_timings:       total time =    2312.57 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4341.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1988.28 ms /    78 tokens (   25.49 ms per token,    39.23 tokens per second)\n",
      "llama_print_timings:        eval time =     221.09 ms /     2 runs   (  110.54 ms per token,     9.05 tokens per second)\n",
      "llama_print_timings:       total time =    2378.27 ms /    80 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# change paths appropriately\n",
    "# make sure the output filename is the same as the reference filename for the scoring program\n",
    "path_val_model_aware = \"../raw/SHROOM_dev-v2/val.model-aware.v2.json\"\n",
    "path_val_model_aware_output = \"./val.model-aware.json\" \n",
    "\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import tqdm.notebook as tqdm\n",
    "seed_val = 442\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "\n",
    "# simple JSON loading\n",
    "with open(path_val_model_aware, 'r') as istr:\n",
    "    data_val_all = json.load(istr)\n",
    "num_sample = len(data_val_all)\n",
    "print(num_sample)\n",
    "\n",
    "output_json = []\n",
    "labels = [\"Not Hallucination\", \"Hallucination\"]\n",
    "\"\"\"\n",
    "SelfCheckGPT Usage: (LLM) Prompt\n",
    "https://github.com/potsawee/selfcheckgpt\n",
    "Context: {}\n",
    "Sentence: {}\n",
    "Is the sentence supported by the context above?\n",
    "Answer Yes or No:\n",
    "\"\"\"\n",
    "for i in tqdm.trange(num_sample):\n",
    "    task = str(data_val_all[i]['task'])\n",
    "    if run_on_test:\n",
    "        # test splits will contain ids to ensure correct alignment before scoring\n",
    "        id = int(data_val_all[i]['id'])\n",
    "    hyp = str(data_val_all[i]['hyp'])\n",
    "    src = str(data_val_all[i]['src'])\n",
    "    tgt = str(data_val_all[i]['tgt'])\n",
    "\n",
    "    if task == \"PG\":\n",
    "        context = f\"Context: {src}\"\n",
    "    else: #i.e. task == \"MT\" or task == \"DM\":\n",
    "        context = f\"Context: {tgt}\"\n",
    "\n",
    "    sentence = f\"Sentence: {hyp}\"\n",
    "    message = f\"{context}\\n{sentence}\\nIs the Sentence supported by the Context above? Answer using ONLY yes or no:\"\n",
    "    prompt = f\"<s>[INST] {message} [/INST]\"\n",
    "\n",
    "    response = lcpp_llm(\n",
    "        prompt=prompt,\n",
    "        temperature= 0.0,\n",
    "        logprobs=1,\n",
    "    )\n",
    "    answer = str(response[\"choices\"][0][\"text\"]).strip().lower()\n",
    "    if answer.startswith(\"yes\"):\n",
    "        output_label = \"Not Hallucination\"\n",
    "        prob = 1-float(np.exp(response[\"choices\"][0][\"logprobs\"][\"token_logprobs\"][0]))\n",
    "    if answer.startswith(\"no\"):\n",
    "        output_label = \"Hallucination\"\n",
    "        prob = float(np.exp(response[\"choices\"][0][\"logprobs\"][\"token_logprobs\"][0]))\n",
    "    if not answer.startswith(\"no\") and not answer.startswith(\"yes\"):\n",
    "        idx_random = random.randint(0,len(labels)-1)\n",
    "        output_label = labels[idx_random]\n",
    "        prob = float(0.5)\n",
    "\n",
    "    item_to_json = {\"label\":output_label, \"p(Hallucination)\":prob}\n",
    "    if run_on_test:\n",
    "        item_to_json['id'] = id\n",
    "    \n",
    "    output_json.append(item_to_json)\n",
    "\n",
    "\n",
    "f = open(path_val_model_aware_output, 'w', encoding='utf-8')\n",
    "json.dump(output_json, f)\n",
    "f.close()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running on the model-agnostic track data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "aff193ecfc2e4d5a8b3ddd4f63604e63",
      "48be64dd9497468f83d73bd119591271",
      "04b2b191f387469facbc7e0f63edd957",
      "e225b3758fa24df3a0d6f1a039d3220a",
      "aeaed97ed3f441e9aa2ce24c87e02d87",
      "cebd82bbc195424a908c9527ee1a21d3",
      "8665cfefbc984fc4873e73cd96d6c018",
      "1c18583fabf94cf88d89e9d0ad83cd46",
      "16ceb8ceabea4adeb2ed5d3c62a52e87",
      "6c4a2676871e492897d305d6d9a6fac9",
      "f432e32a03704652a5bcd21c7ce36abd",
      "86da540e05824f2c95b5c8bea9b4581d",
      "d1f94d67f08449439e3191bcdf87c6bf",
      "cb886b4dac084c0290e1fd1c229b092e",
      "8b8fd80c79c54e479b15f798bc545b96",
      "3e1566a3d2f64b5fbbaf7cc51b9c9902",
      "ac217ebd99d94729ac89ed81fc0a0ab5",
      "2b25549d8eac4efd99bf1beb4fb26b0c",
      "4facca9ecbd74aa5b4dc474634686064",
      "f52b2088b6724e6dad9ee18ba364c009",
      "08db236b9ee74ccb9ac456bf09e298e1",
      "977e8b1928ec42a285804dcc8fc13cb5",
      "a0f2fe09ab0a4a21acda513f96bb7faf",
      "4f891d2316604dd08cd5ffd22c8854d9",
      "0ea36c0ff6cd4559bf733fb73ff82693",
      "de38e0a8f5a24cbdbf755db3cfd399ec",
      "9f4e1bc76cfb4643877686a6f0271b52",
      "5c70248a7e6e45199ed626fa68037174",
      "07bb3c8d23084467b680d0f8be879bcd",
      "fca89659d3684477bb46613bbb96383d",
      "265b13864e334d2d8875d1de157c428a",
      "823cdbf0fa2c43559d01de4664258a86",
      "e5ae38c7214c4f05974de99e5d5c3485"
     ]
    },
    "id": "-2KYuv-H-LYU",
    "outputId": "55d8a874-ee9c-4833-f426-279caf6813ec"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac1f249dd2d34068b77500e14f275114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f916b2176436429a9ddb02ff5faac997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4ad8a34898f4b58a9299a110c45e8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating val split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    val: Dataset({\n",
      "        features: ['label', 'src', 'labels', 'model', 'ref', 'task', 'tgt', 'p(Hallucination)', 'hyp'],\n",
      "        num_rows: 499\n",
      "    })\n",
      "})\n",
      "499\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c8d81f63a894fb4b3e3c9d4ba471b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/499 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4464.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1268.48 ms /    50 tokens (   25.37 ms per token,    39.42 tokens per second)\n",
      "llama_print_timings:        eval time =     203.24 ms /     2 runs   (  101.62 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    1584.00 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4934.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     936.86 ms /    36 tokens (   26.02 ms per token,    38.43 tokens per second)\n",
      "llama_print_timings:        eval time =     216.15 ms /     2 runs   (  108.08 ms per token,     9.25 tokens per second)\n",
      "llama_print_timings:       total time =    1238.07 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4769.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1188.96 ms /    49 tokens (   24.26 ms per token,    41.21 tokens per second)\n",
      "llama_print_timings:        eval time =     202.81 ms /     2 runs   (  101.41 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =    1502.32 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4777.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1452.03 ms /    61 tokens (   23.80 ms per token,    42.01 tokens per second)\n",
      "llama_print_timings:        eval time =     223.97 ms /     2 runs   (  111.98 ms per token,     8.93 tokens per second)\n",
      "llama_print_timings:       total time =    1811.29 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4629.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1451.29 ms /    61 tokens (   23.79 ms per token,    42.03 tokens per second)\n",
      "llama_print_timings:        eval time =     220.82 ms /     2 runs   (  110.41 ms per token,     9.06 tokens per second)\n",
      "llama_print_timings:       total time =    1807.01 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4694.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1064.74 ms /    43 tokens (   24.76 ms per token,    40.39 tokens per second)\n",
      "llama_print_timings:        eval time =     204.93 ms /     2 runs   (  102.46 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    1366.65 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4379.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1806.63 ms /    73 tokens (   24.75 ms per token,    40.41 tokens per second)\n",
      "llama_print_timings:        eval time =     224.11 ms /     2 runs   (  112.05 ms per token,     8.92 tokens per second)\n",
      "llama_print_timings:       total time =    2189.41 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4622.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1303.14 ms /    56 tokens (   23.27 ms per token,    42.97 tokens per second)\n",
      "llama_print_timings:        eval time =     225.95 ms /     2 runs   (  112.97 ms per token,     8.85 tokens per second)\n",
      "llama_print_timings:       total time =    1652.91 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4680.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1223.81 ms /    52 tokens (   23.53 ms per token,    42.49 tokens per second)\n",
      "llama_print_timings:        eval time =     199.88 ms /     2 runs   (   99.94 ms per token,    10.01 tokens per second)\n",
      "llama_print_timings:       total time =    1542.05 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4531.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1423.18 ms /    59 tokens (   24.12 ms per token,    41.46 tokens per second)\n",
      "llama_print_timings:        eval time =     221.72 ms /     2 runs   (  110.86 ms per token,     9.02 tokens per second)\n",
      "llama_print_timings:       total time =    1776.87 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4491.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1330.42 ms /    56 tokens (   23.76 ms per token,    42.09 tokens per second)\n",
      "llama_print_timings:        eval time =     215.93 ms /     2 runs   (  107.96 ms per token,     9.26 tokens per second)\n",
      "llama_print_timings:       total time =    1670.85 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4724.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1285.97 ms /    54 tokens (   23.81 ms per token,    41.99 tokens per second)\n",
      "llama_print_timings:        eval time =     202.18 ms /     2 runs   (  101.09 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =    1610.26 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     3 runs   (    0.24 ms per token,  4237.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1791.84 ms /    72 tokens (   24.89 ms per token,    40.18 tokens per second)\n",
      "llama_print_timings:        eval time =     225.42 ms /     2 runs   (  112.71 ms per token,     8.87 tokens per second)\n",
      "llama_print_timings:       total time =    2179.01 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4504.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     992.36 ms /    39 tokens (   25.45 ms per token,    39.30 tokens per second)\n",
      "llama_print_timings:        eval time =     216.20 ms /     2 runs   (  108.10 ms per token,     9.25 tokens per second)\n",
      "llama_print_timings:       total time =    1303.19 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4622.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1254.46 ms /    53 tokens (   23.67 ms per token,    42.25 tokens per second)\n",
      "llama_print_timings:        eval time =     203.07 ms /     2 runs   (  101.53 ms per token,     9.85 tokens per second)\n",
      "llama_print_timings:       total time =    1576.04 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4823.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1323.16 ms /    56 tokens (   23.63 ms per token,    42.32 tokens per second)\n",
      "llama_print_timings:        eval time =     212.10 ms /     2 runs   (  106.05 ms per token,     9.43 tokens per second)\n",
      "llama_print_timings:       total time =    1660.38 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4629.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1431.91 ms /    60 tokens (   23.87 ms per token,    41.90 tokens per second)\n",
      "llama_print_timings:        eval time =     219.11 ms /     2 runs   (  109.55 ms per token,     9.13 tokens per second)\n",
      "llama_print_timings:       total time =    1786.36 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  5000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1201.85 ms /    50 tokens (   24.04 ms per token,    41.60 tokens per second)\n",
      "llama_print_timings:        eval time =     205.16 ms /     2 runs   (  102.58 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =    1519.24 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4754.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1266.04 ms /    53 tokens (   23.89 ms per token,    41.86 tokens per second)\n",
      "llama_print_timings:        eval time =     200.35 ms /     2 runs   (  100.18 ms per token,     9.98 tokens per second)\n",
      "llama_print_timings:       total time =    1585.59 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4587.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1477.31 ms /    63 tokens (   23.45 ms per token,    42.64 tokens per second)\n",
      "llama_print_timings:        eval time =     221.87 ms /     2 runs   (  110.93 ms per token,     9.01 tokens per second)\n",
      "llama_print_timings:       total time =    1839.62 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4687.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1287.87 ms /    53 tokens (   24.30 ms per token,    41.15 tokens per second)\n",
      "llama_print_timings:        eval time =     202.05 ms /     2 runs   (  101.02 ms per token,     9.90 tokens per second)\n",
      "llama_print_timings:       total time =    1607.15 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4761.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1135.13 ms /    47 tokens (   24.15 ms per token,    41.40 tokens per second)\n",
      "llama_print_timings:        eval time =     206.45 ms /     2 runs   (  103.22 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    1447.10 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4424.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1908.13 ms /    79 tokens (   24.15 ms per token,    41.40 tokens per second)\n",
      "llama_print_timings:        eval time =     231.80 ms /     2 runs   (  115.90 ms per token,     8.63 tokens per second)\n",
      "llama_print_timings:       total time =    2310.54 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  5033.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     921.32 ms /    36 tokens (   25.59 ms per token,    39.07 tokens per second)\n",
      "llama_print_timings:        eval time =     210.16 ms /     2 runs   (  105.08 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =    1215.39 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4934.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1143.73 ms /    47 tokens (   24.33 ms per token,    41.09 tokens per second)\n",
      "llama_print_timings:        eval time =     206.05 ms /     2 runs   (  103.02 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =    1456.18 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4504.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1291.10 ms /    55 tokens (   23.47 ms per token,    42.60 tokens per second)\n",
      "llama_print_timings:        eval time =     213.05 ms /     2 runs   (  106.52 ms per token,     9.39 tokens per second)\n",
      "llama_print_timings:       total time =    1624.36 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4636.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1487.44 ms /    64 tokens (   23.24 ms per token,    43.03 tokens per second)\n",
      "llama_print_timings:        eval time =     219.61 ms /     2 runs   (  109.81 ms per token,     9.11 tokens per second)\n",
      "llama_print_timings:       total time =    1848.47 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  5000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.23 ms /    48 tokens (   24.21 ms per token,    41.30 tokens per second)\n",
      "llama_print_timings:        eval time =     203.97 ms /     2 runs   (  101.99 ms per token,     9.81 tokens per second)\n",
      "llama_print_timings:       total time =    1474.90 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4702.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1211.90 ms /    51 tokens (   23.76 ms per token,    42.08 tokens per second)\n",
      "llama_print_timings:        eval time =     204.00 ms /     2 runs   (  102.00 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =    1529.60 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4601.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1215.21 ms /    51 tokens (   23.83 ms per token,    41.97 tokens per second)\n",
      "llama_print_timings:        eval time =     211.20 ms /     2 runs   (  105.60 ms per token,     9.47 tokens per second)\n",
      "llama_print_timings:       total time =    1540.71 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4746.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1170.65 ms /    49 tokens (   23.89 ms per token,    41.86 tokens per second)\n",
      "llama_print_timings:        eval time =     203.81 ms /     2 runs   (  101.90 ms per token,     9.81 tokens per second)\n",
      "llama_print_timings:       total time =    1485.39 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4470.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1294.98 ms /    55 tokens (   23.55 ms per token,    42.47 tokens per second)\n",
      "llama_print_timings:        eval time =     201.56 ms /     2 runs   (  100.78 ms per token,     9.92 tokens per second)\n",
      "llama_print_timings:       total time =    1618.75 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  4975.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1323.16 ms /    55 tokens (   24.06 ms per token,    41.57 tokens per second)\n",
      "llama_print_timings:        eval time =     205.68 ms /     2 runs   (  102.84 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    1649.97 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4580.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1261.02 ms /    54 tokens (   23.35 ms per token,    42.82 tokens per second)\n",
      "llama_print_timings:        eval time =     211.48 ms /     2 runs   (  105.74 ms per token,     9.46 tokens per second)\n",
      "llama_print_timings:       total time =    1596.08 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4746.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1250.05 ms /    53 tokens (   23.59 ms per token,    42.40 tokens per second)\n",
      "llama_print_timings:        eval time =     201.44 ms /     2 runs   (  100.72 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:       total time =    1568.67 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4716.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1225.12 ms /    51 tokens (   24.02 ms per token,    41.63 tokens per second)\n",
      "llama_print_timings:        eval time =     202.61 ms /     2 runs   (  101.31 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =    1541.17 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4573.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1305.68 ms /    55 tokens (   23.74 ms per token,    42.12 tokens per second)\n",
      "llama_print_timings:        eval time =     203.54 ms /     2 runs   (  101.77 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =    1630.85 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  5025.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1116.93 ms /    46 tokens (   24.28 ms per token,    41.18 tokens per second)\n",
      "llama_print_timings:        eval time =     204.88 ms /     2 runs   (  102.44 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    1433.79 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4304.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1639.82 ms /    65 tokens (   25.23 ms per token,    39.64 tokens per second)\n",
      "llama_print_timings:        eval time =     220.58 ms /     2 runs   (  110.29 ms per token,     9.07 tokens per second)\n",
      "llama_print_timings:       total time =    2002.36 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4601.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1503.39 ms /    64 tokens (   23.49 ms per token,    42.57 tokens per second)\n",
      "llama_print_timings:        eval time =     220.92 ms /     2 runs   (  110.46 ms per token,     9.05 tokens per second)\n",
      "llama_print_timings:       total time =    1862.88 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4291.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1366.77 ms /    58 tokens (   23.56 ms per token,    42.44 tokens per second)\n",
      "llama_print_timings:        eval time =     221.52 ms /     2 runs   (  110.76 ms per token,     9.03 tokens per second)\n",
      "llama_print_timings:       total time =    1718.30 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4709.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1369.07 ms /    58 tokens (   23.60 ms per token,    42.36 tokens per second)\n",
      "llama_print_timings:        eval time =     222.28 ms /     2 runs   (  111.14 ms per token,     9.00 tokens per second)\n",
      "llama_print_timings:       total time =    1721.12 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4580.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1312.45 ms /    56 tokens (   23.44 ms per token,    42.67 tokens per second)\n",
      "llama_print_timings:        eval time =     221.90 ms /     2 runs   (  110.95 ms per token,     9.01 tokens per second)\n",
      "llama_print_timings:       total time =    1659.73 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4457.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1643.48 ms /    65 tokens (   25.28 ms per token,    39.55 tokens per second)\n",
      "llama_print_timings:        eval time =     226.68 ms /     2 runs   (  113.34 ms per token,     8.82 tokens per second)\n",
      "llama_print_timings:       total time =    2019.24 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.59 ms /     3 runs   (    0.20 ms per token,  5084.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1071.05 ms /    44 tokens (   24.34 ms per token,    41.08 tokens per second)\n",
      "llama_print_timings:        eval time =     205.53 ms /     2 runs   (  102.76 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =    1376.37 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4731.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1200.04 ms /    50 tokens (   24.00 ms per token,    41.67 tokens per second)\n",
      "llama_print_timings:        eval time =     202.53 ms /     2 runs   (  101.26 ms per token,     9.88 tokens per second)\n",
      "llama_print_timings:       total time =    1514.30 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4545.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1332.74 ms /    56 tokens (   23.80 ms per token,    42.02 tokens per second)\n",
      "llama_print_timings:        eval time =     216.88 ms /     2 runs   (  108.44 ms per token,     9.22 tokens per second)\n",
      "llama_print_timings:       total time =    1673.63 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4552.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1678.91 ms /    66 tokens (   25.44 ms per token,    39.31 tokens per second)\n",
      "llama_print_timings:        eval time =     225.55 ms /     2 runs   (  112.77 ms per token,     8.87 tokens per second)\n",
      "llama_print_timings:       total time =    2048.62 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4672.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2637.35 ms /   115 tokens (   22.93 ms per token,    43.60 tokens per second)\n",
      "llama_print_timings:        eval time =     243.04 ms /     2 runs   (  121.52 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =    3125.75 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4545.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.26 ms /    58 tokens (   24.04 ms per token,    41.60 tokens per second)\n",
      "llama_print_timings:        eval time =     225.44 ms /     2 runs   (  112.72 ms per token,     8.87 tokens per second)\n",
      "llama_print_timings:       total time =    1750.75 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4716.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1225.72 ms /    51 tokens (   24.03 ms per token,    41.61 tokens per second)\n",
      "llama_print_timings:        eval time =     198.70 ms /     2 runs   (   99.35 ms per token,    10.07 tokens per second)\n",
      "llama_print_timings:       total time =    1539.82 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4451.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2486.49 ms /   108 tokens (   23.02 ms per token,    43.43 tokens per second)\n",
      "llama_print_timings:        eval time =     244.84 ms /     2 runs   (  122.42 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =    2963.13 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4761.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1008.23 ms /    40 tokens (   25.21 ms per token,    39.67 tokens per second)\n",
      "llama_print_timings:        eval time =     212.15 ms /     2 runs   (  106.07 ms per token,     9.43 tokens per second)\n",
      "llama_print_timings:       total time =    1311.14 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4594.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.79 ms /    53 tokens (   23.66 ms per token,    42.27 tokens per second)\n",
      "llama_print_timings:        eval time =     206.22 ms /     2 runs   (  103.11 ms per token,     9.70 tokens per second)\n",
      "llama_print_timings:       total time =    1578.67 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4724.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1400.87 ms /    59 tokens (   23.74 ms per token,    42.12 tokens per second)\n",
      "llama_print_timings:        eval time =     223.20 ms /     2 runs   (  111.60 ms per token,     8.96 tokens per second)\n",
      "llama_print_timings:       total time =    1754.34 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     3 runs   (    0.26 ms per token,  3826.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1286.60 ms /    54 tokens (   23.83 ms per token,    41.97 tokens per second)\n",
      "llama_print_timings:        eval time =     203.03 ms /     2 runs   (  101.51 ms per token,     9.85 tokens per second)\n",
      "llama_print_timings:       total time =    1610.52 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /     3 runs   (    0.24 ms per token,  4149.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.89 ms /    47 tokens (   26.78 ms per token,    37.33 tokens per second)\n",
      "llama_print_timings:        eval time =     226.12 ms /     2 runs   (  113.06 ms per token,     8.84 tokens per second)\n",
      "llama_print_timings:       total time =    1617.18 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     3 runs   (    0.26 ms per token,  3856.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2009.94 ms /    74 tokens (   27.16 ms per token,    36.82 tokens per second)\n",
      "llama_print_timings:        eval time =     249.35 ms /     2 runs   (  124.68 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =    2467.80 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4672.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.82 ms /    45 tokens (   25.73 ms per token,    38.87 tokens per second)\n",
      "llama_print_timings:        eval time =     211.40 ms /     2 runs   (  105.70 ms per token,     9.46 tokens per second)\n",
      "llama_print_timings:       total time =    1474.33 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4594.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1344.90 ms /    56 tokens (   24.02 ms per token,    41.64 tokens per second)\n",
      "llama_print_timings:        eval time =     210.97 ms /     2 runs   (  105.48 ms per token,     9.48 tokens per second)\n",
      "llama_print_timings:       total time =    1682.98 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4665.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.57 ms /    52 tokens (   23.86 ms per token,    41.92 tokens per second)\n",
      "llama_print_timings:        eval time =     204.01 ms /     2 runs   (  102.00 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =    1560.61 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4687.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1137.43 ms /    47 tokens (   24.20 ms per token,    41.32 tokens per second)\n",
      "llama_print_timings:        eval time =     203.17 ms /     2 runs   (  101.58 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    1455.35 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4518.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1251.10 ms /    53 tokens (   23.61 ms per token,    42.36 tokens per second)\n",
      "llama_print_timings:        eval time =     204.21 ms /     2 runs   (  102.10 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =    1581.66 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4862.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1201.25 ms /    50 tokens (   24.02 ms per token,    41.62 tokens per second)\n",
      "llama_print_timings:        eval time =     202.91 ms /     2 runs   (  101.45 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =    1517.69 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4464.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1101.80 ms /    45 tokens (   24.48 ms per token,    40.84 tokens per second)\n",
      "llama_print_timings:        eval time =     207.50 ms /     2 runs   (  103.75 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =    1419.75 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4566.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1490.13 ms /    64 tokens (   23.28 ms per token,    42.95 tokens per second)\n",
      "llama_print_timings:        eval time =     227.93 ms /     2 runs   (  113.97 ms per token,     8.77 tokens per second)\n",
      "llama_print_timings:       total time =    1858.33 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       3.57 ms /    16 runs   (    0.22 ms per token,  4485.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1399.30 ms /    59 tokens (   23.72 ms per token,    42.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1684.82 ms /    15 runs   (  112.32 ms per token,     8.90 tokens per second)\n",
      "llama_print_timings:       total time =    3258.47 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4672.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1396.74 ms /    59 tokens (   23.67 ms per token,    42.24 tokens per second)\n",
      "llama_print_timings:        eval time =     222.92 ms /     2 runs   (  111.46 ms per token,     8.97 tokens per second)\n",
      "llama_print_timings:       total time =    1750.15 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4687.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1184.27 ms /    49 tokens (   24.17 ms per token,    41.38 tokens per second)\n",
      "llama_print_timings:        eval time =     207.02 ms /     2 runs   (  103.51 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    1501.50 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4279.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1831.31 ms /    75 tokens (   24.42 ms per token,    40.95 tokens per second)\n",
      "llama_print_timings:        eval time =     223.02 ms /     2 runs   (  111.51 ms per token,     8.97 tokens per second)\n",
      "llama_print_timings:       total time =    2219.46 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4769.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     988.71 ms /    39 tokens (   25.35 ms per token,    39.45 tokens per second)\n",
      "llama_print_timings:        eval time =     208.54 ms /     2 runs   (  104.27 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    1286.23 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4950.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1224.55 ms /    52 tokens (   23.55 ms per token,    42.46 tokens per second)\n",
      "llama_print_timings:        eval time =     202.72 ms /     2 runs   (  101.36 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =    1544.39 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4587.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1317.87 ms /    56 tokens (   23.53 ms per token,    42.49 tokens per second)\n",
      "llama_print_timings:        eval time =     225.46 ms /     2 runs   (  112.73 ms per token,     8.87 tokens per second)\n",
      "llama_print_timings:       total time =    1667.38 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4658.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1143.39 ms /    47 tokens (   24.33 ms per token,    41.11 tokens per second)\n",
      "llama_print_timings:        eval time =     201.46 ms /     2 runs   (  100.73 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:       total time =    1451.34 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4815.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1146.96 ms /    47 tokens (   24.40 ms per token,    40.98 tokens per second)\n",
      "llama_print_timings:        eval time =     205.17 ms /     2 runs   (  102.59 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =    1465.93 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /     3 runs   (    0.24 ms per token,  4189.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1107.48 ms /    46 tokens (   24.08 ms per token,    41.54 tokens per second)\n",
      "llama_print_timings:        eval time =     205.00 ms /     2 runs   (  102.50 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    1425.68 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4615.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1185.14 ms /    49 tokens (   24.19 ms per token,    41.35 tokens per second)\n",
      "llama_print_timings:        eval time =     201.00 ms /     2 runs   (  100.50 ms per token,     9.95 tokens per second)\n",
      "llama_print_timings:       total time =    1496.89 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4792.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1000.88 ms /    40 tokens (   25.02 ms per token,    39.96 tokens per second)\n",
      "llama_print_timings:        eval time =     200.04 ms /     2 runs   (  100.02 ms per token,    10.00 tokens per second)\n",
      "llama_print_timings:       total time =    1295.22 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  5008.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     951.59 ms /    38 tokens (   25.04 ms per token,    39.93 tokens per second)\n",
      "llama_print_timings:        eval time =     215.19 ms /     2 runs   (  107.59 ms per token,     9.29 tokens per second)\n",
      "llama_print_timings:       total time =    1253.96 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4304.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1113.24 ms /    45 tokens (   24.74 ms per token,    40.42 tokens per second)\n",
      "llama_print_timings:        eval time =     211.61 ms /     2 runs   (  105.80 ms per token,     9.45 tokens per second)\n",
      "llama_print_timings:       total time =    1429.62 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4538.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.20 ms /    48 tokens (   23.98 ms per token,    41.70 tokens per second)\n",
      "llama_print_timings:        eval time =     206.42 ms /     2 runs   (  103.21 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    1469.16 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  4991.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1066.71 ms /    44 tokens (   24.24 ms per token,    41.25 tokens per second)\n",
      "llama_print_timings:        eval time =     218.18 ms /     2 runs   (  109.09 ms per token,     9.17 tokens per second)\n",
      "llama_print_timings:       total time =    1386.00 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4815.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1193.80 ms /    50 tokens (   23.88 ms per token,    41.88 tokens per second)\n",
      "llama_print_timings:        eval time =     205.01 ms /     2 runs   (  102.50 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    1511.78 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.73 ms /     3 runs   (    0.24 ms per token,  4081.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1148.03 ms /    48 tokens (   23.92 ms per token,    41.81 tokens per second)\n",
      "llama_print_timings:        eval time =     202.78 ms /     2 runs   (  101.39 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =    1462.31 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4680.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1078.47 ms /    44 tokens (   24.51 ms per token,    40.80 tokens per second)\n",
      "llama_print_timings:        eval time =     217.57 ms /     2 runs   (  108.78 ms per token,     9.19 tokens per second)\n",
      "llama_print_timings:       total time =    1396.48 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4615.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1315.65 ms /    55 tokens (   23.92 ms per token,    41.80 tokens per second)\n",
      "llama_print_timings:        eval time =     201.87 ms /     2 runs   (  100.94 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =    1639.97 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.21 ms per token,  4651.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1452.85 ms /    62 tokens (   23.43 ms per token,    42.67 tokens per second)\n",
      "llama_print_timings:        eval time =     225.92 ms /     2 runs   (  112.96 ms per token,     8.85 tokens per second)\n",
      "llama_print_timings:       total time =    1818.53 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4901.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     967.51 ms /    38 tokens (   25.46 ms per token,    39.28 tokens per second)\n",
      "llama_print_timings:        eval time =     220.73 ms /     2 runs   (  110.37 ms per token,     9.06 tokens per second)\n",
      "llama_print_timings:       total time =    1276.12 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4746.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1091.46 ms /    45 tokens (   24.25 ms per token,    41.23 tokens per second)\n",
      "llama_print_timings:        eval time =     206.40 ms /     2 runs   (  103.20 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    1401.98 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.73 ms /     3 runs   (    0.24 ms per token,  4087.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1224.82 ms /    51 tokens (   24.02 ms per token,    41.64 tokens per second)\n",
      "llama_print_timings:        eval time =     204.78 ms /     2 runs   (  102.39 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =    1544.95 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4559.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1348.99 ms /    56 tokens (   24.09 ms per token,    41.51 tokens per second)\n",
      "llama_print_timings:        eval time =     225.33 ms /     2 runs   (  112.66 ms per token,     8.88 tokens per second)\n",
      "llama_print_timings:       total time =    1697.92 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4279.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1428.58 ms /    61 tokens (   23.42 ms per token,    42.70 tokens per second)\n",
      "llama_print_timings:        eval time =     233.84 ms /     2 runs   (  116.92 ms per token,     8.55 tokens per second)\n",
      "llama_print_timings:       total time =    1798.36 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     3 runs   (    0.26 ms per token,  3846.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1665.21 ms /    66 tokens (   25.23 ms per token,    39.63 tokens per second)\n",
      "llama_print_timings:        eval time =     229.60 ms /     2 runs   (  114.80 ms per token,     8.71 tokens per second)\n",
      "llama_print_timings:       total time =    2040.90 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4761.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1118.98 ms /    46 tokens (   24.33 ms per token,    41.11 tokens per second)\n",
      "llama_print_timings:        eval time =     204.22 ms /     2 runs   (  102.11 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =    1435.71 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4942.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1035.28 ms /    41 tokens (   25.25 ms per token,    39.60 tokens per second)\n",
      "llama_print_timings:        eval time =     204.05 ms /     2 runs   (  102.03 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =    1332.31 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4411.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1650.12 ms /    65 tokens (   25.39 ms per token,    39.39 tokens per second)\n",
      "llama_print_timings:        eval time =     220.58 ms /     2 runs   (  110.29 ms per token,     9.07 tokens per second)\n",
      "llama_print_timings:       total time =    2013.51 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4724.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1440.69 ms /    61 tokens (   23.62 ms per token,    42.34 tokens per second)\n",
      "llama_print_timings:        eval time =     224.77 ms /     2 runs   (  112.39 ms per token,     8.90 tokens per second)\n",
      "llama_print_timings:       total time =    1803.08 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  5025.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1038.90 ms /    42 tokens (   24.74 ms per token,    40.43 tokens per second)\n",
      "llama_print_timings:        eval time =     204.99 ms /     2 runs   (  102.49 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    1338.22 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     4 runs   (    0.20 ms per token,  4944.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1094.62 ms /    44 tokens (   24.88 ms per token,    40.20 tokens per second)\n",
      "llama_print_timings:        eval time =     305.49 ms /     3 runs   (  101.83 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =    1505.29 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4784.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1145.40 ms /    47 tokens (   24.37 ms per token,    41.03 tokens per second)\n",
      "llama_print_timings:        eval time =     203.83 ms /     2 runs   (  101.91 ms per token,     9.81 tokens per second)\n",
      "llama_print_timings:       total time =    1465.77 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4665.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1688.90 ms /    68 tokens (   24.84 ms per token,    40.26 tokens per second)\n",
      "llama_print_timings:        eval time =     225.40 ms /     2 runs   (  112.70 ms per token,     8.87 tokens per second)\n",
      "llama_print_timings:       total time =    2069.44 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4942.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1040.38 ms /    42 tokens (   24.77 ms per token,    40.37 tokens per second)\n",
      "llama_print_timings:        eval time =     204.63 ms /     2 runs   (  102.32 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =    1342.39 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4573.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1110.30 ms /    45 tokens (   24.67 ms per token,    40.53 tokens per second)\n",
      "llama_print_timings:        eval time =     212.61 ms /     2 runs   (  106.30 ms per token,     9.41 tokens per second)\n",
      "llama_print_timings:       total time =    1429.49 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4807.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1141.95 ms /    47 tokens (   24.30 ms per token,    41.16 tokens per second)\n",
      "llama_print_timings:        eval time =     203.16 ms /     2 runs   (  101.58 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    1453.25 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4504.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1273.70 ms /    54 tokens (   23.59 ms per token,    42.40 tokens per second)\n",
      "llama_print_timings:        eval time =     205.74 ms /     2 runs   (  102.87 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    1601.26 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4658.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1701.79 ms /    68 tokens (   25.03 ms per token,    39.96 tokens per second)\n",
      "llama_print_timings:        eval time =     228.83 ms /     2 runs   (  114.42 ms per token,     8.74 tokens per second)\n",
      "llama_print_timings:       total time =    2083.00 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4497.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1737.90 ms /    69 tokens (   25.19 ms per token,    39.70 tokens per second)\n",
      "llama_print_timings:        eval time =     225.58 ms /     2 runs   (  112.79 ms per token,     8.87 tokens per second)\n",
      "llama_print_timings:       total time =    2115.08 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4901.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1149.20 ms /    47 tokens (   24.45 ms per token,    40.90 tokens per second)\n",
      "llama_print_timings:        eval time =     201.86 ms /     2 runs   (  100.93 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =    1458.36 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4746.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1093.37 ms /    44 tokens (   24.85 ms per token,    40.24 tokens per second)\n",
      "llama_print_timings:        eval time =     203.75 ms /     2 runs   (  101.88 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =    1398.38 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4815.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1097.11 ms /    45 tokens (   24.38 ms per token,    41.02 tokens per second)\n",
      "llama_print_timings:        eval time =     205.86 ms /     2 runs   (  102.93 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    1415.06 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4573.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1183.66 ms /    49 tokens (   24.16 ms per token,    41.40 tokens per second)\n",
      "llama_print_timings:        eval time =     203.16 ms /     2 runs   (  101.58 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    1497.96 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4761.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1187.75 ms /    49 tokens (   24.24 ms per token,    41.25 tokens per second)\n",
      "llama_print_timings:        eval time =     202.82 ms /     2 runs   (  101.41 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =    1500.53 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4665.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1416.54 ms /    60 tokens (   23.61 ms per token,    42.36 tokens per second)\n",
      "llama_print_timings:        eval time =     220.55 ms /     2 runs   (  110.28 ms per token,     9.07 tokens per second)\n",
      "llama_print_timings:       total time =    1772.75 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4398.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1409.12 ms /    59 tokens (   23.88 ms per token,    41.87 tokens per second)\n",
      "llama_print_timings:        eval time =     234.66 ms /     2 runs   (  117.33 ms per token,     8.52 tokens per second)\n",
      "llama_print_timings:       total time =    1778.34 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4807.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1134.84 ms /    47 tokens (   24.15 ms per token,    41.42 tokens per second)\n",
      "llama_print_timings:        eval time =     204.25 ms /     2 runs   (  102.13 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =    1446.73 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4484.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1406.30 ms /    59 tokens (   23.84 ms per token,    41.95 tokens per second)\n",
      "llama_print_timings:        eval time =     222.02 ms /     2 runs   (  111.01 ms per token,     9.01 tokens per second)\n",
      "llama_print_timings:       total time =    1758.62 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4731.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.50 ms /    48 tokens (   24.34 ms per token,    41.08 tokens per second)\n",
      "llama_print_timings:        eval time =     203.58 ms /     2 runs   (  101.79 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =    1493.43 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4878.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1288.93 ms /    55 tokens (   23.44 ms per token,    42.67 tokens per second)\n",
      "llama_print_timings:        eval time =     203.42 ms /     2 runs   (  101.71 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =    1615.49 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4687.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1304.10 ms /    55 tokens (   23.71 ms per token,    42.17 tokens per second)\n",
      "llama_print_timings:        eval time =     200.79 ms /     2 runs   (  100.39 ms per token,     9.96 tokens per second)\n",
      "llama_print_timings:       total time =    1628.85 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4724.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1198.59 ms /    50 tokens (   23.97 ms per token,    41.72 tokens per second)\n",
      "llama_print_timings:        eval time =     204.64 ms /     2 runs   (  102.32 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =    1524.66 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4702.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1496.40 ms /    64 tokens (   23.38 ms per token,    42.77 tokens per second)\n",
      "llama_print_timings:        eval time =     224.78 ms /     2 runs   (  112.39 ms per token,     8.90 tokens per second)\n",
      "llama_print_timings:       total time =    1861.62 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.59 ms /     3 runs   (    0.20 ms per token,  5119.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     953.31 ms /    38 tokens (   25.09 ms per token,    39.86 tokens per second)\n",
      "llama_print_timings:        eval time =     202.02 ms /     2 runs   (  101.01 ms per token,     9.90 tokens per second)\n",
      "llama_print_timings:       total time =    1243.94 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4545.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     978.83 ms /    38 tokens (   25.76 ms per token,    38.82 tokens per second)\n",
      "llama_print_timings:        eval time =     204.86 ms /     2 runs   (  102.43 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    1273.96 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4761.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1147.12 ms /    47 tokens (   24.41 ms per token,    40.97 tokens per second)\n",
      "llama_print_timings:        eval time =     202.11 ms /     2 runs   (  101.06 ms per token,     9.90 tokens per second)\n",
      "llama_print_timings:       total time =    1462.80 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4950.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1130.90 ms /    47 tokens (   24.06 ms per token,    41.56 tokens per second)\n",
      "llama_print_timings:        eval time =     201.65 ms /     2 runs   (  100.82 ms per token,     9.92 tokens per second)\n",
      "llama_print_timings:       total time =    1439.98 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       3.75 ms /    16 runs   (    0.23 ms per token,  4272.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1413.27 ms /    60 tokens (   23.55 ms per token,    42.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1698.43 ms /    15 runs   (  113.23 ms per token,     8.83 tokens per second)\n",
      "llama_print_timings:       total time =    3284.24 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4608.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1441.58 ms /    61 tokens (   23.63 ms per token,    42.31 tokens per second)\n",
      "llama_print_timings:        eval time =     226.29 ms /     2 runs   (  113.15 ms per token,     8.84 tokens per second)\n",
      "llama_print_timings:       total time =    1802.64 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4807.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1411.30 ms /    60 tokens (   23.52 ms per token,    42.51 tokens per second)\n",
      "llama_print_timings:        eval time =     220.53 ms /     2 runs   (  110.26 ms per token,     9.07 tokens per second)\n",
      "llama_print_timings:       total time =    1765.03 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4437.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1289.51 ms /    55 tokens (   23.45 ms per token,    42.65 tokens per second)\n",
      "llama_print_timings:        eval time =     216.20 ms /     2 runs   (  108.10 ms per token,     9.25 tokens per second)\n",
      "llama_print_timings:       total time =    1628.27 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4724.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1310.32 ms /    55 tokens (   23.82 ms per token,    41.97 tokens per second)\n",
      "llama_print_timings:        eval time =     202.19 ms /     2 runs   (  101.09 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =    1638.61 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4885.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1210.16 ms /    50 tokens (   24.20 ms per token,    41.32 tokens per second)\n",
      "llama_print_timings:        eval time =     201.90 ms /     2 runs   (  100.95 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =    1528.99 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4335.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1096.00 ms /    45 tokens (   24.36 ms per token,    41.06 tokens per second)\n",
      "llama_print_timings:        eval time =     204.57 ms /     2 runs   (  102.28 ms per token,     9.78 tokens per second)\n",
      "llama_print_timings:       total time =    1407.77 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4878.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1133.26 ms /    47 tokens (   24.11 ms per token,    41.47 tokens per second)\n",
      "llama_print_timings:        eval time =     204.95 ms /     2 runs   (  102.47 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    1447.52 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4830.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1117.08 ms /    45 tokens (   24.82 ms per token,    40.28 tokens per second)\n",
      "llama_print_timings:        eval time =     203.21 ms /     2 runs   (  101.61 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    1425.31 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4310.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1696.91 ms /    67 tokens (   25.33 ms per token,    39.48 tokens per second)\n",
      "llama_print_timings:        eval time =     222.18 ms /     2 runs   (  111.09 ms per token,     9.00 tokens per second)\n",
      "llama_print_timings:       total time =    2067.40 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4477.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1761.80 ms /    72 tokens (   24.47 ms per token,    40.87 tokens per second)\n",
      "llama_print_timings:        eval time =     225.44 ms /     2 runs   (  112.72 ms per token,     8.87 tokens per second)\n",
      "llama_print_timings:       total time =    2146.90 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4885.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1283.39 ms /    54 tokens (   23.77 ms per token,    42.08 tokens per second)\n",
      "llama_print_timings:        eval time =     201.35 ms /     2 runs   (  100.67 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:       total time =    1605.64 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4870.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1152.13 ms /    47 tokens (   24.51 ms per token,    40.79 tokens per second)\n",
      "llama_print_timings:        eval time =     203.02 ms /     2 runs   (  101.51 ms per token,     9.85 tokens per second)\n",
      "llama_print_timings:       total time =    1462.99 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4784.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1405.10 ms /    58 tokens (   24.23 ms per token,    41.28 tokens per second)\n",
      "llama_print_timings:        eval time =     227.67 ms /     2 runs   (  113.83 ms per token,     8.78 tokens per second)\n",
      "llama_print_timings:       total time =    1761.30 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4615.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1849.65 ms /    75 tokens (   24.66 ms per token,    40.55 tokens per second)\n",
      "llama_print_timings:        eval time =     221.47 ms /     2 runs   (  110.74 ms per token,     9.03 tokens per second)\n",
      "llama_print_timings:       total time =    2239.34 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4769.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1230.86 ms /    51 tokens (   24.13 ms per token,    41.43 tokens per second)\n",
      "llama_print_timings:        eval time =     205.26 ms /     2 runs   (  102.63 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =    1550.08 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4761.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1274.80 ms /    54 tokens (   23.61 ms per token,    42.36 tokens per second)\n",
      "llama_print_timings:        eval time =     200.52 ms /     2 runs   (  100.26 ms per token,     9.97 tokens per second)\n",
      "llama_print_timings:       total time =    1598.79 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4754.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1198.99 ms /    50 tokens (   23.98 ms per token,    41.70 tokens per second)\n",
      "llama_print_timings:        eval time =     210.07 ms /     2 runs   (  105.04 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =    1525.36 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4830.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1463.28 ms /    62 tokens (   23.60 ms per token,    42.37 tokens per second)\n",
      "llama_print_timings:        eval time =     222.88 ms /     2 runs   (  111.44 ms per token,     8.97 tokens per second)\n",
      "llama_print_timings:       total time =    1824.85 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4504.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1645.56 ms /    65 tokens (   25.32 ms per token,    39.50 tokens per second)\n",
      "llama_print_timings:        eval time =     226.97 ms /     2 runs   (  113.49 ms per token,     8.81 tokens per second)\n",
      "llama_print_timings:       total time =    2016.26 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4800.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1173.21 ms /    48 tokens (   24.44 ms per token,    40.91 tokens per second)\n",
      "llama_print_timings:        eval time =     202.63 ms /     2 runs   (  101.32 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =    1484.53 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4777.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1296.20 ms /    55 tokens (   23.57 ms per token,    42.43 tokens per second)\n",
      "llama_print_timings:        eval time =     211.92 ms /     2 runs   (  105.96 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =    1631.54 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4477.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1253.81 ms /    52 tokens (   24.11 ms per token,    41.47 tokens per second)\n",
      "llama_print_timings:        eval time =     236.24 ms /     2 runs   (  118.12 ms per token,     8.47 tokens per second)\n",
      "llama_print_timings:       total time =    1612.89 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4464.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1342.24 ms /    54 tokens (   24.86 ms per token,    40.23 tokens per second)\n",
      "llama_print_timings:        eval time =     209.52 ms /     2 runs   (  104.76 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =    1678.50 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4672.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1326.56 ms /    56 tokens (   23.69 ms per token,    42.21 tokens per second)\n",
      "llama_print_timings:        eval time =     212.49 ms /     2 runs   (  106.25 ms per token,     9.41 tokens per second)\n",
      "llama_print_timings:       total time =    1665.85 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.58 ms /     3 runs   (    0.19 ms per token,  5136.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1131.73 ms /    45 tokens (   25.15 ms per token,    39.76 tokens per second)\n",
      "llama_print_timings:        eval time =     204.85 ms /     2 runs   (  102.43 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    1441.32 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4261.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1284.88 ms /    55 tokens (   23.36 ms per token,    42.81 tokens per second)\n",
      "llama_print_timings:        eval time =     211.72 ms /     2 runs   (  105.86 ms per token,     9.45 tokens per second)\n",
      "llama_print_timings:       total time =    1622.63 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4484.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1824.65 ms /    75 tokens (   24.33 ms per token,    41.10 tokens per second)\n",
      "llama_print_timings:        eval time =     231.00 ms /     2 runs   (  115.50 ms per token,     8.66 tokens per second)\n",
      "llama_print_timings:       total time =    2222.14 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4687.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1210.49 ms /    51 tokens (   23.74 ms per token,    42.13 tokens per second)\n",
      "llama_print_timings:        eval time =     202.65 ms /     2 runs   (  101.32 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =    1528.36 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4366.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1968.41 ms /    80 tokens (   24.61 ms per token,    40.64 tokens per second)\n",
      "llama_print_timings:        eval time =     224.31 ms /     2 runs   (  112.15 ms per token,     8.92 tokens per second)\n",
      "llama_print_timings:       total time =    2369.75 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4800.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1657.27 ms /    66 tokens (   25.11 ms per token,    39.82 tokens per second)\n",
      "llama_print_timings:        eval time =     227.41 ms /     2 runs   (  113.70 ms per token,     8.79 tokens per second)\n",
      "llama_print_timings:       total time =    2030.80 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.59 ms /     3 runs   (    0.20 ms per token,  5076.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1040.85 ms /    42 tokens (   24.78 ms per token,    40.35 tokens per second)\n",
      "llama_print_timings:        eval time =     203.81 ms /     2 runs   (  101.91 ms per token,     9.81 tokens per second)\n",
      "llama_print_timings:       total time =    1341.16 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4411.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1936.58 ms /    80 tokens (   24.21 ms per token,    41.31 tokens per second)\n",
      "llama_print_timings:        eval time =     223.84 ms /     2 runs   (  111.92 ms per token,     8.94 tokens per second)\n",
      "llama_print_timings:       total time =    2333.77 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4784.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1359.64 ms /    57 tokens (   23.85 ms per token,    41.92 tokens per second)\n",
      "llama_print_timings:        eval time =     221.40 ms /     2 runs   (  110.70 ms per token,     9.03 tokens per second)\n",
      "llama_print_timings:       total time =    1709.02 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4870.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1062.16 ms /    43 tokens (   24.70 ms per token,    40.48 tokens per second)\n",
      "llama_print_timings:        eval time =     215.45 ms /     2 runs   (  107.73 ms per token,     9.28 tokens per second)\n",
      "llama_print_timings:       total time =    1375.24 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4694.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1327.29 ms /    57 tokens (   23.29 ms per token,    42.94 tokens per second)\n",
      "llama_print_timings:        eval time =     222.32 ms /     2 runs   (  111.16 ms per token,     9.00 tokens per second)\n",
      "llama_print_timings:       total time =    1677.35 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4792.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.65 ms /    47 tokens (   24.63 ms per token,    40.60 tokens per second)\n",
      "llama_print_timings:        eval time =     203.75 ms /     2 runs   (  101.87 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =    1470.45 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.74 ms /     3 runs   (    0.25 ms per token,  4076.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1824.95 ms /    74 tokens (   24.66 ms per token,    40.55 tokens per second)\n",
      "llama_print_timings:        eval time =     225.20 ms /     2 runs   (  112.60 ms per token,     8.88 tokens per second)\n",
      "llama_print_timings:       total time =    2213.28 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4724.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1240.43 ms /    52 tokens (   23.85 ms per token,    41.92 tokens per second)\n",
      "llama_print_timings:        eval time =     202.88 ms /     2 runs   (  101.44 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =    1560.71 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4777.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1149.03 ms /    48 tokens (   23.94 ms per token,    41.77 tokens per second)\n",
      "llama_print_timings:        eval time =     208.28 ms /     2 runs   (  104.14 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    1466.05 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4926.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1134.60 ms /    46 tokens (   24.67 ms per token,    40.54 tokens per second)\n",
      "llama_print_timings:        eval time =     203.51 ms /     2 runs   (  101.75 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =    1443.16 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4559.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1833.12 ms /    75 tokens (   24.44 ms per token,    40.91 tokens per second)\n",
      "llama_print_timings:        eval time =     220.81 ms /     2 runs   (  110.40 ms per token,     9.06 tokens per second)\n",
      "llama_print_timings:       total time =    2222.22 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4784.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1088.60 ms /    44 tokens (   24.74 ms per token,    40.42 tokens per second)\n",
      "llama_print_timings:        eval time =     205.69 ms /     2 runs   (  102.85 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    1395.89 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4658.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1176.28 ms /    49 tokens (   24.01 ms per token,    41.66 tokens per second)\n",
      "llama_print_timings:        eval time =     206.50 ms /     2 runs   (  103.25 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    1497.92 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4862.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1282.73 ms /    54 tokens (   23.75 ms per token,    42.10 tokens per second)\n",
      "llama_print_timings:        eval time =     201.84 ms /     2 runs   (  100.92 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =    1604.24 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  5000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1081.51 ms /    44 tokens (   24.58 ms per token,    40.68 tokens per second)\n",
      "llama_print_timings:        eval time =     214.58 ms /     2 runs   (  107.29 ms per token,     9.32 tokens per second)\n",
      "llama_print_timings:       total time =    1395.31 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4846.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1058.27 ms /    43 tokens (   24.61 ms per token,    40.63 tokens per second)\n",
      "llama_print_timings:        eval time =     206.02 ms /     2 runs   (  103.01 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =    1364.81 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4716.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1152.99 ms /    48 tokens (   24.02 ms per token,    41.63 tokens per second)\n",
      "llama_print_timings:        eval time =     202.12 ms /     2 runs   (  101.06 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =    1463.72 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4518.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1694.54 ms /    67 tokens (   25.29 ms per token,    39.54 tokens per second)\n",
      "llama_print_timings:        eval time =     223.14 ms /     2 runs   (  111.57 ms per token,     8.96 tokens per second)\n",
      "llama_print_timings:       total time =    2066.35 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4491.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1374.26 ms /    58 tokens (   23.69 ms per token,    42.20 tokens per second)\n",
      "llama_print_timings:        eval time =     225.75 ms /     2 runs   (  112.88 ms per token,     8.86 tokens per second)\n",
      "llama_print_timings:       total time =    1729.79 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4511.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1106.90 ms /    45 tokens (   24.60 ms per token,    40.65 tokens per second)\n",
      "llama_print_timings:        eval time =     212.10 ms /     2 runs   (  106.05 ms per token,     9.43 tokens per second)\n",
      "llama_print_timings:       total time =    1426.58 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4545.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1064.24 ms /    44 tokens (   24.19 ms per token,    41.34 tokens per second)\n",
      "llama_print_timings:        eval time =     211.53 ms /     2 runs   (  105.77 ms per token,     9.45 tokens per second)\n",
      "llama_print_timings:       total time =    1374.35 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.73 ms /     3 runs   (    0.24 ms per token,  4120.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1752.20 ms /    70 tokens (   25.03 ms per token,    39.95 tokens per second)\n",
      "llama_print_timings:        eval time =     223.77 ms /     2 runs   (  111.88 ms per token,     8.94 tokens per second)\n",
      "llama_print_timings:       total time =    2131.46 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  5000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1152.38 ms /    47 tokens (   24.52 ms per token,    40.79 tokens per second)\n",
      "llama_print_timings:        eval time =     200.78 ms /     2 runs   (  100.39 ms per token,     9.96 tokens per second)\n",
      "llama_print_timings:       total time =    1459.22 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4934.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     975.38 ms /    38 tokens (   25.67 ms per token,    38.96 tokens per second)\n",
      "llama_print_timings:        eval time =     219.08 ms /     2 runs   (  109.54 ms per token,     9.13 tokens per second)\n",
      "llama_print_timings:       total time =    1283.90 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4694.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1268.37 ms /    54 tokens (   23.49 ms per token,    42.57 tokens per second)\n",
      "llama_print_timings:        eval time =     208.48 ms /     2 runs   (  104.24 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    1597.84 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4552.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1288.21 ms /    55 tokens (   23.42 ms per token,    42.69 tokens per second)\n",
      "llama_print_timings:        eval time =     212.93 ms /     2 runs   (  106.46 ms per token,     9.39 tokens per second)\n",
      "llama_print_timings:       total time =    1622.98 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4573.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1401.19 ms /    59 tokens (   23.75 ms per token,    42.11 tokens per second)\n",
      "llama_print_timings:        eval time =     222.88 ms /     2 runs   (  111.44 ms per token,     8.97 tokens per second)\n",
      "llama_print_timings:       total time =    1754.35 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4702.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1290.05 ms /    54 tokens (   23.89 ms per token,    41.86 tokens per second)\n",
      "llama_print_timings:        eval time =     202.70 ms /     2 runs   (  101.35 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =    1614.94 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4291.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1077.00 ms /    44 tokens (   24.48 ms per token,    40.85 tokens per second)\n",
      "llama_print_timings:        eval time =     210.80 ms /     2 runs   (  105.40 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =    1386.59 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4424.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1163.31 ms /    48 tokens (   24.24 ms per token,    41.26 tokens per second)\n",
      "llama_print_timings:        eval time =     201.68 ms /     2 runs   (  100.84 ms per token,     9.92 tokens per second)\n",
      "llama_print_timings:       total time =    1473.68 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4622.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1402.14 ms /    58 tokens (   24.17 ms per token,    41.37 tokens per second)\n",
      "llama_print_timings:        eval time =     222.94 ms /     2 runs   (  111.47 ms per token,     8.97 tokens per second)\n",
      "llama_print_timings:       total time =    1753.03 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4807.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1084.67 ms /    43 tokens (   25.22 ms per token,    39.64 tokens per second)\n",
      "llama_print_timings:        eval time =     215.32 ms /     2 runs   (  107.66 ms per token,     9.29 tokens per second)\n",
      "llama_print_timings:       total time =    1401.32 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4846.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1074.61 ms /    44 tokens (   24.42 ms per token,    40.95 tokens per second)\n",
      "llama_print_timings:        eval time =     208.91 ms /     2 runs   (  104.45 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    1385.04 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     4 runs   (    0.20 ms per token,  5050.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1009.34 ms /    40 tokens (   25.23 ms per token,    39.63 tokens per second)\n",
      "llama_print_timings:        eval time =     305.57 ms /     3 runs   (  101.86 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =    1409.31 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     4 runs   (    0.20 ms per token,  5082.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1140.78 ms /    46 tokens (   24.80 ms per token,    40.32 tokens per second)\n",
      "llama_print_timings:        eval time =     304.93 ms /     3 runs   (  101.64 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    1554.55 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4830.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1032.13 ms /    42 tokens (   24.57 ms per token,    40.69 tokens per second)\n",
      "llama_print_timings:        eval time =     215.66 ms /     2 runs   (  107.83 ms per token,     9.27 tokens per second)\n",
      "llama_print_timings:       total time =    1343.81 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4838.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1123.58 ms /    46 tokens (   24.43 ms per token,    40.94 tokens per second)\n",
      "llama_print_timings:        eval time =     203.59 ms /     2 runs   (  101.80 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =    1432.15 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  4958.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1387.10 ms /    58 tokens (   23.92 ms per token,    41.81 tokens per second)\n",
      "llama_print_timings:        eval time =     221.55 ms /     2 runs   (  110.78 ms per token,     9.03 tokens per second)\n",
      "llama_print_timings:       total time =    1736.89 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4724.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1080.30 ms /    44 tokens (   24.55 ms per token,    40.73 tokens per second)\n",
      "llama_print_timings:        eval time =     211.88 ms /     2 runs   (  105.94 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =    1391.83 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4477.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     959.74 ms /    38 tokens (   25.26 ms per token,    39.59 tokens per second)\n",
      "llama_print_timings:        eval time =     212.61 ms /     2 runs   (  106.30 ms per token,     9.41 tokens per second)\n",
      "llama_print_timings:       total time =    1259.62 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  4958.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1000.84 ms /    40 tokens (   25.02 ms per token,    39.97 tokens per second)\n",
      "llama_print_timings:        eval time =     204.38 ms /     2 runs   (  102.19 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =    1298.45 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4754.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1138.69 ms /    47 tokens (   24.23 ms per token,    41.28 tokens per second)\n",
      "llama_print_timings:        eval time =     201.18 ms /     2 runs   (  100.59 ms per token,     9.94 tokens per second)\n",
      "llama_print_timings:       total time =    1445.90 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4769.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1144.35 ms /    47 tokens (   24.35 ms per token,    41.07 tokens per second)\n",
      "llama_print_timings:        eval time =     204.47 ms /     2 runs   (  102.23 ms per token,     9.78 tokens per second)\n",
      "llama_print_timings:       total time =    1457.36 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4373.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1192.35 ms /    50 tokens (   23.85 ms per token,    41.93 tokens per second)\n",
      "llama_print_timings:        eval time =     206.17 ms /     2 runs   (  103.08 ms per token,     9.70 tokens per second)\n",
      "llama_print_timings:       total time =    1518.11 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4800.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1061.22 ms /    43 tokens (   24.68 ms per token,    40.52 tokens per second)\n",
      "llama_print_timings:        eval time =     210.31 ms /     2 runs   (  105.15 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =    1371.16 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4901.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1167.39 ms /    49 tokens (   23.82 ms per token,    41.97 tokens per second)\n",
      "llama_print_timings:        eval time =     206.70 ms /     2 runs   (  103.35 ms per token,     9.68 tokens per second)\n",
      "llama_print_timings:       total time =    1483.80 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.59 ms /     3 runs   (    0.20 ms per token,  5067.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1051.94 ms /    42 tokens (   25.05 ms per token,    39.93 tokens per second)\n",
      "llama_print_timings:        eval time =     204.02 ms /     2 runs   (  102.01 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =    1352.75 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4566.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1039.28 ms /    42 tokens (   24.74 ms per token,    40.41 tokens per second)\n",
      "llama_print_timings:        eval time =     218.58 ms /     2 runs   (  109.29 ms per token,     9.15 tokens per second)\n",
      "llama_print_timings:       total time =    1354.48 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4942.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1086.74 ms /    45 tokens (   24.15 ms per token,    41.41 tokens per second)\n",
      "llama_print_timings:        eval time =     202.22 ms /     2 runs   (  101.11 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =    1392.65 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4792.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1264.81 ms /    53 tokens (   23.86 ms per token,    41.90 tokens per second)\n",
      "llama_print_timings:        eval time =     205.12 ms /     2 runs   (  102.56 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =    1588.13 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4754.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1010.63 ms /    40 tokens (   25.27 ms per token,    39.58 tokens per second)\n",
      "llama_print_timings:        eval time =     213.60 ms /     2 runs   (  106.80 ms per token,     9.36 tokens per second)\n",
      "llama_print_timings:       total time =    1316.17 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4392.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.05 ms /    49 tokens (   24.04 ms per token,    41.59 tokens per second)\n",
      "llama_print_timings:        eval time =     201.02 ms /     2 runs   (  100.51 ms per token,     9.95 tokens per second)\n",
      "llama_print_timings:       total time =    1490.18 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4709.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1164.73 ms /    46 tokens (   25.32 ms per token,    39.49 tokens per second)\n",
      "llama_print_timings:        eval time =     213.84 ms /     2 runs   (  106.92 ms per token,     9.35 tokens per second)\n",
      "llama_print_timings:       total time =    1497.10 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  4991.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1083.43 ms /    44 tokens (   24.62 ms per token,    40.61 tokens per second)\n",
      "llama_print_timings:        eval time =     204.53 ms /     2 runs   (  102.27 ms per token,     9.78 tokens per second)\n",
      "llama_print_timings:       total time =    1391.54 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  5025.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1050.87 ms /    43 tokens (   24.44 ms per token,    40.92 tokens per second)\n",
      "llama_print_timings:        eval time =     206.82 ms /     2 runs   (  103.41 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    1354.11 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     4 runs   (    0.20 ms per token,  5076.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1023.77 ms /    40 tokens (   25.59 ms per token,    39.07 tokens per second)\n",
      "llama_print_timings:        eval time =     308.73 ms /     3 runs   (  102.91 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    1427.94 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4531.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1310.02 ms /    56 tokens (   23.39 ms per token,    42.75 tokens per second)\n",
      "llama_print_timings:        eval time =     214.66 ms /     2 runs   (  107.33 ms per token,     9.32 tokens per second)\n",
      "llama_print_timings:       total time =    1649.81 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4484.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1090.27 ms /    45 tokens (   24.23 ms per token,    41.27 tokens per second)\n",
      "llama_print_timings:        eval time =     211.90 ms /     2 runs   (  105.95 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =    1411.47 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4926.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1029.64 ms /    41 tokens (   25.11 ms per token,    39.82 tokens per second)\n",
      "llama_print_timings:        eval time =     203.20 ms /     2 runs   (  101.60 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    1328.61 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.59 ms /     3 runs   (    0.20 ms per token,  5050.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1053.97 ms /    43 tokens (   24.51 ms per token,    40.80 tokens per second)\n",
      "llama_print_timings:        eval time =     202.84 ms /     2 runs   (  101.42 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =    1356.34 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4545.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1144.90 ms /    47 tokens (   24.36 ms per token,    41.05 tokens per second)\n",
      "llama_print_timings:        eval time =     203.75 ms /     2 runs   (  101.88 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =    1458.04 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4838.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1176.24 ms /    49 tokens (   24.00 ms per token,    41.66 tokens per second)\n",
      "llama_print_timings:        eval time =     200.13 ms /     2 runs   (  100.07 ms per token,     9.99 tokens per second)\n",
      "llama_print_timings:       total time =    1495.69 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  4983.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1081.26 ms /    44 tokens (   24.57 ms per token,    40.69 tokens per second)\n",
      "llama_print_timings:        eval time =     204.25 ms /     2 runs   (  102.12 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =    1385.46 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4580.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     994.99 ms /    40 tokens (   24.87 ms per token,    40.20 tokens per second)\n",
      "llama_print_timings:        eval time =     206.89 ms /     2 runs   (  103.45 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    1294.92 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4901.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1048.87 ms /    42 tokens (   24.97 ms per token,    40.04 tokens per second)\n",
      "llama_print_timings:        eval time =     201.21 ms /     2 runs   (  100.60 ms per token,     9.94 tokens per second)\n",
      "llama_print_timings:       total time =    1345.30 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4815.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1033.95 ms /    42 tokens (   24.62 ms per token,    40.62 tokens per second)\n",
      "llama_print_timings:        eval time =     221.91 ms /     2 runs   (  110.95 ms per token,     9.01 tokens per second)\n",
      "llama_print_timings:       total time =    1353.36 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4792.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1032.45 ms /    42 tokens (   24.58 ms per token,    40.68 tokens per second)\n",
      "llama_print_timings:        eval time =     207.92 ms /     2 runs   (  103.96 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    1336.26 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4815.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1078.94 ms /    44 tokens (   24.52 ms per token,    40.78 tokens per second)\n",
      "llama_print_timings:        eval time =     204.05 ms /     2 runs   (  102.03 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =    1382.37 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     4 runs   (    0.21 ms per token,  4722.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1205.05 ms /    50 tokens (   24.10 ms per token,    41.49 tokens per second)\n",
      "llama_print_timings:        eval time =     307.38 ms /     3 runs   (  102.46 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    1630.86 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4815.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1091.79 ms /    44 tokens (   24.81 ms per token,    40.30 tokens per second)\n",
      "llama_print_timings:        eval time =     204.88 ms /     2 runs   (  102.44 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    1404.68 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.59 ms /     3 runs   (    0.20 ms per token,  5076.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     987.05 ms /    39 tokens (   25.31 ms per token,    39.51 tokens per second)\n",
      "llama_print_timings:        eval time =     205.16 ms /     2 runs   (  102.58 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =    1283.59 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  4966.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1003.47 ms /    40 tokens (   25.09 ms per token,    39.86 tokens per second)\n",
      "llama_print_timings:        eval time =     211.66 ms /     2 runs   (  105.83 ms per token,     9.45 tokens per second)\n",
      "llama_print_timings:       total time =    1307.71 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4335.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1277.29 ms /    54 tokens (   23.65 ms per token,    42.28 tokens per second)\n",
      "llama_print_timings:        eval time =     203.23 ms /     2 runs   (  101.61 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    1601.03 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  4975.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1146.09 ms /    47 tokens (   24.38 ms per token,    41.01 tokens per second)\n",
      "llama_print_timings:        eval time =     200.96 ms /     2 runs   (  100.48 ms per token,     9.95 tokens per second)\n",
      "llama_print_timings:       total time =    1460.98 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  4983.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1069.05 ms /    43 tokens (   24.86 ms per token,    40.22 tokens per second)\n",
      "llama_print_timings:        eval time =     203.36 ms /     2 runs   (  101.68 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =    1373.42 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4672.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1051.54 ms /    43 tokens (   24.45 ms per token,    40.89 tokens per second)\n",
      "llama_print_timings:        eval time =     199.32 ms /     2 runs   (   99.66 ms per token,    10.03 tokens per second)\n",
      "llama_print_timings:       total time =    1350.52 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4807.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1183.13 ms /    48 tokens (   24.65 ms per token,    40.57 tokens per second)\n",
      "llama_print_timings:        eval time =     201.77 ms /     2 runs   (  100.88 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =    1493.92 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4665.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1121.56 ms /    46 tokens (   24.38 ms per token,    41.01 tokens per second)\n",
      "llama_print_timings:        eval time =     200.38 ms /     2 runs   (  100.19 ms per token,     9.98 tokens per second)\n",
      "llama_print_timings:       total time =    1427.23 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4769.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1118.66 ms /    46 tokens (   24.32 ms per token,    41.12 tokens per second)\n",
      "llama_print_timings:        eval time =     202.05 ms /     2 runs   (  101.03 ms per token,     9.90 tokens per second)\n",
      "llama_print_timings:       total time =    1425.12 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4437.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1177.55 ms /    49 tokens (   24.03 ms per token,    41.61 tokens per second)\n",
      "llama_print_timings:        eval time =     204.87 ms /     2 runs   (  102.44 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    1505.94 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.21 ms per token,  4651.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1045.20 ms /    42 tokens (   24.89 ms per token,    40.18 tokens per second)\n",
      "llama_print_timings:        eval time =     212.95 ms /     2 runs   (  106.48 ms per token,     9.39 tokens per second)\n",
      "llama_print_timings:       total time =    1359.54 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4918.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1046.49 ms /    43 tokens (   24.34 ms per token,    41.09 tokens per second)\n",
      "llama_print_timings:        eval time =     203.00 ms /     2 runs   (  101.50 ms per token,     9.85 tokens per second)\n",
      "llama_print_timings:       total time =    1347.83 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     4 runs   (    0.21 ms per token,  4790.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1119.07 ms /    45 tokens (   24.87 ms per token,    40.21 tokens per second)\n",
      "llama_print_timings:        eval time =     307.03 ms /     3 runs   (  102.34 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =    1531.35 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     4 runs   (    0.20 ms per token,  4993.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1131.69 ms /    46 tokens (   24.60 ms per token,    40.65 tokens per second)\n",
      "llama_print_timings:        eval time =     304.94 ms /     3 runs   (  101.65 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    1552.30 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4926.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1033.96 ms /    42 tokens (   24.62 ms per token,    40.62 tokens per second)\n",
      "llama_print_timings:        eval time =     203.43 ms /     2 runs   (  101.71 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =    1333.41 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.59 ms /     3 runs   (    0.20 ms per token,  5042.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1036.34 ms /    41 tokens (   25.28 ms per token,    39.56 tokens per second)\n",
      "llama_print_timings:        eval time =     203.28 ms /     2 runs   (  101.64 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    1334.00 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  5016.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     995.16 ms /    39 tokens (   25.52 ms per token,    39.19 tokens per second)\n",
      "llama_print_timings:        eval time =     203.71 ms /     2 runs   (  101.85 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =    1289.82 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4926.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1037.82 ms /    42 tokens (   24.71 ms per token,    40.47 tokens per second)\n",
      "llama_print_timings:        eval time =     203.34 ms /     2 runs   (  101.67 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    1337.24 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4870.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1119.54 ms /    46 tokens (   24.34 ms per token,    41.09 tokens per second)\n",
      "llama_print_timings:        eval time =     202.96 ms /     2 runs   (  101.48 ms per token,     9.85 tokens per second)\n",
      "llama_print_timings:       total time =    1427.18 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4405.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1339.35 ms /    57 tokens (   23.50 ms per token,    42.56 tokens per second)\n",
      "llama_print_timings:        eval time =     228.22 ms /     2 runs   (  114.11 ms per token,     8.76 tokens per second)\n",
      "llama_print_timings:       total time =    1698.81 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     4 runs   (    0.21 ms per token,  4778.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1077.87 ms /    44 tokens (   24.50 ms per token,    40.82 tokens per second)\n",
      "llama_print_timings:        eval time =     316.49 ms /     3 runs   (  105.50 ms per token,     9.48 tokens per second)\n",
      "llama_print_timings:       total time =    1497.66 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4909.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1033.40 ms /    42 tokens (   24.60 ms per token,    40.64 tokens per second)\n",
      "llama_print_timings:        eval time =     204.32 ms /     2 runs   (  102.16 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =    1333.94 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4784.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1207.30 ms /    50 tokens (   24.15 ms per token,    41.41 tokens per second)\n",
      "llama_print_timings:        eval time =     204.07 ms /     2 runs   (  102.03 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =    1524.50 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4716.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1005.34 ms /    40 tokens (   25.13 ms per token,    39.79 tokens per second)\n",
      "llama_print_timings:        eval time =     221.78 ms /     2 runs   (  110.89 ms per token,     9.02 tokens per second)\n",
      "llama_print_timings:       total time =    1323.16 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4846.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1129.81 ms /    47 tokens (   24.04 ms per token,    41.60 tokens per second)\n",
      "llama_print_timings:        eval time =     201.69 ms /     2 runs   (  100.84 ms per token,     9.92 tokens per second)\n",
      "llama_print_timings:       total time =    1439.01 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4594.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.25 ms /    48 tokens (   24.48 ms per token,    40.84 tokens per second)\n",
      "llama_print_timings:        eval time =     204.10 ms /     2 runs   (  102.05 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =    1488.09 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4672.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1201.68 ms /    50 tokens (   24.03 ms per token,    41.61 tokens per second)\n",
      "llama_print_timings:        eval time =     201.86 ms /     2 runs   (  100.93 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =    1522.52 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4830.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1128.90 ms /    47 tokens (   24.02 ms per token,    41.63 tokens per second)\n",
      "llama_print_timings:        eval time =     200.93 ms /     2 runs   (  100.47 ms per token,     9.95 tokens per second)\n",
      "llama_print_timings:       total time =    1437.07 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4739.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.92 ms /    52 tokens (   24.38 ms per token,    41.01 tokens per second)\n",
      "llama_print_timings:        eval time =     204.15 ms /     2 runs   (  102.08 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =    1589.13 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     4 runs   (    0.21 ms per token,  4872.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1078.29 ms /    44 tokens (   24.51 ms per token,    40.81 tokens per second)\n",
      "llama_print_timings:        eval time =     315.66 ms /     3 runs   (  105.22 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =    1498.02 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4594.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1307.76 ms /    56 tokens (   23.35 ms per token,    42.82 tokens per second)\n",
      "llama_print_timings:        eval time =     223.91 ms /     2 runs   (  111.95 ms per token,     8.93 tokens per second)\n",
      "llama_print_timings:       total time =    1659.67 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4672.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.67 ms /    49 tokens (   23.91 ms per token,    41.82 tokens per second)\n",
      "llama_print_timings:        eval time =     204.08 ms /     2 runs   (  102.04 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =    1487.68 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     4 runs   (    0.22 ms per token,  4592.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1412.25 ms /    59 tokens (   23.94 ms per token,    41.78 tokens per second)\n",
      "llama_print_timings:        eval time =     340.54 ms /     3 runs   (  113.51 ms per token,     8.81 tokens per second)\n",
      "llama_print_timings:       total time =    1892.14 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4739.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1201.73 ms /    50 tokens (   24.03 ms per token,    41.61 tokens per second)\n",
      "llama_print_timings:        eval time =     200.53 ms /     2 runs   (  100.26 ms per token,     9.97 tokens per second)\n",
      "llama_print_timings:       total time =    1517.09 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4878.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1056.36 ms /    43 tokens (   24.57 ms per token,    40.71 tokens per second)\n",
      "llama_print_timings:        eval time =     209.91 ms /     2 runs   (  104.96 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    1364.59 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4815.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1028.13 ms /    42 tokens (   24.48 ms per token,    40.85 tokens per second)\n",
      "llama_print_timings:        eval time =     214.94 ms /     2 runs   (  107.47 ms per token,     9.30 tokens per second)\n",
      "llama_print_timings:       total time =    1339.84 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  4958.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1052.28 ms /    42 tokens (   25.05 ms per token,    39.91 tokens per second)\n",
      "llama_print_timings:        eval time =     203.90 ms /     2 runs   (  101.95 ms per token,     9.81 tokens per second)\n",
      "llama_print_timings:       total time =    1355.31 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4870.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1275.25 ms /    54 tokens (   23.62 ms per token,    42.34 tokens per second)\n",
      "llama_print_timings:        eval time =     212.78 ms /     2 runs   (  106.39 ms per token,     9.40 tokens per second)\n",
      "llama_print_timings:       total time =    1610.27 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4615.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1077.08 ms /    44 tokens (   24.48 ms per token,    40.85 tokens per second)\n",
      "llama_print_timings:        eval time =     212.05 ms /     2 runs   (  106.03 ms per token,     9.43 tokens per second)\n",
      "llama_print_timings:       total time =    1397.67 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  4966.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     982.27 ms /    38 tokens (   25.85 ms per token,    38.69 tokens per second)\n",
      "llama_print_timings:        eval time =     205.16 ms /     2 runs   (  102.58 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =    1277.10 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4823.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1318.24 ms /    56 tokens (   23.54 ms per token,    42.48 tokens per second)\n",
      "llama_print_timings:        eval time =     217.36 ms /     2 runs   (  108.68 ms per token,     9.20 tokens per second)\n",
      "llama_print_timings:       total time =    1665.44 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4335.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1391.56 ms /    57 tokens (   24.41 ms per token,    40.96 tokens per second)\n",
      "llama_print_timings:        eval time =     229.69 ms /     2 runs   (  114.85 ms per token,     8.71 tokens per second)\n",
      "llama_print_timings:       total time =    1755.48 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4746.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1448.49 ms /    62 tokens (   23.36 ms per token,    42.80 tokens per second)\n",
      "llama_print_timings:        eval time =     223.46 ms /     2 runs   (  111.73 ms per token,     8.95 tokens per second)\n",
      "llama_print_timings:       total time =    1810.73 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4504.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1118.89 ms /    45 tokens (   24.86 ms per token,    40.22 tokens per second)\n",
      "llama_print_timings:        eval time =     204.94 ms /     2 runs   (  102.47 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    1427.94 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4731.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1070.69 ms /    44 tokens (   24.33 ms per token,    41.09 tokens per second)\n",
      "llama_print_timings:        eval time =     204.61 ms /     2 runs   (  102.31 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =    1378.43 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  5033.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1054.25 ms /    43 tokens (   24.52 ms per token,    40.79 tokens per second)\n",
      "llama_print_timings:        eval time =     203.04 ms /     2 runs   (  101.52 ms per token,     9.85 tokens per second)\n",
      "llama_print_timings:       total time =    1357.63 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     4 runs   (    0.20 ms per token,  5115.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1050.85 ms /    42 tokens (   25.02 ms per token,    39.97 tokens per second)\n",
      "llama_print_timings:        eval time =     305.50 ms /     3 runs   (  101.83 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =    1461.40 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4823.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1141.94 ms /    47 tokens (   24.30 ms per token,    41.16 tokens per second)\n",
      "llama_print_timings:        eval time =     201.33 ms /     2 runs   (  100.67 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:       total time =    1454.44 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4792.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1194.95 ms /    50 tokens (   23.90 ms per token,    41.84 tokens per second)\n",
      "llama_print_timings:        eval time =     202.49 ms /     2 runs   (  101.24 ms per token,     9.88 tokens per second)\n",
      "llama_print_timings:       total time =    1515.90 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4761.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1165.56 ms /    48 tokens (   24.28 ms per token,    41.18 tokens per second)\n",
      "llama_print_timings:        eval time =     200.83 ms /     2 runs   (  100.41 ms per token,     9.96 tokens per second)\n",
      "llama_print_timings:       total time =    1474.92 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4687.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1235.43 ms /    51 tokens (   24.22 ms per token,    41.28 tokens per second)\n",
      "llama_print_timings:        eval time =     205.83 ms /     2 runs   (  102.91 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    1554.88 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4761.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1050.18 ms /    43 tokens (   24.42 ms per token,    40.95 tokens per second)\n",
      "llama_print_timings:        eval time =     215.33 ms /     2 runs   (  107.67 ms per token,     9.29 tokens per second)\n",
      "llama_print_timings:       total time =    1363.55 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4823.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1094.07 ms /    45 tokens (   24.31 ms per token,    41.13 tokens per second)\n",
      "llama_print_timings:        eval time =     204.26 ms /     2 runs   (  102.13 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =    1401.01 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4643.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1093.06 ms /    43 tokens (   25.42 ms per token,    39.34 tokens per second)\n",
      "llama_print_timings:        eval time =     204.63 ms /     2 runs   (  102.31 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =    1397.62 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4901.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1054.03 ms /    43 tokens (   24.51 ms per token,    40.80 tokens per second)\n",
      "llama_print_timings:        eval time =     225.58 ms /     2 runs   (  112.79 ms per token,     8.87 tokens per second)\n",
      "llama_print_timings:       total time =    1377.24 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4694.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1367.73 ms /    58 tokens (   23.58 ms per token,    42.41 tokens per second)\n",
      "llama_print_timings:        eval time =     222.28 ms /     2 runs   (  111.14 ms per token,     9.00 tokens per second)\n",
      "llama_print_timings:       total time =    1717.94 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     4 runs   (    0.21 ms per token,  4767.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1113.84 ms /    44 tokens (   25.31 ms per token,    39.50 tokens per second)\n",
      "llama_print_timings:        eval time =     308.93 ms /     3 runs   (  102.98 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =    1527.01 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4629.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1153.80 ms /    48 tokens (   24.04 ms per token,    41.60 tokens per second)\n",
      "llama_print_timings:        eval time =     202.69 ms /     2 runs   (  101.34 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =    1479.73 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4823.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1121.33 ms /    46 tokens (   24.38 ms per token,    41.02 tokens per second)\n",
      "llama_print_timings:        eval time =     202.64 ms /     2 runs   (  101.32 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =    1428.67 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  4966.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1066.80 ms /    42 tokens (   25.40 ms per token,    39.37 tokens per second)\n",
      "llama_print_timings:        eval time =     204.94 ms /     2 runs   (  102.47 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    1371.88 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4901.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1060.66 ms /    43 tokens (   24.67 ms per token,    40.54 tokens per second)\n",
      "llama_print_timings:        eval time =     204.25 ms /     2 runs   (  102.12 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =    1365.11 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.58 ms /     3 runs   (    0.19 ms per token,  5136.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1049.84 ms /    42 tokens (   25.00 ms per token,    40.01 tokens per second)\n",
      "llama_print_timings:        eval time =     206.02 ms /     2 runs   (  103.01 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =    1351.08 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4815.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1051.27 ms /    42 tokens (   25.03 ms per token,    39.95 tokens per second)\n",
      "llama_print_timings:        eval time =     217.18 ms /     2 runs   (  108.59 ms per token,     9.21 tokens per second)\n",
      "llama_print_timings:       total time =    1365.90 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4622.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1249.41 ms /    52 tokens (   24.03 ms per token,    41.62 tokens per second)\n",
      "llama_print_timings:        eval time =     202.46 ms /     2 runs   (  101.23 ms per token,     9.88 tokens per second)\n",
      "llama_print_timings:       total time =    1571.80 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /     3 runs   (    0.25 ms per token,  3973.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1279.17 ms /    54 tokens (   23.69 ms per token,    42.21 tokens per second)\n",
      "llama_print_timings:        eval time =     224.92 ms /     2 runs   (  112.46 ms per token,     8.89 tokens per second)\n",
      "llama_print_timings:       total time =    1625.93 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4754.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1118.62 ms /    46 tokens (   24.32 ms per token,    41.12 tokens per second)\n",
      "llama_print_timings:        eval time =     203.52 ms /     2 runs   (  101.76 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =    1426.73 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4885.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1068.26 ms /    41 tokens (   26.06 ms per token,    38.38 tokens per second)\n",
      "llama_print_timings:        eval time =     211.84 ms /     2 runs   (  105.92 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =    1377.55 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4784.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1166.04 ms /    48 tokens (   24.29 ms per token,    41.17 tokens per second)\n",
      "llama_print_timings:        eval time =     208.06 ms /     2 runs   (  104.03 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    1491.58 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4746.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1275.52 ms /    54 tokens (   23.62 ms per token,    42.34 tokens per second)\n",
      "llama_print_timings:        eval time =     202.44 ms /     2 runs   (  101.22 ms per token,     9.88 tokens per second)\n",
      "llama_print_timings:       total time =    1597.26 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4893.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1006.54 ms /    39 tokens (   25.81 ms per token,    38.75 tokens per second)\n",
      "llama_print_timings:        eval time =     212.12 ms /     2 runs   (  106.06 ms per token,     9.43 tokens per second)\n",
      "llama_print_timings:       total time =    1316.93 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4431.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1022.97 ms /    41 tokens (   24.95 ms per token,    40.08 tokens per second)\n",
      "llama_print_timings:        eval time =     222.76 ms /     2 runs   (  111.38 ms per token,     8.98 tokens per second)\n",
      "llama_print_timings:       total time =    1341.34 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.59 ms /     3 runs   (    0.20 ms per token,  5059.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1059.76 ms /    43 tokens (   24.65 ms per token,    40.58 tokens per second)\n",
      "llama_print_timings:        eval time =     204.58 ms /     2 runs   (  102.29 ms per token,     9.78 tokens per second)\n",
      "llama_print_timings:       total time =    1363.69 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.73 ms /     3 runs   (    0.24 ms per token,  4109.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1026.42 ms /    40 tokens (   25.66 ms per token,    38.97 tokens per second)\n",
      "llama_print_timings:        eval time =     215.93 ms /     2 runs   (  107.96 ms per token,     9.26 tokens per second)\n",
      "llama_print_timings:       total time =    1337.33 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4457.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1020.84 ms /    41 tokens (   24.90 ms per token,    40.16 tokens per second)\n",
      "llama_print_timings:        eval time =     214.83 ms /     2 runs   (  107.42 ms per token,     9.31 tokens per second)\n",
      "llama_print_timings:       total time =    1331.54 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  4991.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1090.65 ms /    44 tokens (   24.79 ms per token,    40.34 tokens per second)\n",
      "llama_print_timings:        eval time =     202.48 ms /     2 runs   (  101.24 ms per token,     9.88 tokens per second)\n",
      "llama_print_timings:       total time =    1392.72 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  4975.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1098.92 ms /    44 tokens (   24.98 ms per token,    40.04 tokens per second)\n",
      "llama_print_timings:        eval time =     203.18 ms /     2 runs   (  101.59 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    1405.05 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4870.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1039.00 ms /    41 tokens (   25.34 ms per token,    39.46 tokens per second)\n",
      "llama_print_timings:        eval time =     206.72 ms /     2 runs   (  103.36 ms per token,     9.68 tokens per second)\n",
      "llama_print_timings:       total time =    1340.26 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4909.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1122.61 ms /    46 tokens (   24.40 ms per token,    40.98 tokens per second)\n",
      "llama_print_timings:        eval time =     205.36 ms /     2 runs   (  102.68 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =    1432.14 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4878.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1109.95 ms /    45 tokens (   24.67 ms per token,    40.54 tokens per second)\n",
      "llama_print_timings:        eval time =     205.20 ms /     2 runs   (  102.60 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =    1427.19 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       1.04 ms /     4 runs   (    0.26 ms per token,  3853.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1005.45 ms /    40 tokens (   25.14 ms per token,    39.78 tokens per second)\n",
      "llama_print_timings:        eval time =     306.17 ms /     3 runs   (  102.06 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =    1406.08 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4761.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1225.30 ms /    50 tokens (   24.51 ms per token,    40.81 tokens per second)\n",
      "llama_print_timings:        eval time =     205.02 ms /     2 runs   (  102.51 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    1542.41 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4709.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1228.56 ms /    51 tokens (   24.09 ms per token,    41.51 tokens per second)\n",
      "llama_print_timings:        eval time =     203.71 ms /     2 runs   (  101.85 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =    1549.32 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4665.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1110.89 ms /    46 tokens (   24.15 ms per token,    41.41 tokens per second)\n",
      "llama_print_timings:        eval time =     210.64 ms /     2 runs   (  105.32 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =    1427.47 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4815.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1148.27 ms /    47 tokens (   24.43 ms per token,    40.93 tokens per second)\n",
      "llama_print_timings:        eval time =     203.19 ms /     2 runs   (  101.59 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    1459.41 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4807.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1085.47 ms /    44 tokens (   24.67 ms per token,    40.54 tokens per second)\n",
      "llama_print_timings:        eval time =     212.41 ms /     2 runs   (  106.20 ms per token,     9.42 tokens per second)\n",
      "llama_print_timings:       total time =    1399.28 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4870.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1021.95 ms /    41 tokens (   24.93 ms per token,    40.12 tokens per second)\n",
      "llama_print_timings:        eval time =     213.08 ms /     2 runs   (  106.54 ms per token,     9.39 tokens per second)\n",
      "llama_print_timings:       total time =    1329.98 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4909.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1102.06 ms /    45 tokens (   24.49 ms per token,    40.83 tokens per second)\n",
      "llama_print_timings:        eval time =     202.41 ms /     2 runs   (  101.20 ms per token,     9.88 tokens per second)\n",
      "llama_print_timings:       total time =    1417.61 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4724.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1262.67 ms /    52 tokens (   24.28 ms per token,    41.18 tokens per second)\n",
      "llama_print_timings:        eval time =     201.62 ms /     2 runs   (  100.81 ms per token,     9.92 tokens per second)\n",
      "llama_print_timings:       total time =    1580.13 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4909.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1189.66 ms /    49 tokens (   24.28 ms per token,    41.19 tokens per second)\n",
      "llama_print_timings:        eval time =     203.02 ms /     2 runs   (  101.51 ms per token,     9.85 tokens per second)\n",
      "llama_print_timings:       total time =    1505.32 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  4983.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     996.82 ms /    39 tokens (   25.56 ms per token,    39.12 tokens per second)\n",
      "llama_print_timings:        eval time =     205.81 ms /     2 runs   (  102.91 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    1291.41 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4934.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1068.95 ms /    43 tokens (   24.86 ms per token,    40.23 tokens per second)\n",
      "llama_print_timings:        eval time =     219.03 ms /     2 runs   (  109.52 ms per token,     9.13 tokens per second)\n",
      "llama_print_timings:       total time =    1385.47 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     4 runs   (    0.22 ms per token,  4587.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1095.48 ms /    45 tokens (   24.34 ms per token,    41.08 tokens per second)\n",
      "llama_print_timings:        eval time =     326.74 ms /     3 runs   (  108.91 ms per token,     9.18 tokens per second)\n",
      "llama_print_timings:       total time =    1532.13 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4511.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1234.57 ms /    49 tokens (   25.20 ms per token,    39.69 tokens per second)\n",
      "llama_print_timings:        eval time =     214.26 ms /     2 runs   (  107.13 ms per token,     9.33 tokens per second)\n",
      "llama_print_timings:       total time =    1568.88 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     3 runs   (    0.26 ms per token,  3851.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1295.14 ms /    50 tokens (   25.90 ms per token,    38.61 tokens per second)\n",
      "llama_print_timings:        eval time =     215.93 ms /     2 runs   (  107.96 ms per token,     9.26 tokens per second)\n",
      "llama_print_timings:       total time =    1627.22 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4769.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1141.17 ms /    43 tokens (   26.54 ms per token,    37.68 tokens per second)\n",
      "llama_print_timings:        eval time =     216.15 ms /     2 runs   (  108.07 ms per token,     9.25 tokens per second)\n",
      "llama_print_timings:       total time =    1461.99 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4405.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1292.69 ms /    50 tokens (   25.85 ms per token,    38.68 tokens per second)\n",
      "llama_print_timings:        eval time =     218.54 ms /     2 runs   (  109.27 ms per token,     9.15 tokens per second)\n",
      "llama_print_timings:       total time =    1638.84 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4587.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1183.16 ms /    46 tokens (   25.72 ms per token,    38.88 tokens per second)\n",
      "llama_print_timings:        eval time =     212.83 ms /     2 runs   (  106.42 ms per token,     9.40 tokens per second)\n",
      "llama_print_timings:       total time =    1507.84 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4694.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1098.80 ms /    42 tokens (   26.16 ms per token,    38.22 tokens per second)\n",
      "llama_print_timings:        eval time =     213.11 ms /     2 runs   (  106.55 ms per token,     9.38 tokens per second)\n",
      "llama_print_timings:       total time =    1415.66 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4497.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2354.69 ms /    96 tokens (   24.53 ms per token,    40.77 tokens per second)\n",
      "llama_print_timings:        eval time =     244.26 ms /     2 runs   (  122.13 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =    2817.00 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     4 runs   (    0.21 ms per token,  4739.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1256.35 ms /    53 tokens (   23.70 ms per token,    42.19 tokens per second)\n",
      "llama_print_timings:        eval time =     300.96 ms /     3 runs   (  100.32 ms per token,     9.97 tokens per second)\n",
      "llama_print_timings:       total time =    1678.21 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4854.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1052.77 ms /    42 tokens (   25.07 ms per token,    39.89 tokens per second)\n",
      "llama_print_timings:        eval time =     218.79 ms /     2 runs   (  109.39 ms per token,     9.14 tokens per second)\n",
      "llama_print_timings:       total time =    1370.56 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4524.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1423.79 ms /    60 tokens (   23.73 ms per token,    42.14 tokens per second)\n",
      "llama_print_timings:        eval time =     232.09 ms /     2 runs   (  116.05 ms per token,     8.62 tokens per second)\n",
      "llama_print_timings:       total time =    1806.53 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     3 runs   (    0.24 ms per token,  4249.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1034.07 ms /    41 tokens (   25.22 ms per token,    39.65 tokens per second)\n",
      "llama_print_timings:        eval time =     218.89 ms /     2 runs   (  109.45 ms per token,     9.14 tokens per second)\n",
      "llama_print_timings:       total time =    1349.23 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4792.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1044.64 ms /    41 tokens (   25.48 ms per token,    39.25 tokens per second)\n",
      "llama_print_timings:        eval time =     204.21 ms /     2 runs   (  102.11 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =    1346.07 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     3 runs   (    0.27 ms per token,  3680.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1291.39 ms /    54 tokens (   23.91 ms per token,    41.82 tokens per second)\n",
      "llama_print_timings:        eval time =     202.60 ms /     2 runs   (  101.30 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =    1625.99 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4838.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1189.43 ms /    50 tokens (   23.79 ms per token,    42.04 tokens per second)\n",
      "llama_print_timings:        eval time =     204.34 ms /     2 runs   (  102.17 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =    1507.76 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4587.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1289.01 ms /    54 tokens (   23.87 ms per token,    41.89 tokens per second)\n",
      "llama_print_timings:        eval time =     209.02 ms /     2 runs   (  104.51 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    1624.32 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4444.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1452.81 ms /    61 tokens (   23.82 ms per token,    41.99 tokens per second)\n",
      "llama_print_timings:        eval time =     222.45 ms /     2 runs   (  111.22 ms per token,     8.99 tokens per second)\n",
      "llama_print_timings:       total time =    1812.25 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4594.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1187.99 ms /    49 tokens (   24.24 ms per token,    41.25 tokens per second)\n",
      "llama_print_timings:        eval time =     204.90 ms /     2 runs   (  102.45 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    1508.20 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4531.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1220.51 ms /    52 tokens (   23.47 ms per token,    42.61 tokens per second)\n",
      "llama_print_timings:        eval time =     206.87 ms /     2 runs   (  103.43 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    1545.82 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4761.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     988.50 ms /    39 tokens (   25.35 ms per token,    39.45 tokens per second)\n",
      "llama_print_timings:        eval time =     219.11 ms /     2 runs   (  109.55 ms per token,     9.13 tokens per second)\n",
      "llama_print_timings:       total time =    1297.97 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4687.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1101.55 ms /    45 tokens (   24.48 ms per token,    40.85 tokens per second)\n",
      "llama_print_timings:        eval time =     202.69 ms /     2 runs   (  101.35 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =    1411.84 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  4983.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1013.48 ms /    40 tokens (   25.34 ms per token,    39.47 tokens per second)\n",
      "llama_print_timings:        eval time =     205.94 ms /     2 runs   (  102.97 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =    1313.92 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4950.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1042.57 ms /    42 tokens (   24.82 ms per token,    40.29 tokens per second)\n",
      "llama_print_timings:        eval time =     205.44 ms /     2 runs   (  102.72 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =    1345.30 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4807.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1054.28 ms /    43 tokens (   24.52 ms per token,    40.79 tokens per second)\n",
      "llama_print_timings:        eval time =     204.30 ms /     2 runs   (  102.15 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =    1360.30 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4815.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1022.81 ms /    41 tokens (   24.95 ms per token,    40.09 tokens per second)\n",
      "llama_print_timings:        eval time =     217.97 ms /     2 runs   (  108.99 ms per token,     9.18 tokens per second)\n",
      "llama_print_timings:       total time =    1337.98 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4587.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1461.92 ms /    62 tokens (   23.58 ms per token,    42.41 tokens per second)\n",
      "llama_print_timings:        eval time =     223.21 ms /     2 runs   (  111.60 ms per token,     8.96 tokens per second)\n",
      "llama_print_timings:       total time =    1829.33 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4838.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1133.07 ms /    46 tokens (   24.63 ms per token,    40.60 tokens per second)\n",
      "llama_print_timings:        eval time =     202.14 ms /     2 runs   (  101.07 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =    1442.40 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4731.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.21 ms /    49 tokens (   24.05 ms per token,    41.59 tokens per second)\n",
      "llama_print_timings:        eval time =     213.92 ms /     2 runs   (  106.96 ms per token,     9.35 tokens per second)\n",
      "llama_print_timings:       total time =    1504.40 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4815.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     996.29 ms /    40 tokens (   24.91 ms per token,    40.15 tokens per second)\n",
      "llama_print_timings:        eval time =     200.92 ms /     2 runs   (  100.46 ms per token,     9.95 tokens per second)\n",
      "llama_print_timings:       total time =    1287.77 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  4975.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1050.99 ms /    42 tokens (   25.02 ms per token,    39.96 tokens per second)\n",
      "llama_print_timings:        eval time =     215.86 ms /     2 runs   (  107.93 ms per token,     9.27 tokens per second)\n",
      "llama_print_timings:       total time =    1365.57 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  5016.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1015.63 ms /    41 tokens (   24.77 ms per token,    40.37 tokens per second)\n",
      "llama_print_timings:        eval time =     203.36 ms /     2 runs   (  101.68 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =    1314.35 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.58 ms /     3 runs   (    0.19 ms per token,  5128.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1022.51 ms /    40 tokens (   25.56 ms per token,    39.12 tokens per second)\n",
      "llama_print_timings:        eval time =     204.70 ms /     2 runs   (  102.35 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =    1319.79 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4643.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1122.43 ms /    46 tokens (   24.40 ms per token,    40.98 tokens per second)\n",
      "llama_print_timings:        eval time =     206.23 ms /     2 runs   (  103.11 ms per token,     9.70 tokens per second)\n",
      "llama_print_timings:       total time =    1441.56 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4754.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1064.37 ms /    43 tokens (   24.75 ms per token,    40.40 tokens per second)\n",
      "llama_print_timings:        eval time =     206.76 ms /     2 runs   (  103.38 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    1368.57 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4261.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1307.50 ms /    55 tokens (   23.77 ms per token,    42.06 tokens per second)\n",
      "llama_print_timings:        eval time =     202.30 ms /     2 runs   (  101.15 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =    1641.35 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1434.36 ms /    60 tokens (   23.91 ms per token,    41.83 tokens per second)\n",
      "llama_print_timings:        eval time =     223.69 ms /     2 runs   (  111.84 ms per token,     8.94 tokens per second)\n",
      "llama_print_timings:       total time =    1795.60 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4870.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1037.02 ms /    42 tokens (   24.69 ms per token,    40.50 tokens per second)\n",
      "llama_print_timings:        eval time =     205.52 ms /     2 runs   (  102.76 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =    1341.73 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4672.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1068.43 ms /    41 tokens (   26.06 ms per token,    38.37 tokens per second)\n",
      "llama_print_timings:        eval time =     207.91 ms /     2 runs   (  103.95 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    1371.28 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4739.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1130.66 ms /    46 tokens (   24.58 ms per token,    40.68 tokens per second)\n",
      "llama_print_timings:        eval time =     205.25 ms /     2 runs   (  102.62 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =    1449.11 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4672.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1123.99 ms /    46 tokens (   24.43 ms per token,    40.93 tokens per second)\n",
      "llama_print_timings:        eval time =     204.00 ms /     2 runs   (  102.00 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =    1437.25 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4629.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1214.76 ms /    51 tokens (   23.82 ms per token,    41.98 tokens per second)\n",
      "llama_print_timings:        eval time =     199.01 ms /     2 runs   (   99.50 ms per token,    10.05 tokens per second)\n",
      "llama_print_timings:       total time =    1528.81 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4909.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1001.43 ms /    39 tokens (   25.68 ms per token,    38.94 tokens per second)\n",
      "llama_print_timings:        eval time =     214.77 ms /     2 runs   (  107.39 ms per token,     9.31 tokens per second)\n",
      "llama_print_timings:       total time =    1307.24 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4862.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     955.40 ms /    38 tokens (   25.14 ms per token,    39.77 tokens per second)\n",
      "llama_print_timings:        eval time =     210.17 ms /     2 runs   (  105.08 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =    1255.68 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4942.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     971.37 ms /    38 tokens (   25.56 ms per token,    39.12 tokens per second)\n",
      "llama_print_timings:        eval time =     204.55 ms /     2 runs   (  102.28 ms per token,     9.78 tokens per second)\n",
      "llama_print_timings:       total time =    1263.86 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4709.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1042.15 ms /    42 tokens (   24.81 ms per token,    40.30 tokens per second)\n",
      "llama_print_timings:        eval time =     216.99 ms /     2 runs   (  108.50 ms per token,     9.22 tokens per second)\n",
      "llama_print_timings:       total time =    1357.83 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  5033.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1002.76 ms /    40 tokens (   25.07 ms per token,    39.89 tokens per second)\n",
      "llama_print_timings:        eval time =     206.33 ms /     2 runs   (  103.16 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    1301.21 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4724.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1235.13 ms /    51 tokens (   24.22 ms per token,    41.29 tokens per second)\n",
      "llama_print_timings:        eval time =     205.72 ms /     2 runs   (  102.86 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    1558.71 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4862.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     990.36 ms /    39 tokens (   25.39 ms per token,    39.38 tokens per second)\n",
      "llama_print_timings:        eval time =     205.66 ms /     2 runs   (  102.83 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    1286.57 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4545.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1040.72 ms /    42 tokens (   24.78 ms per token,    40.36 tokens per second)\n",
      "llama_print_timings:        eval time =     203.14 ms /     2 runs   (  101.57 ms per token,     9.85 tokens per second)\n",
      "llama_print_timings:       total time =    1340.25 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4854.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1034.62 ms /    41 tokens (   25.23 ms per token,    39.63 tokens per second)\n",
      "llama_print_timings:        eval time =     218.06 ms /     2 runs   (  109.03 ms per token,     9.17 tokens per second)\n",
      "llama_print_timings:       total time =    1349.61 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     4 runs   (    0.20 ms per token,  4975.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1027.35 ms /    41 tokens (   25.06 ms per token,    39.91 tokens per second)\n",
      "llama_print_timings:        eval time =     303.07 ms /     3 runs   (  101.02 ms per token,     9.90 tokens per second)\n",
      "llama_print_timings:       total time =    1429.39 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4846.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1015.90 ms /    41 tokens (   24.78 ms per token,    40.36 tokens per second)\n",
      "llama_print_timings:        eval time =     206.91 ms /     2 runs   (  103.45 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    1319.16 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4559.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1013.53 ms /    40 tokens (   25.34 ms per token,    39.47 tokens per second)\n",
      "llama_print_timings:        eval time =     216.61 ms /     2 runs   (  108.30 ms per token,     9.23 tokens per second)\n",
      "llama_print_timings:       total time =    1322.80 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4518.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1118.98 ms /    46 tokens (   24.33 ms per token,    41.11 tokens per second)\n",
      "llama_print_timings:        eval time =     202.11 ms /     2 runs   (  101.05 ms per token,     9.90 tokens per second)\n",
      "llama_print_timings:       total time =    1431.25 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  5033.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     945.81 ms /    37 tokens (   25.56 ms per token,    39.12 tokens per second)\n",
      "llama_print_timings:        eval time =     208.91 ms /     2 runs   (  104.46 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    1241.96 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4807.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.68 ms /    47 tokens (   24.67 ms per token,    40.53 tokens per second)\n",
      "llama_print_timings:        eval time =     201.82 ms /     2 runs   (  100.91 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =    1481.84 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4926.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1198.57 ms /    50 tokens (   23.97 ms per token,    41.72 tokens per second)\n",
      "llama_print_timings:        eval time =     199.11 ms /     2 runs   (   99.55 ms per token,    10.04 tokens per second)\n",
      "llama_print_timings:       total time =    1516.46 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.59 ms /     3 runs   (    0.20 ms per token,  5050.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     932.74 ms /    37 tokens (   25.21 ms per token,    39.67 tokens per second)\n",
      "llama_print_timings:        eval time =     205.59 ms /     2 runs   (  102.79 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =    1224.70 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4800.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     967.62 ms /    38 tokens (   25.46 ms per token,    39.27 tokens per second)\n",
      "llama_print_timings:        eval time =     217.90 ms /     2 runs   (  108.95 ms per token,     9.18 tokens per second)\n",
      "llama_print_timings:       total time =    1275.92 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4926.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     974.47 ms /    39 tokens (   24.99 ms per token,    40.02 tokens per second)\n",
      "llama_print_timings:        eval time =     207.87 ms /     2 runs   (  103.93 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    1274.08 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  4991.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     976.11 ms /    39 tokens (   25.03 ms per token,    39.95 tokens per second)\n",
      "llama_print_timings:        eval time =     204.58 ms /     2 runs   (  102.29 ms per token,     9.78 tokens per second)\n",
      "llama_print_timings:       total time =    1270.80 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4862.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1051.77 ms /    42 tokens (   25.04 ms per token,    39.93 tokens per second)\n",
      "llama_print_timings:        eval time =     216.07 ms /     2 runs   (  108.04 ms per token,     9.26 tokens per second)\n",
      "llama_print_timings:       total time =    1368.88 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4716.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1088.79 ms /    45 tokens (   24.20 ms per token,    41.33 tokens per second)\n",
      "llama_print_timings:        eval time =     201.09 ms /     2 runs   (  100.55 ms per token,     9.95 tokens per second)\n",
      "llama_print_timings:       total time =    1393.89 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4950.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1193.37 ms /    49 tokens (   24.35 ms per token,    41.06 tokens per second)\n",
      "llama_print_timings:        eval time =     204.51 ms /     2 runs   (  102.25 ms per token,     9.78 tokens per second)\n",
      "llama_print_timings:       total time =    1511.59 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     4 runs   (    0.20 ms per token,  4950.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1063.86 ms /    43 tokens (   24.74 ms per token,    40.42 tokens per second)\n",
      "llama_print_timings:        eval time =     315.25 ms /     3 runs   (  105.08 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =    1486.64 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4552.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1702.28 ms /    68 tokens (   25.03 ms per token,    39.95 tokens per second)\n",
      "llama_print_timings:        eval time =     222.84 ms /     2 runs   (  111.42 ms per token,     8.97 tokens per second)\n",
      "llama_print_timings:       total time =    2081.78 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4777.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1113.14 ms /    45 tokens (   24.74 ms per token,    40.43 tokens per second)\n",
      "llama_print_timings:        eval time =     214.02 ms /     2 runs   (  107.01 ms per token,     9.34 tokens per second)\n",
      "llama_print_timings:       total time =    1430.12 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4665.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1147.65 ms /    48 tokens (   23.91 ms per token,    41.82 tokens per second)\n",
      "llama_print_timings:        eval time =     203.21 ms /     2 runs   (  101.60 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    1478.54 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4854.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1072.54 ms /    43 tokens (   24.94 ms per token,    40.09 tokens per second)\n",
      "llama_print_timings:        eval time =     202.14 ms /     2 runs   (  101.07 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =    1372.81 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.75 ms /     3 runs   (    0.25 ms per token,  4010.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1118.79 ms /    46 tokens (   24.32 ms per token,    41.12 tokens per second)\n",
      "llama_print_timings:        eval time =     209.69 ms /     2 runs   (  104.84 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =    1436.07 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.73 ms /     3 runs   (    0.24 ms per token,  4103.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1098.65 ms /    45 tokens (   24.41 ms per token,    40.96 tokens per second)\n",
      "llama_print_timings:        eval time =     215.22 ms /     2 runs   (  107.61 ms per token,     9.29 tokens per second)\n",
      "llama_print_timings:       total time =    1418.88 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4878.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1090.43 ms /    44 tokens (   24.78 ms per token,    40.35 tokens per second)\n",
      "llama_print_timings:        eval time =     200.75 ms /     2 runs   (  100.37 ms per token,     9.96 tokens per second)\n",
      "llama_print_timings:       total time =    1393.03 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.58 ms /     3 runs   (    0.19 ms per token,  5145.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     927.59 ms /    36 tokens (   25.77 ms per token,    38.81 tokens per second)\n",
      "llama_print_timings:        eval time =     207.97 ms /     2 runs   (  103.98 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    1218.05 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  5033.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     965.70 ms /    38 tokens (   25.41 ms per token,    39.35 tokens per second)\n",
      "llama_print_timings:        eval time =     214.67 ms /     2 runs   (  107.34 ms per token,     9.32 tokens per second)\n",
      "llama_print_timings:       total time =    1268.47 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4709.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1201.73 ms /    50 tokens (   24.03 ms per token,    41.61 tokens per second)\n",
      "llama_print_timings:        eval time =     203.90 ms /     2 runs   (  101.95 ms per token,     9.81 tokens per second)\n",
      "llama_print_timings:       total time =    1525.02 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4665.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.39 ms /    48 tokens (   24.34 ms per token,    41.08 tokens per second)\n",
      "llama_print_timings:        eval time =     204.14 ms /     2 runs   (  102.07 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =    1486.61 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4830.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1079.30 ms /    44 tokens (   24.53 ms per token,    40.77 tokens per second)\n",
      "llama_print_timings:        eval time =     213.33 ms /     2 runs   (  106.67 ms per token,     9.38 tokens per second)\n",
      "llama_print_timings:       total time =    1392.19 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4672.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1415.62 ms /    60 tokens (   23.59 ms per token,    42.38 tokens per second)\n",
      "llama_print_timings:        eval time =     219.76 ms /     2 runs   (  109.88 ms per token,     9.10 tokens per second)\n",
      "llama_print_timings:       total time =    1774.70 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4658.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1313.14 ms /    55 tokens (   23.88 ms per token,    41.88 tokens per second)\n",
      "llama_print_timings:        eval time =     199.09 ms /     2 runs   (   99.54 ms per token,    10.05 tokens per second)\n",
      "llama_print_timings:       total time =    1639.83 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4643.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1045.25 ms /    42 tokens (   24.89 ms per token,    40.18 tokens per second)\n",
      "llama_print_timings:        eval time =     213.70 ms /     2 runs   (  106.85 ms per token,     9.36 tokens per second)\n",
      "llama_print_timings:       total time =    1354.37 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     3 runs   (    0.23 ms per token,  4279.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2299.91 ms /    98 tokens (   23.47 ms per token,    42.61 tokens per second)\n",
      "llama_print_timings:        eval time =     241.44 ms /     2 runs   (  120.72 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =    2760.68 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4918.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1031.93 ms /    42 tokens (   24.57 ms per token,    40.70 tokens per second)\n",
      "llama_print_timings:        eval time =     202.98 ms /     2 runs   (  101.49 ms per token,     9.85 tokens per second)\n",
      "llama_print_timings:       total time =    1329.08 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4444.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4577.77 ms /   193 tokens (   23.72 ms per token,    42.16 tokens per second)\n",
      "llama_print_timings:        eval time =     290.32 ms /     2 runs   (  145.16 ms per token,     6.89 tokens per second)\n",
      "llama_print_timings:       total time =    5282.85 ms /   195 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4878.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1089.32 ms /    44 tokens (   24.76 ms per token,    40.39 tokens per second)\n",
      "llama_print_timings:        eval time =     202.82 ms /     2 runs   (  101.41 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =    1401.22 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4746.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1089.32 ms /    44 tokens (   24.76 ms per token,    40.39 tokens per second)\n",
      "llama_print_timings:        eval time =     203.03 ms /     2 runs   (  101.52 ms per token,     9.85 tokens per second)\n",
      "llama_print_timings:       total time =    1395.86 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.59 ms /     3 runs   (    0.20 ms per token,  5093.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     884.31 ms /    34 tokens (   26.01 ms per token,    38.45 tokens per second)\n",
      "llama_print_timings:        eval time =     204.25 ms /     2 runs   (  102.12 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =    1175.12 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4761.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1066.31 ms /    43 tokens (   24.80 ms per token,    40.33 tokens per second)\n",
      "llama_print_timings:        eval time =     217.31 ms /     2 runs   (  108.65 ms per token,     9.20 tokens per second)\n",
      "llama_print_timings:       total time =    1383.15 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4709.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1070.31 ms /    43 tokens (   24.89 ms per token,    40.18 tokens per second)\n",
      "llama_print_timings:        eval time =     202.74 ms /     2 runs   (  101.37 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =    1371.22 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4893.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1005.77 ms /    40 tokens (   25.14 ms per token,    39.77 tokens per second)\n",
      "llama_print_timings:        eval time =     214.63 ms /     2 runs   (  107.31 ms per token,     9.32 tokens per second)\n",
      "llama_print_timings:       total time =    1313.47 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4777.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.46 ms /    48 tokens (   24.09 ms per token,    41.51 tokens per second)\n",
      "llama_print_timings:        eval time =     203.53 ms /     2 runs   (  101.76 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =    1476.47 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  4975.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1084.74 ms /    44 tokens (   24.65 ms per token,    40.56 tokens per second)\n",
      "llama_print_timings:        eval time =     201.60 ms /     2 runs   (  100.80 ms per token,     9.92 tokens per second)\n",
      "llama_print_timings:       total time =    1386.82 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4823.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1091.63 ms /    45 tokens (   24.26 ms per token,    41.22 tokens per second)\n",
      "llama_print_timings:        eval time =     207.63 ms /     2 runs   (  103.81 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    1404.75 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4862.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1120.55 ms /    46 tokens (   24.36 ms per token,    41.05 tokens per second)\n",
      "llama_print_timings:        eval time =     203.55 ms /     2 runs   (  101.78 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =    1426.99 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4724.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1118.56 ms /    46 tokens (   24.32 ms per token,    41.12 tokens per second)\n",
      "llama_print_timings:        eval time =     202.61 ms /     2 runs   (  101.30 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =    1426.36 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4901.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1015.30 ms /    41 tokens (   24.76 ms per token,    40.38 tokens per second)\n",
      "llama_print_timings:        eval time =     210.20 ms /     2 runs   (  105.10 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =    1320.77 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4792.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1205.42 ms /    49 tokens (   24.60 ms per token,    40.65 tokens per second)\n",
      "llama_print_timings:        eval time =     204.01 ms /     2 runs   (  102.01 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =    1519.63 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4784.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1059.59 ms /    43 tokens (   24.64 ms per token,    40.58 tokens per second)\n",
      "llama_print_timings:        eval time =     220.65 ms /     2 runs   (  110.33 ms per token,     9.06 tokens per second)\n",
      "llama_print_timings:       total time =    1378.37 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4531.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1074.85 ms /    44 tokens (   24.43 ms per token,    40.94 tokens per second)\n",
      "llama_print_timings:        eval time =     209.70 ms /     2 runs   (  104.85 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =    1387.79 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4950.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1037.15 ms /    42 tokens (   24.69 ms per token,    40.50 tokens per second)\n",
      "llama_print_timings:        eval time =     202.94 ms /     2 runs   (  101.47 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =    1335.63 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4784.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1078.65 ms /    43 tokens (   25.08 ms per token,    39.86 tokens per second)\n",
      "llama_print_timings:        eval time =     204.97 ms /     2 runs   (  102.49 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    1382.14 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4784.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1032.62 ms /    42 tokens (   24.59 ms per token,    40.67 tokens per second)\n",
      "llama_print_timings:        eval time =     225.37 ms /     2 runs   (  112.69 ms per token,     8.87 tokens per second)\n",
      "llama_print_timings:       total time =    1353.46 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4739.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.11 ms /    48 tokens (   23.98 ms per token,    41.70 tokens per second)\n",
      "llama_print_timings:        eval time =     204.07 ms /     2 runs   (  102.04 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =    1463.71 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4830.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.62 ms /    47 tokens (   24.74 ms per token,    40.43 tokens per second)\n",
      "llama_print_timings:        eval time =     201.76 ms /     2 runs   (  100.88 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =    1470.60 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4559.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1215.60 ms /    50 tokens (   24.31 ms per token,    41.13 tokens per second)\n",
      "llama_print_timings:        eval time =     214.69 ms /     2 runs   (  107.35 ms per token,     9.32 tokens per second)\n",
      "llama_print_timings:       total time =    1546.95 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4552.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     964.68 ms /    38 tokens (   25.39 ms per token,    39.39 tokens per second)\n",
      "llama_print_timings:        eval time =     207.62 ms /     2 runs   (  103.81 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    1262.83 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4636.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1288.13 ms /    54 tokens (   23.85 ms per token,    41.92 tokens per second)\n",
      "llama_print_timings:        eval time =     206.46 ms /     2 runs   (  103.23 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    1618.65 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4862.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1190.20 ms /    49 tokens (   24.29 ms per token,    41.17 tokens per second)\n",
      "llama_print_timings:        eval time =     203.80 ms /     2 runs   (  101.90 ms per token,     9.81 tokens per second)\n",
      "llama_print_timings:       total time =    1504.64 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /     3 runs   (    0.24 ms per token,  4184.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1110.82 ms /    46 tokens (   24.15 ms per token,    41.41 tokens per second)\n",
      "llama_print_timings:        eval time =     207.89 ms /     2 runs   (  103.95 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    1436.94 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4457.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1104.16 ms /    45 tokens (   24.54 ms per token,    40.76 tokens per second)\n",
      "llama_print_timings:        eval time =     205.09 ms /     2 runs   (  102.54 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =    1414.50 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4608.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1303.34 ms /    55 tokens (   23.70 ms per token,    42.20 tokens per second)\n",
      "llama_print_timings:        eval time =     201.46 ms /     2 runs   (  100.73 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:       total time =    1628.24 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4601.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1200.96 ms /    50 tokens (   24.02 ms per token,    41.63 tokens per second)\n",
      "llama_print_timings:        eval time =     206.63 ms /     2 runs   (  103.31 ms per token,     9.68 tokens per second)\n",
      "llama_print_timings:       total time =    1522.74 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.73 ms /     3 runs   (    0.24 ms per token,  4103.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2127.45 ms /    90 tokens (   23.64 ms per token,    42.30 tokens per second)\n",
      "llama_print_timings:        eval time =     243.69 ms /     2 runs   (  121.84 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =    2567.00 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4709.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1306.39 ms /    56 tokens (   23.33 ms per token,    42.87 tokens per second)\n",
      "llama_print_timings:        eval time =     239.68 ms /     2 runs   (  119.84 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =    1671.36 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4731.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1102.05 ms /    45 tokens (   24.49 ms per token,    40.83 tokens per second)\n",
      "llama_print_timings:        eval time =     205.09 ms /     2 runs   (  102.55 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =    1412.58 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  4983.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1043.06 ms /    41 tokens (   25.44 ms per token,    39.31 tokens per second)\n",
      "llama_print_timings:        eval time =     208.17 ms /     2 runs   (  104.09 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    1347.49 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     3 runs   (    0.24 ms per token,  4201.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1084.49 ms /    44 tokens (   24.65 ms per token,    40.57 tokens per second)\n",
      "llama_print_timings:        eval time =     217.24 ms /     2 runs   (  108.62 ms per token,     9.21 tokens per second)\n",
      "llama_print_timings:       total time =    1411.34 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4926.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     981.20 ms /    39 tokens (   25.16 ms per token,    39.75 tokens per second)\n",
      "llama_print_timings:        eval time =     205.53 ms /     2 runs   (  102.77 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =    1275.85 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /    16 runs   (    0.21 ms per token,  4705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1090.61 ms /    44 tokens (   24.79 ms per token,    40.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1552.90 ms /    15 runs   (  103.53 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    2782.55 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4636.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1215.27 ms /    51 tokens (   23.83 ms per token,    41.97 tokens per second)\n",
      "llama_print_timings:        eval time =     207.80 ms /     2 runs   (  103.90 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    1549.34 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4854.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1028.73 ms /    41 tokens (   25.09 ms per token,    39.85 tokens per second)\n",
      "llama_print_timings:        eval time =     207.31 ms /     2 runs   (  103.65 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =    1329.60 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4587.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1099.87 ms /    45 tokens (   24.44 ms per token,    40.91 tokens per second)\n",
      "llama_print_timings:        eval time =     202.54 ms /     2 runs   (  101.27 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =    1410.04 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4615.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     989.84 ms /    39 tokens (   25.38 ms per token,    39.40 tokens per second)\n",
      "llama_print_timings:        eval time =     205.56 ms /     2 runs   (  102.78 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =    1286.81 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4815.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     992.77 ms /    39 tokens (   25.46 ms per token,    39.28 tokens per second)\n",
      "llama_print_timings:        eval time =     215.00 ms /     2 runs   (  107.50 ms per token,     9.30 tokens per second)\n",
      "llama_print_timings:       total time =    1298.78 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4709.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1053.48 ms /    43 tokens (   24.50 ms per token,    40.82 tokens per second)\n",
      "llama_print_timings:        eval time =     205.34 ms /     2 runs   (  102.67 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =    1357.70 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4615.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1362.91 ms /    58 tokens (   23.50 ms per token,    42.56 tokens per second)\n",
      "llama_print_timings:        eval time =     225.54 ms /     2 runs   (  112.77 ms per token,     8.87 tokens per second)\n",
      "llama_print_timings:       total time =    1717.90 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4893.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1353.23 ms /    57 tokens (   23.74 ms per token,    42.12 tokens per second)\n",
      "llama_print_timings:        eval time =     222.30 ms /     2 runs   (  111.15 ms per token,     9.00 tokens per second)\n",
      "llama_print_timings:       total time =    1701.77 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       3.28 ms /    16 runs   (    0.21 ms per token,  4876.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     931.69 ms /    36 tokens (   25.88 ms per token,    38.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1540.69 ms /    15 runs   (  102.71 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =    2595.95 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  5025.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1010.48 ms /    40 tokens (   25.26 ms per token,    39.59 tokens per second)\n",
      "llama_print_timings:        eval time =     206.17 ms /     2 runs   (  103.08 ms per token,     9.70 tokens per second)\n",
      "llama_print_timings:       total time =    1308.48 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4629.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1289.49 ms /    55 tokens (   23.45 ms per token,    42.65 tokens per second)\n",
      "llama_print_timings:        eval time =     202.50 ms /     2 runs   (  101.25 ms per token,     9.88 tokens per second)\n",
      "llama_print_timings:       total time =    1614.65 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4784.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1046.18 ms /    42 tokens (   24.91 ms per token,    40.15 tokens per second)\n",
      "llama_print_timings:        eval time =     218.86 ms /     2 runs   (  109.43 ms per token,     9.14 tokens per second)\n",
      "llama_print_timings:       total time =    1363.42 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4746.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1111.45 ms /    45 tokens (   24.70 ms per token,    40.49 tokens per second)\n",
      "llama_print_timings:        eval time =     204.98 ms /     2 runs   (  102.49 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    1420.67 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4823.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1380.69 ms /    58 tokens (   23.81 ms per token,    42.01 tokens per second)\n",
      "llama_print_timings:        eval time =     224.57 ms /     2 runs   (  112.29 ms per token,     8.91 tokens per second)\n",
      "llama_print_timings:       total time =    1737.39 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4893.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1119.83 ms /    46 tokens (   24.34 ms per token,    41.08 tokens per second)\n",
      "llama_print_timings:        eval time =     202.02 ms /     2 runs   (  101.01 ms per token,     9.90 tokens per second)\n",
      "llama_print_timings:       total time =    1438.33 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       3.56 ms /    16 runs   (    0.22 ms per token,  4493.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1211.95 ms /    51 tokens (   23.76 ms per token,    42.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1636.58 ms /    15 runs   (  109.11 ms per token,     9.17 tokens per second)\n",
      "llama_print_timings:       total time =    3004.00 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4901.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1126.03 ms /    47 tokens (   23.96 ms per token,    41.74 tokens per second)\n",
      "llama_print_timings:        eval time =     216.85 ms /     2 runs   (  108.42 ms per token,     9.22 tokens per second)\n",
      "llama_print_timings:       total time =    1448.79 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4587.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1152.65 ms /    48 tokens (   24.01 ms per token,    41.64 tokens per second)\n",
      "llama_print_timings:        eval time =     212.26 ms /     2 runs   (  106.13 ms per token,     9.42 tokens per second)\n",
      "llama_print_timings:       total time =    1483.70 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  5000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1107.74 ms /    46 tokens (   24.08 ms per token,    41.53 tokens per second)\n",
      "llama_print_timings:        eval time =     200.30 ms /     2 runs   (  100.15 ms per token,     9.99 tokens per second)\n",
      "llama_print_timings:       total time =    1415.31 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4918.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1005.03 ms /    39 tokens (   25.77 ms per token,    38.80 tokens per second)\n",
      "llama_print_timings:        eval time =     210.55 ms /     2 runs   (  105.28 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =    1312.87 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  4975.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     983.73 ms /    38 tokens (   25.89 ms per token,    38.63 tokens per second)\n",
      "llama_print_timings:        eval time =     206.63 ms /     2 runs   (  103.32 ms per token,     9.68 tokens per second)\n",
      "llama_print_timings:       total time =    1278.37 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4702.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.15 ms /    48 tokens (   24.54 ms per token,    40.74 tokens per second)\n",
      "llama_print_timings:        eval time =     202.11 ms /     2 runs   (  101.06 ms per token,     9.90 tokens per second)\n",
      "llama_print_timings:       total time =    1488.78 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4777.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1098.47 ms /    44 tokens (   24.97 ms per token,    40.06 tokens per second)\n",
      "llama_print_timings:        eval time =     206.00 ms /     2 runs   (  103.00 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =    1404.57 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4658.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.50 ms /    53 tokens (   23.92 ms per token,    41.81 tokens per second)\n",
      "llama_print_timings:        eval time =     204.08 ms /     2 runs   (  102.04 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =    1595.11 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4885.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     989.44 ms /    39 tokens (   25.37 ms per token,    39.42 tokens per second)\n",
      "llama_print_timings:        eval time =     203.32 ms /     2 runs   (  101.66 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    1281.96 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4418.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.41 ms /    48 tokens (   24.47 ms per token,    40.87 tokens per second)\n",
      "llama_print_timings:        eval time =     206.20 ms /     2 runs   (  103.10 ms per token,     9.70 tokens per second)\n",
      "llama_print_timings:       total time =    1491.10 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4823.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1435.15 ms /    60 tokens (   23.92 ms per token,    41.81 tokens per second)\n",
      "llama_print_timings:        eval time =     223.63 ms /     2 runs   (  111.81 ms per token,     8.94 tokens per second)\n",
      "llama_print_timings:       total time =    1792.57 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.41 ms /     2 runs   (    0.20 ms per token,  4889.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     987.82 ms /    39 tokens (   25.33 ms per token,    39.48 tokens per second)\n",
      "llama_print_timings:        eval time =     103.46 ms /     1 runs   (  103.46 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    1178.15 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4909.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1088.27 ms /    43 tokens (   25.31 ms per token,    39.51 tokens per second)\n",
      "llama_print_timings:        eval time =     208.23 ms /     2 runs   (  104.11 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    1395.13 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4761.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1070.02 ms /    43 tokens (   24.88 ms per token,    40.19 tokens per second)\n",
      "llama_print_timings:        eval time =     206.39 ms /     2 runs   (  103.19 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    1378.81 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4587.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1236.25 ms /    52 tokens (   23.77 ms per token,    42.06 tokens per second)\n",
      "llama_print_timings:        eval time =     205.40 ms /     2 runs   (  102.70 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =    1557.90 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  5025.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1077.35 ms /    43 tokens (   25.05 ms per token,    39.91 tokens per second)\n",
      "llama_print_timings:        eval time =     206.80 ms /     2 runs   (  103.40 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    1383.49 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  5000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1130.73 ms /    46 tokens (   24.58 ms per token,    40.68 tokens per second)\n",
      "llama_print_timings:        eval time =     204.18 ms /     2 runs   (  102.09 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =    1441.27 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.40 ms /     2 runs   (    0.20 ms per token,  5037.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     999.60 ms /    39 tokens (   25.63 ms per token,    39.02 tokens per second)\n",
      "llama_print_timings:        eval time =     102.35 ms /     1 runs   (  102.35 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =    1189.98 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.59 ms /     3 runs   (    0.20 ms per token,  5050.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     948.57 ms /    36 tokens (   26.35 ms per token,    37.95 tokens per second)\n",
      "llama_print_timings:        eval time =     203.44 ms /     2 runs   (  101.72 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =    1237.15 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  4991.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1046.03 ms /    42 tokens (   24.91 ms per token,    40.15 tokens per second)\n",
      "llama_print_timings:        eval time =     205.56 ms /     2 runs   (  102.78 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =    1347.04 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4792.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1295.56 ms /    54 tokens (   23.99 ms per token,    41.68 tokens per second)\n",
      "llama_print_timings:        eval time =     202.31 ms /     2 runs   (  101.16 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =    1618.86 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     3 runs   (    0.22 ms per token,  4545.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     992.31 ms /    38 tokens (   26.11 ms per token,    38.29 tokens per second)\n",
      "llama_print_timings:        eval time =     211.35 ms /     2 runs   (  105.67 ms per token,     9.46 tokens per second)\n",
      "llama_print_timings:       total time =    1292.01 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     4 runs   (    0.20 ms per token,  4926.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1010.21 ms /    40 tokens (   25.26 ms per token,    39.60 tokens per second)\n",
      "llama_print_timings:        eval time =     311.58 ms /     3 runs   (  103.86 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    1418.17 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4687.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1085.23 ms /    44 tokens (   24.66 ms per token,    40.54 tokens per second)\n",
      "llama_print_timings:        eval time =     206.03 ms /     2 runs   (  103.01 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =    1394.28 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4934.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1152.29 ms /    47 tokens (   24.52 ms per token,    40.79 tokens per second)\n",
      "llama_print_timings:        eval time =     202.03 ms /     2 runs   (  101.02 ms per token,     9.90 tokens per second)\n",
      "llama_print_timings:       total time =    1460.70 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     3 runs   (    0.21 ms per token,  4672.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1184.45 ms /    49 tokens (   24.17 ms per token,    41.37 tokens per second)\n",
      "llama_print_timings:        eval time =     215.95 ms /     2 runs   (  107.97 ms per token,     9.26 tokens per second)\n",
      "llama_print_timings:       total time =    1513.56 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4934.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1013.38 ms /    40 tokens (   25.33 ms per token,    39.47 tokens per second)\n",
      "llama_print_timings:        eval time =     207.61 ms /     2 runs   (  103.81 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    1312.09 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4870.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1050.60 ms /    42 tokens (   25.01 ms per token,    39.98 tokens per second)\n",
      "llama_print_timings:        eval time =     213.32 ms /     2 runs   (  106.66 ms per token,     9.38 tokens per second)\n",
      "llama_print_timings:       total time =    1359.50 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       3.23 ms /    16 runs   (    0.20 ms per token,  4956.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     969.58 ms /    38 tokens (   25.52 ms per token,    39.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1536.43 ms /    15 runs   (  102.43 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    2635.56 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4950.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1048.48 ms /    42 tokens (   24.96 ms per token,    40.06 tokens per second)\n",
      "llama_print_timings:        eval time =     207.20 ms /     2 runs   (  103.60 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =    1350.65 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4942.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1048.46 ms /    42 tokens (   24.96 ms per token,    40.06 tokens per second)\n",
      "llama_print_timings:        eval time =     206.62 ms /     2 runs   (  103.31 ms per token,     9.68 tokens per second)\n",
      "llama_print_timings:       total time =    1351.06 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4823.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1112.35 ms /    45 tokens (   24.72 ms per token,    40.46 tokens per second)\n",
      "llama_print_timings:        eval time =     203.24 ms /     2 runs   (  101.62 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    1418.10 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4838.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1031.91 ms /    41 tokens (   25.17 ms per token,    39.73 tokens per second)\n",
      "llama_print_timings:        eval time =     202.53 ms /     2 runs   (  101.26 ms per token,     9.88 tokens per second)\n",
      "llama_print_timings:       total time =    1328.26 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4777.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.15 ms /    47 tokens (   24.49 ms per token,    40.83 tokens per second)\n",
      "llama_print_timings:        eval time =     205.42 ms /     2 runs   (  102.71 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =    1464.50 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     4 runs   (    0.20 ms per token,  4962.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1029.78 ms /    41 tokens (   25.12 ms per token,    39.81 tokens per second)\n",
      "llama_print_timings:        eval time =     305.58 ms /     3 runs   (  101.86 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =    1432.05 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4784.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1017.44 ms /    40 tokens (   25.44 ms per token,    39.31 tokens per second)\n",
      "llama_print_timings:        eval time =     204.73 ms /     2 runs   (  102.37 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =    1317.01 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4746.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1149.58 ms /    47 tokens (   24.46 ms per token,    40.88 tokens per second)\n",
      "llama_print_timings:        eval time =     205.78 ms /     2 runs   (  102.89 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    1462.15 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.58 ms /     3 runs   (    0.19 ms per token,  5128.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1010.32 ms /    40 tokens (   25.26 ms per token,    39.59 tokens per second)\n",
      "llama_print_timings:        eval time =     203.64 ms /     2 runs   (  101.82 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =    1316.28 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.59 ms /     3 runs   (    0.20 ms per token,  5042.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1108.86 ms /    45 tokens (   24.64 ms per token,    40.58 tokens per second)\n",
      "llama_print_timings:        eval time =     207.32 ms /     2 runs   (  103.66 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =    1420.81 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4731.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1122.41 ms /    46 tokens (   24.40 ms per token,    40.98 tokens per second)\n",
      "llama_print_timings:        eval time =     202.71 ms /     2 runs   (  101.35 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =    1430.06 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     3 runs   (    0.22 ms per token,  4497.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1202.96 ms /    50 tokens (   24.06 ms per token,    41.56 tokens per second)\n",
      "llama_print_timings:        eval time =     201.85 ms /     2 runs   (  100.92 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =    1518.44 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  4983.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1131.22 ms /    46 tokens (   24.59 ms per token,    40.66 tokens per second)\n",
      "llama_print_timings:        eval time =     205.78 ms /     2 runs   (  102.89 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    1443.17 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.58 ms /     3 runs   (    0.19 ms per token,  5145.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     931.39 ms /    36 tokens (   25.87 ms per token,    38.65 tokens per second)\n",
      "llama_print_timings:        eval time =     207.25 ms /     2 runs   (  103.62 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =    1221.76 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4885.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1149.24 ms /    46 tokens (   24.98 ms per token,    40.03 tokens per second)\n",
      "llama_print_timings:        eval time =     204.65 ms /     2 runs   (  102.33 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =    1461.72 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.21 ms per token,  4651.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1334.42 ms /    56 tokens (   23.83 ms per token,    41.97 tokens per second)\n",
      "llama_print_timings:        eval time =     212.08 ms /     2 runs   (  106.04 ms per token,     9.43 tokens per second)\n",
      "llama_print_timings:       total time =    1676.38 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4854.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1143.94 ms /    46 tokens (   24.87 ms per token,    40.21 tokens per second)\n",
      "llama_print_timings:        eval time =     205.11 ms /     2 runs   (  102.56 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =    1461.99 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4909.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     987.66 ms /    39 tokens (   25.32 ms per token,    39.49 tokens per second)\n",
      "llama_print_timings:        eval time =     205.24 ms /     2 runs   (  102.62 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =    1284.48 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1529.03 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4754.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1221.08 ms /    50 tokens (   24.42 ms per token,    40.95 tokens per second)\n",
      "llama_print_timings:        eval time =     205.20 ms /     2 runs   (  102.60 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =    1546.96 ms /    52 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# change paths appropriately\n",
    "# make sure the output filename is the same as the reference filename for the scoring program\n",
    "path_val_model_agnostic = \"../raw/SHROOM_dev-v2/val.model-agnostic.json\"\n",
    "path_val_model_agnostic_output = \"./val.model-agnostic.json\"\n",
    "\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import tqdm.notebook as tqdm\n",
    "seed_val = 442\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "\n",
    "# alternatively, one can use HuggingFace's library to load the data\n",
    "dataset = load_dataset('json', data_files={'val':path_val_model_agnostic})\n",
    "data_val_all = dataset['val']\n",
    "num_sample = len(data_val_all)\n",
    "print(dataset)\n",
    "print(num_sample)\n",
    "\n",
    "output_json = []\n",
    "labels = [\"Not Hallucination\", \"Hallucination\"]\n",
    "\"\"\"\n",
    "SelfCheckGPT Usage: (LLM) Prompt\n",
    "https://github.com/potsawee/selfcheckgpt\n",
    "Context: {}\n",
    "Sentence: {}\n",
    "Is the sentence supported by the context above?\n",
    "Answer Yes or No:\n",
    "\"\"\"\n",
    "for i in tqdm.trange(num_sample):\n",
    "    # label = str(data_val_all[i]['label'])\n",
    "    task = str(data_val_all[i]['task'])\n",
    "    if run_on_test:\n",
    "        # test splits will contain ids to ensure correct alignment before scoring\n",
    "        id = int(data_val_all[i]['id'])\n",
    "    hyp = str(data_val_all[i]['hyp'])\n",
    "    src = str(data_val_all[i]['src'])\n",
    "    tgt = str(data_val_all[i]['tgt'])\n",
    "\n",
    "    if task == \"PG\":\n",
    "        context = f\"Context: {src}\"\n",
    "    else: #i.e. task == \"MT\" or task == \"DM\":\n",
    "        context = f\"Context: {tgt}\"\n",
    "\n",
    "    sentence = f\"Sentence: {hyp}\"\n",
    "    message = f\"{context}\\n{sentence}\\nIs the Sentence supported by the Context above? Answer using ONLY yes or no:\"\n",
    "    prompt = f\"<s>[INST] {message} [/INST]\"\n",
    "\n",
    "    response = lcpp_llm(\n",
    "        prompt=prompt,\n",
    "        temperature= 0.0,\n",
    "        logprobs=1,\n",
    "    )\n",
    "    answer = str(response[\"choices\"][0][\"text\"]).strip().lower()\n",
    "    if answer.startswith(\"yes\"):\n",
    "        output_label = \"Not Hallucination\"\n",
    "        prob = 1-float(np.exp(response[\"choices\"][0][\"logprobs\"][\"token_logprobs\"][0]))\n",
    "    if answer.startswith(\"no\"):\n",
    "        output_label = \"Hallucination\"\n",
    "        prob = float(np.exp(response[\"choices\"][0][\"logprobs\"][\"token_logprobs\"][0]))\n",
    "    if not answer.startswith(\"no\") and not answer.startswith(\"yes\"):\n",
    "        idx_random = random.randint(0,len(labels)-1)\n",
    "        output_label = labels[idx_random]\n",
    "        prob = float(0.5)\n",
    "\n",
    "    item_to_json = {\"label\":output_label, \"p(Hallucination)\":prob}\n",
    "    if run_on_test:\n",
    "        item_to_json['id'] = id\n",
    "    output_json.append(item_to_json)\n",
    "\n",
    "\n",
    "f = open(path_val_model_agnostic_output, 'w', encoding='utf-8')\n",
    "json.dump(output_json, f)\n",
    "f.close()\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04b2b191f387469facbc7e0f63edd957": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c18583fabf94cf88d89e9d0ad83cd46",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_16ceb8ceabea4adeb2ed5d3c62a52e87",
      "value": 1
     }
    },
    "07bb3c8d23084467b680d0f8be879bcd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "08db236b9ee74ccb9ac456bf09e298e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ea36c0ff6cd4559bf733fb73ff82693": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fca89659d3684477bb46613bbb96383d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_265b13864e334d2d8875d1de157c428a",
      "value": 1
     }
    },
    "16ceb8ceabea4adeb2ed5d3c62a52e87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1c18583fabf94cf88d89e9d0ad83cd46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "265b13864e334d2d8875d1de157c428a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2abefc6082af406ab1c955a880a2b419": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2ae89d1a8a074a249b750d138587e44d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eb30e73c1e824fa8942f0c58104d696f",
       "IPY_MODEL_df0a135d8a5b43d5ab94bef15b2db5aa",
       "IPY_MODEL_a5e99c0d3739407799fde2f29a301d05"
      ],
      "layout": "IPY_MODEL_fa5555299e2e47ae9d2cc7a7e58415f4"
     }
    },
    "2b25549d8eac4efd99bf1beb4fb26b0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3e1566a3d2f64b5fbbaf7cc51b9c9902": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48be64dd9497468f83d73bd119591271": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cebd82bbc195424a908c9527ee1a21d3",
      "placeholder": "​",
      "style": "IPY_MODEL_8665cfefbc984fc4873e73cd96d6c018",
      "value": "Downloading data files: 100%"
     }
    },
    "4f891d2316604dd08cd5ffd22c8854d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c70248a7e6e45199ed626fa68037174",
      "placeholder": "​",
      "style": "IPY_MODEL_07bb3c8d23084467b680d0f8be879bcd",
      "value": "Generating val split: "
     }
    },
    "4facca9ecbd74aa5b4dc474634686064": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c70248a7e6e45199ed626fa68037174": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c4a2676871e492897d305d6d9a6fac9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "823cdbf0fa2c43559d01de4664258a86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8665cfefbc984fc4873e73cd96d6c018": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "86da540e05824f2c95b5c8bea9b4581d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d1f94d67f08449439e3191bcdf87c6bf",
       "IPY_MODEL_cb886b4dac084c0290e1fd1c229b092e",
       "IPY_MODEL_8b8fd80c79c54e479b15f798bc545b96"
      ],
      "layout": "IPY_MODEL_3e1566a3d2f64b5fbbaf7cc51b9c9902"
     }
    },
    "8b8fd80c79c54e479b15f798bc545b96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08db236b9ee74ccb9ac456bf09e298e1",
      "placeholder": "​",
      "style": "IPY_MODEL_977e8b1928ec42a285804dcc8fc13cb5",
      "value": " 1/1 [00:00&lt;00:00,  1.86it/s]"
     }
    },
    "977e8b1928ec42a285804dcc8fc13cb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9f4e1bc76cfb4643877686a6f0271b52": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0ceffacff7f492d87084da291061006": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0f2fe09ab0a4a21acda513f96bb7faf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4f891d2316604dd08cd5ffd22c8854d9",
       "IPY_MODEL_0ea36c0ff6cd4559bf733fb73ff82693",
       "IPY_MODEL_de38e0a8f5a24cbdbf755db3cfd399ec"
      ],
      "layout": "IPY_MODEL_9f4e1bc76cfb4643877686a6f0271b52"
     }
    },
    "a5e99c0d3739407799fde2f29a301d05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e35a5293e19748679095d1222f1a31e5",
      "placeholder": "​",
      "style": "IPY_MODEL_2abefc6082af406ab1c955a880a2b419",
      "value": " 5.94G/5.94G [00:45&lt;00:00, 157MB/s]"
     }
    },
    "ac217ebd99d94729ac89ed81fc0a0ab5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aeaed97ed3f441e9aa2ce24c87e02d87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af87959da48a436e842f58ac691717df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "aff193ecfc2e4d5a8b3ddd4f63604e63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_48be64dd9497468f83d73bd119591271",
       "IPY_MODEL_04b2b191f387469facbc7e0f63edd957",
       "IPY_MODEL_e225b3758fa24df3a0d6f1a039d3220a"
      ],
      "layout": "IPY_MODEL_aeaed97ed3f441e9aa2ce24c87e02d87"
     }
    },
    "c96a1b051a7b4fbfbd873be07cf44cf0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb886b4dac084c0290e1fd1c229b092e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4facca9ecbd74aa5b4dc474634686064",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f52b2088b6724e6dad9ee18ba364c009",
      "value": 1
     }
    },
    "cebd82bbc195424a908c9527ee1a21d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1f94d67f08449439e3191bcdf87c6bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac217ebd99d94729ac89ed81fc0a0ab5",
      "placeholder": "​",
      "style": "IPY_MODEL_2b25549d8eac4efd99bf1beb4fb26b0c",
      "value": "Extracting data files: 100%"
     }
    },
    "de38e0a8f5a24cbdbf755db3cfd399ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_823cdbf0fa2c43559d01de4664258a86",
      "placeholder": "​",
      "style": "IPY_MODEL_e5ae38c7214c4f05974de99e5d5c3485",
      "value": " 499/0 [00:00&lt;00:00, 2393.49 examples/s]"
     }
    },
    "df0a135d8a5b43d5ab94bef15b2db5aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0ceffacff7f492d87084da291061006",
      "max": 5942065440,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_af87959da48a436e842f58ac691717df",
      "value": 5942065440
     }
    },
    "e225b3758fa24df3a0d6f1a039d3220a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c4a2676871e492897d305d6d9a6fac9",
      "placeholder": "​",
      "style": "IPY_MODEL_f432e32a03704652a5bcd21c7ce36abd",
      "value": " 1/1 [00:00&lt;00:00, 29.62it/s]"
     }
    },
    "e35a5293e19748679095d1222f1a31e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5ae38c7214c4f05974de99e5d5c3485": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eb30e73c1e824fa8942f0c58104d696f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c96a1b051a7b4fbfbd873be07cf44cf0",
      "placeholder": "​",
      "style": "IPY_MODEL_fa37a3f2205749468f31309b6061ffef",
      "value": "mistral-7b-instruct-v0.2.Q6_K.gguf: 100%"
     }
    },
    "f432e32a03704652a5bcd21c7ce36abd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f52b2088b6724e6dad9ee18ba364c009": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fa37a3f2205749468f31309b6061ffef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fa5555299e2e47ae9d2cc7a7e58415f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fca89659d3684477bb46613bbb96383d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
