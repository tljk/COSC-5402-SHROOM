{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "S7p86kSc2T-0",
        "outputId": "280c9681-5a84-4066-83b1-031f23ef2ac5"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers.cross_encoder import CrossEncoder\n",
        "from sentence_transformers.cross_encoder.evaluation import CEBinaryClassificationEvaluator\n",
        "from sentence_transformers import InputExample\n",
        "import pandas as pd, math\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "\n",
        "num_epochs = 1\n",
        "train_batch_size = 5\n",
        "model_save_path = \"./model_dump\"\n",
        "model_name = 'vectara/hallucination_evaluation_model' # base model, use 'vectara/hallucination_evaluation_model' if you want to further fine-tune ours\n",
        "\n",
        "model = CrossEncoder(model_name, num_labels=1, automodel_args={'ignore_mismatched_sizes':True})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train examples: 6084 Test examples: 1500\n",
            "<InputExample> label: 1, texts: `` i would have written to him , but a few words from you will go further than all the apologetical sesquipedalities i could muster on the occasion . What is the meaning of apologetical ? apologetic; expressing or expressing regret or apology\n",
            "<InputExample> label: 1, texts: Sadly , at the end of his life , Luther became somewhat of a nutso . Crazy person ; crackpot or lunatic .; A crazy person .\n"
          ]
        }
      ],
      "source": [
        "# Load some training examples as such, using a pandas dataframe with source and summary columns:\n",
        "train_examples, test_examples = [], []\n",
        "# load train\n",
        "\n",
        "# # trial dev\n",
        "# train = pd.read_excel('../data/trial_v1.xlsx')\n",
        "# for i, row in train.iterrows():\n",
        "#     train_examples.append(InputExample(texts=[str(row['src'])+\" \"+str(row[\"tgt\"]), str(row['hyp'])], label=int(0 if row['label'] == \"Hallucination\" else 1)))\n",
        "# train = pd.read_excel('../data/dev_aware.xlsx')\n",
        "# for i, row in train.iterrows():\n",
        "#     train_examples.append(InputExample(texts=[str(row['src'])+\" \"+str(row[\"tgt\"]), str(row['hyp'])], label=int(0 if row['label'] == \"Hallucination\" else 1)))\n",
        "# train = pd.read_excel('../data/dev_agnostic.xlsx')\n",
        "# for i, row in train.iterrows():\n",
        "#     train_examples.append(InputExample(texts=[str(row['src'])+\" \"+str(row[\"tgt\"]), str(row['hyp'])], label=int(0 if row['label'] == \"Hallucination\" else 1)))\n",
        "\n",
        "# # solar\n",
        "# train = pd.read_excel('../data/train_aware.xlsx')\n",
        "# for i, row in train.iterrows():\n",
        "#     train_examples.append(InputExample(texts=[str(row['src'])+\" \"+str(row[\"tgt\"]), str(row['hyp'])], label=int(0 if row['solar'] == \"Hallucination\" else 1)))\n",
        "# train = pd.read_excel('../data/train_agnostic.xlsx')\n",
        "# for i, row in train.iterrows():\n",
        "#     train_examples.append(InputExample(texts=[str(row['src'])+\" \"+str(row[\"tgt\"]), str(row['hyp'])], label=int(0 if row['solar'] == \"Hallucination\" else 1)))\n",
        "\n",
        "# # baseline\n",
        "# train = pd.read_excel('../data/train_aware.xlsx')\n",
        "# for i, row in train.iterrows():\n",
        "#     train_examples.append(InputExample(texts=[str(row['src'])+\" \"+str(row[\"tgt\"]), str(row['hyp'])], label=int(0 if row['baseline'] == \"Hallucination\" else 1)))\n",
        "# train = pd.read_excel('../data/train_agnostic.xlsx')\n",
        "# for i, row in train.iterrows():\n",
        "#     train_examples.append(InputExample(texts=[str(row['src'])+\" \"+str(row[\"tgt\"]), str(row['hyp'])], label=int(0 if row['baseline'] == \"Hallucination\" else 1)))\n",
        "\n",
        "# special filtered results for solar\n",
        "json = pd.read_json('../data/filter_results.json')\n",
        "index = 1 # 0, 1, 2\n",
        "train_aware_filter = json[index][\"aware\"]\n",
        "train_agnostic_filter = json[index][\"agnostic\"]\n",
        "\n",
        "train = pd.read_excel('../data/train_aware.xlsx')\n",
        "for i, row in train.iterrows():\n",
        "    if train_aware_filter[i] == True:\n",
        "        train_examples.append(InputExample(texts=[str(row['src'])+\" \"+str(row[\"tgt\"]), str(row['hyp'])], label=int(0 if row['solar'] == \"Hallucination\" else 1)))\n",
        "train = pd.read_excel('../data/train_agnostic.xlsx')\n",
        "for i, row in train.iterrows():\n",
        "    if train_agnostic_filter[i] == True:\n",
        "        train_examples.append(InputExample(texts=[str(row['src'])+\" \"+str(row[\"tgt\"]), str(row['hyp'])], label=int(0 if row['solar'] == \"Hallucination\" else 1)))\n",
        "\n",
        "# load test\n",
        "test = pd.read_excel('../data/test_aware.xlsx')\n",
        "for i, row in test.iterrows():\n",
        "    test_examples.append(InputExample(texts=[str(row['src'])+\" \"+str(row[\"tgt\"]), str(row['hyp'])], label=int(0 if row['label'] == \"Hallucination\" else 1)))\n",
        "\n",
        "print(\"Train examples:\", len(train_examples), \"Test examples:\", len(test_examples))\n",
        "print(train_examples[0])\n",
        "print(test_examples[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35159ebc46094d6aa5dd49135c548966",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8033457221ef4a7fb44fd936973841e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Iteration:   0%|          | 0/1217 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Then train the model as such as per the Cross Encoder API:\n",
        "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=train_batch_size)\n",
        "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1) #10% of train data for warm-up\n",
        "model.fit(train_dataloader=train_dataloader,\n",
        "          evaluator=CEBinaryClassificationEvaluator.from_input_examples(test_examples, name='test'),\n",
        "          epochs=num_epochs,\n",
        "          evaluation_steps=10_000,\n",
        "          warmup_steps=warmup_steps,\n",
        "          output_path=model_save_path,\n",
        "          show_progress_bar=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
